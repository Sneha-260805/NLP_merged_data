```json
{
  "unnormalised": "ठीक है, तो किसी ने मुझसे पूछा कि लीनियर अलजेब्रा कितना महत्वपूर्ण है, खासकर यदि आप डेटा साइंस जैसे क्षेत्रों को देख रहे हैं। ठीक है, मुझ पर विश्वास करो, यह बहुत महत्वपूर्ण है! आपको लग सकता है कि कैलक 1, 2, और 3 गणित के पवित्र ग्रेल हैं, और वे भी महत्वपूर्ण हैं, इसमें कोई संदेह नहीं है। लेकिन मशीन लर्निंग को रेखांकित करने वाले गणित को समझने के लिए? लीनियर अलजेब्रा आपका दोस्त है। यह ऐसा है, 80% गणित जो आप वास्तव में दैनिक आधार पर उपयोग करेंगे। इस महत्वपूर्ण आधार को न छोड़ें।",
  "normalised": "ठीक है, तो किसी ने मुझसे पूछा कि लीनियर अलजेब्रा कितना महत्वपूर्ण है, खासकर यदि आप डेटा साइंस जैसे क्षेत्रों को देख रहे हैं। ठीक है, मुझ पर विश्वास करो, यह बहुत महत्वपूर्ण है! आपको लग सकता है कि कैलक एक, दो और तीन गणित के पवित्र ग्रेल हैं, और वे भी महत्वपूर्ण हैं, इसमें कोई संदेह नहीं है। लेकिन मशीन लर्निंग को रेखांकित करने वाले गणित को समझने के लिए? लीनियर अलजेब्रा आपका दोस्त है। यह ऐसा है, अस्सी प्रतिशत गणित जो आप वास्तव में दैनिक आधार पर उपयोग करेंगे। इस महत्वपूर्ण आधार को न छोड़ें।",
  "raw": "ठीक है, तो किसी ने मुझसे पूछा कि लीनियर अलजेब्रा कितना महत्वपूर्ण है, खासकर यदि आप डेटा साइंस जैसे क्षेत्रों को देख रहे हैं। ठीक है, मुझ पर विश्वास करो, यह बहुत महत्वपूर्ण है! आपको लग सकता है कि कैलक 1, 2, और 3 गणित के पवित्र ग्रेल हैं, और वे भी महत्वपूर्ण हैं, इसमें कोई संदेह नहीं है। लेकिन मशीन लर्निंग को रेखांकित करने वाले गणित को समझने के लिए? लीनियर अलजेब्रा आपका दोस्त है। यह ऐसा है, 80% गणित जो आप वास्तव में दैनिक आधार पर उपयोग करेंगे। इस महत्वपूर्ण आधार को न छोड़ें।"
}
```
```json
{
  "unnormalised": "इसके बारे में सोचें: डेटा को अक्सर मैट्रिक्स में व्यवस्थित किया जाता है। छवियों को पिक्सेल मानों के मैट्रिक्स के रूप में दर्शाया जाता है (उदाहरण के लिए, एक 256x256 छवि)। मशीन लर्निंग के लिए डेटासेट को अक्सर मैट्रिक्स के रूप में दर्शाया जाता है, जिसमें पंक्तियाँ नमूनों का प्रतिनिधित्व करती हैं और कॉलम सुविधाओं का प्रतिनिधित्व करते हैं। रैखिक बीजगणित इन मैट्रिक्सों को हेरफेर और विश्लेषण करने के लिए उपकरण प्रदान करता है। मैट्रिक्स गुणन, रैखिक समीकरणों की प्रणालियों को हल करना (जैसे Ax = b), और आइगेनवैल्यू अपघटन जैसे ऑपरेशन सभी मशीन लर्निंग एल्गोरिदम के लिए मौलिक हैं। यहां तक कि रोटेशन जैसी सरल चीज भी मैट्रिक्स का उपयोग करती है! आप SVD और PCA जैसे शब्दों का सामना कर सकते हैं। SVD, उदाहरण के लिए, छवि संपीड़न और अनुशंसक प्रणालियों में उपयोग किया जाता है। PCA (प्रिंसिपल कंपोनेंट एनालिसिस) का उपयोग आयामीता में कमी के लिए किया जाता है, उदाहरण के लिए 1000 आयामों को 10 तक कम करना।",
  "normalised": "इसके बारे में सोचें: डेटा को अक्सर मैट्रिक्स में व्यवस्थित किया जाता है। छवियों को पिक्सेल मानों के मैट्रिक्स के रूप में दर्शाया जाता है (उदाहरण के लिए, दो सौ छप्पन गुणा दो सौ छप्पन छवि)। मशीन लर्निंग के लिए डेटासेट को अक्सर मैट्रिक्स के रूप में दर्शाया जाता है, जिसमें पंक्तियाँ नमूनों का प्रतिनिधित्व करती हैं और कॉलम सुविधाओं का प्रतिनिधित्व करते हैं। रैखिक बीजगणित इन मैट्रिक्सों को हेरफेर और विश्लेषण करने के लिए उपकरण प्रदान करता है। मैट्रिक्स गुणन, रैखिक समीकरणों की प्रणालियों को हल करना (जैसे A x बराबर b), और आइगेनवैल्यू अपघटन जैसे ऑपरेशन सभी मशीन लर्निंग एल्गोरिदम के लिए मौलिक हैं। यहां तक कि रोटेशन जैसी सरल चीज भी मैट्रिक्स का उपयोग करती है! आप S-V-D और P-C-A जैसे शब्दों का सामना कर सकते हैं। S-V-D, उदाहरण के लिए, छवि संपीड़न और अनुशंसक प्रणालियों में उपयोग किया जाता है। P-C-A (प्रिंसिपल कंपोनेंट एनालिसिस) का उपयोग आयामीता में कमी के लिए किया जाता है, उदाहरण के लिए एक हजार आयामों को दस तक कम करना।",
  "raw": "इसके बारे में सोचें: डेटा को अक्सर मैट्रिक्स में व्यवस्थित किया जाता है। छवियों को पिक्सेल मानों के मैट्रिक्स के रूप में दर्शाया जाता है (उदाहरण के लिए, एक 256x256 छवि)। मशीन लर्निंग के लिए डेटासेट को अक्सर मैट्रिक्स के रूप में दर्शाया जाता है, जिसमें पंक्तियाँ नमूनों का प्रतिनिधित्व करती हैं और कॉलम सुविधाओं का प्रतिनिधित्व करते हैं। रैखिक बीजगणित इन मैट्रिक्सों को हेरफेर और विश्लेषण करने के लिए उपकरण प्रदान करता है। मैट्रिक्स गुणन, रैखिक समीकरणों की प्रणालियों को हल करना (जैसे Ax = b), और आइगेनवैल्यू अपघटन जैसे ऑपरेशन सभी मशीन लर्निंग एल्गोरिदम के लिए मौलिक हैं। यहां तक कि रोटेशन जैसी सरल चीज भी मैट्रिक्स का उपयोग करती है! आप SVD और PCA जैसे शब्दों का सामना कर सकते हैं। SVD, उदाहरण के लिए, छवि संपीड़न और अनुशंसक प्रणालियों में उपयोग किया जाता है। PCA (प्रिंसिपल कंपोनेंट एनालिसिस) का उपयोग आयामीता में कमी के लिए किया जाता है, उदाहरण के लिए 1000 आयामों को 10 तक कम करना।"
}
```
```json
{
  "unnormalised": "तो हाँ, लीनियर अलजेब्रा सिर्फ़ कोई अमूर्त गणित का कोर्स नहीं है। यह आपको वास्तव में यह _समझने_ के लिए कौशल देता है कि मशीन लर्निंग मॉडल कैसे काम करते हैं। सिर्फ़ समीकरणों को रटने को भूल जाइए, आप लीनियर अलजेब्रा से चीज़ें बना सकते हैं। यदि आप AI/ML को लेकर गंभीर हैं, तो इसे ठीक से सीखने में समय लगाएँ। आपको इसका पछतावा नहीं होगा! गंभीरता से, क्लास से अपने नोट्स पर वापस जाएँ या शायद MIT 18.06 व्याख्यानों जैसे संसाधनों से समीक्षा करें। आपको अंतर्निहित अवधारणाओं को समझने और उन्हें व्यावहारिक रूप से लागू करने में सक्षम होने की आवश्यकता है।",
  "normalised": "तो हाँ, लीनियर अलजेब्रा सिर्फ़ कोई अमूर्त गणित का कोर्स नहीं है। यह आपको वास्तव में यह समझने के लिए कौशल देता है कि मशीन लर्निंग मॉडल कैसे काम करते हैं। सिर्फ़ समीकरणों को रटने को भूल जाइए, आप लीनियर अलजेब्रा से चीज़ें बना सकते हैं। यदि आप A-I स्लैश M-L को लेकर गंभीर हैं, तो इसे ठीक से सीखने में समय लगाएँ। आपको इसका पछतावा नहीं होगा! गंभीरता से, क्लास से अपने नोट्स पर वापस जाएँ या शायद M-I-T अठारह दशमलव शून्य छह व्याख्यानों जैसे संसाधनों से समीक्षा करें। आपको अंतर्निहित अवधारणाओं को समझने और उन्हें व्यावहारिक रूप से लागू करने में सक्षम होने की आवश्यकता है।",
  "raw": "तो हाँ, लीनियर अलजेब्रा सिर्फ़ कोई अमूर्त गणित का कोर्स नहीं है। यह आपको वास्तव में यह _समझने_ के लिए कौशल देता है कि मशीन लर्निंग मॉडल कैसे काम करते हैं। सिर्फ़ समीकरणों को रटने को भूल जाइए, आप लीनियर अलजेब्रा से चीज़ें बना सकते हैं। यदि आप AI/ML को लेकर गंभीर हैं, तो इसे ठीक से सीखने में समय लगाएँ। आपको इसका पछतावा नहीं होगा! गंभीरता से, क्लास से अपने नोट्स पर वापस जाएँ या शायद MIT 18.06 व्याख्यानों जैसे संसाधनों से समीक्षा करें। आपको अंतर्निहित अवधारणाओं को समझने और उन्हें व्यावहारिक रूप से लागू करने में सक्षम होने की आवश्यकता है।"
}
```
