{"unnormalised": "IIT Delhi researchers have apparently cracked a new method for solving complex linear algebra probs. Seems like they're calling it \"Modified Gauss-Jordan Elimination++\" – fancy, huh? Apparently, it's supposed to be way faster for matrices larger than 1000x1000, which is kinda a big deal in fields like AI and big data analytics.", "normalised": "I-I-T Delhi researchers have apparently cracked a new method for solving complex linear algebra problems. Seems like they are calling it \"Modified Gauss-Jordan Elimination plus plus\" – fancy, huh? Apparently, it is supposed to be way faster for matrices larger than one thousand by one thousand, which is kind of a big deal in fields like A-I and big data analytics."}
{"unnormalised": "The team, led by Prof. Meena Krishnan, published their findings in the \"Journal of Applied Maths\" earlier this week. They claim their algorithm reduces computation time by approx. 20-25% compared to existing methods. Imagine all the saved processing power!", "normalised": "The team, led by Professor Meena Krishnan, published their findings in the \"Journal of Applied Maths\" earlier this week. They claim their algorithm reduces computation time by approximately twenty to twenty five percent compared to existing methods. Imagine all the saved processing power!"}
{"unnormalised": "So, what's the big deal with linear algebra anyway? Well, it's the backbone of so many things we use every day, from Google Search (algorithms are basically linear equations), to image processing software, to even weather forecasting models. All use intense mathematical equations.", "normalised": "So, what is the big deal with linear algebra anyway? Well, it is the backbone of so many things we use every day, from Google Search algorithms are basically linear equations, to image processing software, to even weather forecasting models. All use intense mathematical equations."}
{"unnormalised": "Prof. Krishnan mentioned that the code will be released as open source on GitHub sometime in Q4 2024. Anyone who wants to try their hand at it can do it. That is great!", "normalised": "Professor Krishnan mentioned that the code will be released as open source on G-it-H-u-b sometime in Q four two thousand and twenty four. Anyone who wants to try their hand at it can do it. That is great!"}
{"unnormalised": "Initial tests show a significant difference in speed (around 0.25x faster) when applied to datasets exceeding 2GB. Will this really make a difference in AI development? Only time will tell.", "normalised": "Initial tests show a significant difference in speed around zero point two five x faster when applied to datasets exceeding two gigabytes. Will this really make a difference in A-I development? Only time will tell."}
