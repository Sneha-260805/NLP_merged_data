{"unnormalised": "Remember to use \"Dr.\" for medical professionals and \"Prof.\" for professors. It's also common to see \"Adv.\" used for lawyers in legal contexts in India.", "normalised": "Okay, I understand the comprehensive normalization rules and the specific handling of \"Dr.\", \"Prof.\", and \"Adv.\". I will implement a Python script to process the textual data according to these requirements."}
{"unnormalised": "", "normalised": "Here's a breakdown of how the script will address each rule, followed by the Python code:"}
{"unnormalised": "", "normalised": "**Core Logic and Approach:**"}
{"unnormalised": "", "normalised": "1.  **File System Traversal:** I'll use `os.walk` to recursively go through all folders and files in the input directory."}
{"unnormalised": "", "normalised": "2.  **Output Directory Mirroring:** For each folder in the input, I'll create a corresponding folder in the `dataset_normalized` output directory."}
{"unnormalised": "", "normalised": "3.  **File Processing:**"}
{"unnormalised": "", "normalised": "    *   If a file is a `.txt` file, its content will be read, normalized, and then written to a new `.txt` file in the mirrored output folder."}
{"unnormalised": "", "normalised": "    *   If a file is not a `.txt` file, it will be copied directly to the mirrored output folder without modification."}
{"unnormalised": "", "normalised": "4.  **Normalization Order (Crucial for correct output):** The order of applying the normalization rules matters. I'll generally apply more specific rules before more general ones (e.g., currency + number + suffix before general numbers, or specific symbols before general alphanumeric patterns)."}
{"unnormalised": "", "normalised": "    *   Symbols and special characters."}
{"unnormalised": "", "normalised": "    *   Currency + Number + Suffix."}
{"unnormalised": "", "normalised": "    *   Dates."}
{"unnormalised": "", "normalised": "    *   Numbers (including those in units, but the units expansion itself comes after)."}
{"unnormalised": "", "normalised": "    *   Acronyms."}
{"unnormalised": "", "normalised": "    *   Units."}
{"unnormalised": "", "normalised": "    *   Mathematical notation."}
{"unnormalised": "", "normalised": "    *   Special prefixes like \"Dr.\", \"Prof.\", \"Adv.\" will be handled early or with specific regex to avoid misinterpretation by number or acronym rules."}
{"unnormalised": "", "normalised": "    *   General `/` handling."}
{"unnormalised": "", "normalised": "    *   Space normalization as a final step."}
{"unnormalised": "", "normalised": "**Detailed Rule Implementation Strategy:**"}
{"unnormalised": "", "normalised": "1.  **Symbols → Spoken form:** I'll use a dictionary mapping common symbols to their spoken forms and iterate through the text, performing replacements. Regular expressions will be used for symbols that might appear with varying contexts (e.g., `+/-`)."}
{"unnormalised": "", "normalised": "    *   `art/craft` -> `art or craft` (regex: `(\\b\\w+)\\/(\\w+\\b)`)"}
{"unnormalised": "", "normalised": "    *   `QA/Dev` -> `Q-A slash D-e-v` (regex for mixed case or abbreviations `(\\b[A-Z0-9]+)\\/([A-Z0-9]+\\b)`)"}
{"unnormalised": "", "normalised": "    *   `2+2=4` will be handled by the mathematical notation rule."}
{"unnormalised": "", "normalised": "    *   `$`, `~`, `*`, `#`, `@`, `&`, etc. will be directly mapped."}
{"unnormalised": "", "normalised": "2.  **Acronyms → Hyphenated letters:**"}
{"unnormalised": "", "normalised": "    *   Regex: `\\b[A-Z]{2,}\\b` (two or more consecutive uppercase letters, as a whole word). I need to be careful not to apply this to `Dr.`, `Prof.`, `Adv.`."}
{"unnormalised": "", "normalised": "    *   Replace with `'-'.join(match.group())`."}
{"unnormalised": "", "normalised": "3.  **Numbers → Spoken form:** This is complex. I'll use the `num2words` library for general number conversion, which handles various contexts. For specific cases like \"half kilogram\", I'll use regex to identify patterns like `(\\d+)/(\\d+)\\s*(\\w+)` followed by a unit, and apply `num2words` to the fraction or convert `1/2` to \"half\"."}
{"unnormalised": "", "normalised": "    *   General numbers: `num2words(number)`"}
{"unnormalised": "", "normalised": "    *   Fractions: `1/2 kg` -> `half kilogram`, `3/4` -> `three divided by four` (handled by math, but needs to be careful not to confuse with dates)."}
{"unnormalised": "", "normalised": "4.  **Numeric suffixes → Expanded form:**"}
{"unnormalised": "", "normalised": "    *   Regex: `(\\d+)([KMBT])\\b`"}
{"unnormalised": "", "normalised": "    *   Map `K` to `thousand`, `M` to `million`, `B` to `billion`, `T` to `trillion`."}
{"unnormalised": "", "normalised": "    *   Convert number part using `num2words`."}
{"unnormalised": "", "normalised": "5.  **Currency + Number + Suffix:**"}
{"unnormalised": "", "normalised": "    *   Regex: `([$₹€£])(\\s*)(\\d+)([KMBT])?\\b`"}
{"unnormalised": "", "normalised": "    *   Convert currency symbol, number, and suffix."}
{"unnormalised": "", "normalised": "6.  **Dates → Natural spoken form:**"}
{"unnormalised": "", "normalised": "    *   Regex patterns for `DD-MM-YYYY`, `DD/MM/YYYY`, `YYYY-MM-DD`."}
{"unnormalised": "", "normalised": "    *   Use `datetime.strptime` to parse and then `strftime` with custom logic for ordinal numbers (e.g., \"tenth\", \"first\") and spoken year. Assuming `DD/MM/YYYY` as default for ambiguous `DD/MM/YYYY`."}
{"unnormalised": "", "normalised": "7.  **Units → Spoken form:**"}
{"unnormalised": "", "normalised": "    *   Regex to find `(\\d+)(\\s*)(cm|mm|m|km|g|kg|mg|ml|l|°C|...)`"}
{"unnormalised": "", "normalised": "    *   Map units to full words (e.g., `cm` to `centimeter`, `°C` to `degree celsius`)."}
{"unnormalised": "", "normalised": "    *   Apply number conversion to the preceding number."}
{"unnormalised": "", "normalised": "8.  **Mathematical notation → Spoken form:** This requires a sophisticated set of regex and potentially a small parser for more complex expressions."}
{"unnormalised": "", "normalised": "    *   `x^2`: `x squared` (regex `(\\w)\\^2`)"}
{"unnormalised": "", "normalised": "    *   `x^3`: `x cubed` (regex `(\\w)\\^3`)"}
{"unnormalised": "", "normalised": "    *   `x^n`: `x to the power of n` (regex `(\\w)\\^(\\w+)`)"}
{"unnormalised": "", "normalised": "    *   `x_i`: `x sub i` (regex `(\\w)_(\\w+)`)"}
{"unnormalised": "", "normalised": "    *   `√x`: `square root of x` (regex `√(\\w+)`)"}
{"unnormalised": "", "normalised": "    *   `∫`: `integral`"}
{"unnormalised": "", "normalised": "    *   `Σ`: `summation`"}
{"unnormalised": "", "normalised": "    *   Fractions: `3/4` -> `three divided by four` (regex: `(\\d+)\\/(\\d+)`, but ensuring it's not a date)."}
{"unnormalised": "", "normalised": "    *   Symbols: `≠`, `≤`, `≥` will be handled by the general symbol replacement."}
{"unnormalised": "", "normalised": "9.  **Output format:**"}
{"unnormalised": "", "normalised": "    *   Normalize spaces at the end: `re.sub(r'\\s+', ' ', text).strip()`."}
{"unnormalised": "", "normalised": "10. **File handling:** `os.walk`, `os.makedirs`, `shutil.copy2`."}
{"unnormalised": "", "normalised": "**Specific Prefix Handling:**"}
{"unnormalised": "", "normalised": "*   `Dr.`, `Prof.`, `Adv.` will be handled by looking for these exact strings, potentially with a period or space following, and preserving them. This should happen before general acronym processing."}
{"unnormalised": "", "normalised": "Let's start building the Python script."}
{"unnormalised": "", "normalised": "```python"}
{"unnormalised": "", "normalised": "import os"}
{"unnormalised": "", "normalised": "import re"}
{"unnormalised": "", "normalised": "import shutil"}
{"unnormalised": "", "normalised": "from datetime import datetime"}
{"unnormalised": "", "normalised": "from num2words import num2words"}
{"unnormalised": "", "normalised": "import unicodedata # For handling unicode symbols"}
{"unnormalised": "", "normalised": "def ordinal_suffix(day):"}
{"unnormalised": "", "normalised": "    \"\"\"Returns the ordinal suffix for a number.\"\"\""}
{"unnormalised": "", "normalised": "    if 10 <= day % 100 <= 20:"}
{"unnormalised": "", "normalised": "        return 'th'"}
{"unnormalised": "", "normalised": "    else:"}
{"unnormalised": "", "normalised": "        return {1: 'st', 2: 'nd', 3: 'rd'}.get(day % 10, 'th')"}
{"unnormalised": "", "normalised": "def convert_number_to_words(number_str):"}
{"unnormalised": "", "normalised": "    \"\"\"Converts a number string to its spoken form, handling edge cases.\"\"\""}
{"unnormalised": "", "normalised": "    try:"}
{"unnormalised": "", "normalised": "        if '.' in number_str:"}
{"unnormalised": "", "normalised": "            # Handle decimals separately if num2words doesn't do it naturally for all cases"}
{"unnormalised": "", "normalised": "            integer_part, decimal_part = number_str.split('.')"}
{"unnormalised": "", "normalised": "            integer_words = num2words(int(integer_part))"}
{"unnormalised": "", "normalised": "            decimal_words = 'point ' + ' '.join(num2words(int(d)) for d in decimal_part)"}
{"unnormalised": "", "normalised": "            return f\"{integer_words} {decimal_words}\""}
{"unnormalised": "", "normalised": "        else:"}
{"unnormalised": "", "normalised": "            return num2words(int(number_str))"}
{"unnormalised": "", "normalised": "    except ValueError:"}
{"unnormalised": "", "normalised": "        return number_str # Return original if conversion fails"}
{"unnormalised": "", "normalised": "def normalize_text(text):"}
{"unnormalised": "", "normalised": "    \"\"\""}
{"unnormalised": "", "normalised": "    Applies all normalization rules to the input text."}
{"unnormalised": "", "normalised": "    \"\"\""}
{"unnormalised": "", "normalised": "    # --- 0. Special Prefix Handling (Dr., Prof., Adv.) ---"}
{"unnormalised": "", "normalised": "    # These are handled by keeping them as is, they should not be treated as acronyms."}
{"unnormalised": "", "normalised": "    # No explicit replacement needed, just ensures other rules don't modify them."}
{"unnormalised": "", "normalised": "    # --- 1. Symbols → Spoken form ---"}
{"unnormalised": "", "normalised": "    # More specific symbol replacements first"}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\+/-', 'plus or minus', text)"}
{"unnormalised": "", "normalised": "    text = re.sub(r'!=', 'not equal to', text)"}
{"unnormalised": "", "normalised": "    text = re.sub(r'<=', 'less than or equal to', text)"}
{"unnormalised": "", "normalised": "    text = re.sub(r'>=', 'greater than or equal to', text)"}
{"unnormalised": "", "normalised": "    text = re.sub(r'==', 'equals', text)"}
{"unnormalised": "", "normalised": "    text = re.sub(r'->', 'maps to', text) # Common in math/programming context"}
{"unnormalised": "", "normalised": "    symbol_map = {"}
{"unnormalised": "", "normalised": "        '#': 'hash',"}
{"unnormalised": "", "normalised": "        '@': 'at',"}
{"unnormalised": "", "normalised": "        '&': 'and',"}
{"unnormalised": "", "normalised": "        '*': 'asterisk',"}
{"unnormalised": "", "normalised": "        '~': 'approximately',"}
{"unnormalised": "", "normalised": "        '≠': 'not equal to',"}
{"unnormalised": "", "normalised": "        '≤': 'less than or equal to',"}
{"unnormalised": "", "normalised": "        '≥': 'greater than or equal to',"}
{"unnormalised": "", "normalised": "        '∫': 'integral',"}
{"unnormalised": "", "normalised": "        '∑': 'summation',"}
{"unnormalised": "", "normalised": "        'π': 'pi',"}
{"unnormalised": "", "normalised": "        '√': 'square root of',"}
{"unnormalised": "", "normalised": "        '%': 'percent', # After ~ approximately, before general numbers"}
{"unnormalised": "", "normalised": "        '°': 'degree', # Before general numbers"}
{"unnormalised": "", "normalised": "        '€': 'euro',"}
{"unnormalised": "", "normalised": "        '£': 'pound',"}
{"unnormalised": "", "normalised": "    }"}
{"unnormalised": "", "normalised": "    # Sort keys by length in descending order to avoid partial matches (e.g., '≠' before '≠')"}
{"unnormalised": "", "normalised": "    for symbol, spoken_form in sorted(symbol_map.items(), key=lambda item: len(item[0]), reverse=True):"}
{"unnormalised": "", "normalised": "        text = text.replace(symbol, spoken_form)"}
{"unnormalised": "", "normalised": "    # Handling '/'"}
{"unnormalised": "", "normalised": "    # Priority:"}
{"unnormalised": "", "normalised": "    # 1. Divided by (between numbers/math)"}
{"unnormalised": "", "normalised": "    # 2. Or (between words)"}
{"unnormalised": "", "normalised": "    # 3. Slash (mixed cases, abbreviations, remaining)"}
{"unnormalised": "", "normalised": "    # 1. Fractions or division in math: 3/4 -> three divided by four, 1/2 -> one divided by two"}
{"unnormalised": "", "normalised": "    # This needs to be robust, ensuring it's not a date."}
{"unnormalised": "", "normalised": "    # Specific for 1/2 as \"half\" when followed by a unit (Rule 3/7 interplay)"}
{"unnormalised": "", "normalised": "    def replace_fraction_with_unit(match):"}
{"unnormalised": "", "normalised": "        num_str = match.group(1)"}
{"unnormalised": "", "normalised": "        denom_str = match.group(2)"}
{"unnormalised": "", "normalised": "        unit = match.group(3) if match.group(3) else ''"}
{"unnormalised": "", "normalised": "        if num_str == '1' and denom_str == '2':"}
{"unnormalised": "", "normalised": "            return f\"half {unit}\""}
{"unnormalised": "", "normalised": "        else:"}
{"unnormalised": "", "normalised": "            return f\"{convert_number_to_words(num_str)} divided by {convert_number_to_words(denom_str)} {unit}\".strip()"}
{"unnormalised": "", "normalised": "    # Pattern for X/Y unit, e.g., 1/2 kg, 3/4 meter"}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\b(\\d+)/(\\d+)\\s*(cm|mm|m|km|g|kg|mg|ml|l|C|F|K|hour|day|week|month|year)s?\\b',"}
{"unnormalised": "", "normalised": "                  replace_fraction_with_unit, text, flags=re.IGNORECASE)"}
{"unnormalised": "", "normalised": "    # Pattern for X/Y without a specific unit, e.g., 3/4"}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\b(\\d+)/(\\d+)\\b',"}
{"unnormalised": "", "normalised": "                  lambda m: f\"{convert_number_to_words(m.group(1))} divided by {convert_number_to_words(m.group(2))}\","}
{"unnormalised": "", "normalised": "                  text)"}
{"unnormalised": "", "normalised": "    # 2. \"or\" between words (e.g., art/craft)"}
{"unnormalised": "", "normalised": "    text = re.sub(r'(\\b\\w+)\\/(\\w+\\b)', r'\\1 or \\2', text)"}
{"unnormalised": "", "normalised": "    # 3. \"slash\" for mixed cases or abbreviations (e.g., QA/Dev, R/D)"}
{"unnormalised": "", "normalised": "    # This also catches any remaining slashes that aren't dates or fractions"}
{"unnormalised": "", "normalised": "    text = re.sub(r'([A-Za-z0-9]+)\\/([A-Za-z0-9]+)', r'\\1 slash \\2', text)"}
{"unnormalised": "", "normalised": "    # --- 2. Acronyms → Hyphenated letters ---"}
{"unnormalised": "", "normalised": "    # Exclude Dr., Prof., Adv. and common currency codes (e.g., USD, EUR, INR)"}
{"unnormalised": "", "normalised": "    # Also exclude single letters or numbers that might be part of an expression, and units."}
{"unnormalised": "", "normalised": "    # This regex is tricky. Let's try to match sequences of uppercase letters."}
{"unnormalised": "", "normalised": "    # Lookbehind for a word boundary, lookahead for a word boundary."}
{"unnormalised": "", "normalised": "    # Exclude common pre-defined terms."}
{"unnormalised": "", "normalised": "    excluded_acronyms = {'DR', 'PROF', 'ADV', 'USD', 'EUR', 'GBP', 'INR', 'K', 'M', 'B', 'T'}"}
{"unnormalised": "", "normalised": "    def replace_acronym(match):"}
{"unnormalised": "", "normalised": "        acronym = match.group(0)"}
{"unnormalised": "", "normalised": "        if acronym in excluded_acronyms:"}
{"unnormalised": "", "normalised": "            return acronym"}
{"unnormalised": "", "normalised": "        # Check if it's potentially a unit like 'KG', 'CM' etc. (already handled by units rule later)"}
{"unnormalised": "", "normalised": "        if len(acronym) <= 3 and acronym.lower() in ['cm', 'mm', 'm', 'km', 'g', 'kg', 'mg', 'ml', 'l', 'c', 'f', 'k']:"}
{"unnormalised": "", "normalised": "            return acronym # Let unit rule handle it"}
{"unnormalised": "", "normalised": "        return '-'.join(list(acronym))"}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\b[A-Z]{2,}\\b', replace_acronym, text)"}
{"unnormalised": "", "normalised": "    # --- 6. Dates → Natural spoken form ---"}
{"unnormalised": "", "normalised": "    # Prioritize YYYY-MM-DD"}
{"unnormalised": "", "normalised": "    def replace_date(match):"}
{"unnormalised": "", "normalised": "        try:"}
{"unnormalised": "", "normalised": "            date_obj = datetime.strptime(match.group(0), '%Y-%m-%d')"}
{"unnormalised": "", "normalised": "            day = date_obj.day"}
{"unnormalised": "", "normalised": "            month = date_obj.strftime('%B').lower()"}
{"unnormalised": "", "normalised": "            year = num2words(date_obj.year)"}
{"unnormalised": "", "normalised": "            return f\"{num2words(day, to='ordinal')} {month} {year}\""}
{"unnormalised": "", "normalised": "        except ValueError:"}
{"unnormalised": "", "normalised": "            return match.group(0) # Return original if parsing fails"}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\b\\d{4}-\\d{2}-\\d{2}\\b', replace_date, text)"}
{"unnormalised": "", "normalised": "    # Prioritize DD-MM-YYYY or DD/MM/YYYY (assuming DD/MM/YYYY when ambiguous)"}
{"unnormalised": "", "normalised": "    def replace_date_ambiguous(match):"}
{"unnormalised": "", "normalised": "        try:"}
{"unnormalised": "", "normalised": "            # Try DD/MM/YYYY first"}
{"unnormalised": "", "normalised": "            date_obj = datetime.strptime(match.group(0), '%d/%m/%Y')"}
{"unnormalised": "", "normalised": "        except ValueError:"}
{"unnormalised": "", "normalised": "            try:"}
{"unnormalised": "", "normalised": "                # Then try DD-MM-YYYY"}
{"unnormalised": "", "normalised": "                date_obj = datetime.strptime(match.group(0), '%d-%m-%Y')"}
{"unnormalised": "", "normalised": "            except ValueError:"}
{"unnormalised": "", "normalised": "                return match.group(0) # Return original if parsing fails"}
{"unnormalised": "", "normalised": "        day = date_obj.day"}
{"unnormalised": "", "normalised": "        month = date_obj.strftime('%B').lower()"}
{"unnormalised": "", "normalised": "        year = num2words(date_obj.year)"}
{"unnormalised": "", "normalised": "        return f\"{num2words(day, to='ordinal')} {month} {year}\""}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\b\\d{2}[-/]\\d{2}[-/]\\d{4}\\b', replace_date_ambiguous, text)"}
{"unnormalised": "", "normalised": "    # --- 5. Currency + Number + Suffix ---"}
{"unnormalised": "", "normalised": "    # This must come before general numeric suffix and general number conversion."}
{"unnormalised": "", "normalised": "    def replace_currency_suffix(match):"}
{"unnormalised": "", "normalised": "        currency_symbol = match.group(1)"}
{"unnormalised": "", "normalised": "        number_str = match.group(3)"}
{"unnormalised": "", "normalised": "        suffix = match.group(4)"}
{"unnormalised": "", "normalised": "        "}
{"unnormalised": "", "normalised": "        currency_name = ''"}
{"unnormalised": "", "normalised": "        if currency_symbol == '$':"}
{"unnormalised": "", "normalised": "            currency_name = 'dollar'"}
{"unnormalised": "", "normalised": "        elif currency_symbol == '₹':"}
{"unnormalised": "", "normalised": "            currency_name = 'rupee'"}
{"unnormalised": "", "normalised": "        # Add other currencies if needed"}
{"unnormalised": "", "normalised": "        spoken_number = convert_number_to_words(number_str)"}
{"unnormalised": "", "normalised": "        if suffix:"}
{"unnormalised": "", "normalised": "            suffix_map = {'K': 'thousand', 'M': 'million', 'B': 'billion', 'T': 'trillion'}"}
{"unnormalised": "", "normalised": "            return f\"{currency_name} {spoken_number} {suffix_map[suffix]}\""}
{"unnormalised": "", "normalised": "        else:"}
{"unnormalised": "", "normalised": "            return f\"{currency_name} {spoken_number}\""}
{"unnormalised": "", "normalised": "    text = re.sub(r'([$₹€£])(\\s*)(\\d+)([KMBT])?\\b', replace_currency_suffix, text)"}
{"unnormalised": "", "normalised": "    # --- 4. Numeric suffixes → Expanded form ---"}
{"unnormalised": "", "normalised": "    # This must come before general number conversion."}
{"unnormalised": "", "normalised": "    def replace_numeric_suffix(match):"}
{"unnormalised": "", "normalised": "        number_str = match.group(1)"}
{"unnormalised": "", "normalised": "        suffix = match.group(2)"}
{"unnormalised": "", "normalised": "        spoken_number = convert_number_to_words(number_str)"}
{"unnormalised": "", "normalised": "        "}
{"unnormalised": "", "normalised": "        suffix_map = {'K': 'thousand', 'M': 'million', 'B': 'billion', 'T': 'trillion'}"}
{"unnormalised": "", "normalised": "        return f\"{spoken_number} {suffix_map[suffix]}\""}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\b(\\d+)([KMBT])\\b', replace_numeric_suffix, text)"}
{"unnormalised": "", "normalised": "    # --- 7. Units → Spoken form ---"}
{"unnormalised": "", "normalised": "    # This must come before general number conversion."}
{"unnormalised": "", "normalised": "    unit_map = {"}
{"unnormalised": "", "normalised": "        'cm': 'centimeter', 'mm': 'millimeter', 'm': 'meter', 'km': 'kilometer',"}
{"unnormalised": "", "normalised": "        'g': 'gram', 'kg': 'kilogram', 'mg': 'milligram',"}
{"unnormalised": "", "normalised": "        'ml': 'milliliter', 'l': 'liter',"}
{"unnormalised": "", "normalised": "        'C': 'celsius', 'F': 'fahrenheit', 'K': 'kelvin', # For degree units"}
{"unnormalised": "", "normalised": "        'hrs': 'hours', 'hr': 'hour',"}
{"unnormalised": "", "normalised": "        'min': 'minute', 'mins': 'minutes',"}
{"unnormalised": "", "normalised": "        'sec': 'second', 'secs': 'seconds',"}
{"unnormalised": "", "normalised": "        'volt': 'volt', 'volts': 'volts', 'v': 'volt',"}
{"unnormalised": "", "normalised": "        'amp': 'ampere', 'amps': 'amperes', 'a': 'ampere',"}
{"unnormalised": "", "normalised": "        'watt': 'watt', 'watts': 'watts', 'w': 'watt',"}
{"unnormalised": "", "normalised": "        'hz': 'hertz', 'khz': 'kilohertz', 'mhz': 'megahertz', 'ghz': 'gigahertz'"}
{"unnormalised": "", "normalised": "    }"}
{"unnormalised": "", "normalised": "    def replace_unit(match):"}
{"unnormalised": "", "normalised": "        number_str = match.group(1)"}
{"unnormalised": "", "normalised": "        unit = match.group(2).lower()"}
{"unnormalised": "", "normalised": "        spoken_number = convert_number_to_words(number_str)"}
{"unnormalised": "", "normalised": "        spoken_unit = unit_map.get(unit, unit)"}
{"unnormalised": "", "normalised": "        # Handle plurals for units"}
{"unnormalised": "", "normalised": "        if int(number_str) > 1 and not spoken_unit.endswith('s') and spoken_unit not in ['celsius', 'fahrenheit', 'kelvin']:"}
{"unnormalised": "", "normalised": "            spoken_unit += 's'"}
{"unnormalised": "", "normalised": "        elif int(number_str) == 1 and spoken_unit.endswith('s') and spoken_unit not in ['celsius', 'fahrenheit', 'kelvin']:"}
{"unnormalised": "", "normalised": "            spoken_unit = spoken_unit[:-1] # Remove 's' if number is 1 and unit is plural"}
{"unnormalised": "", "normalised": "        return f\"{spoken_number} {spoken_unit}\""}
{"unnormalised": "", "normalised": "    # Pattern for numbers directly followed by a unit (e.g., 10cm, 5kg)"}
{"unnormalised": "", "normalised": "    # Using \\b for units to avoid partial matches (e.g., 'm' in 'meter')"}
{"unnormalised": "", "normalised": "    unit_pattern = r'\\b(\\d+(?:\\.\\d+)?)\\s*(%s)\\b' % '|'.join(re.escape(u) for u in unit_map.keys())"}
{"unnormalised": "", "normalised": "    text = re.sub(unit_pattern, replace_unit, text, flags=re.IGNORECASE)"}
{"unnormalised": "", "normalised": "    # Handle degrees Celsius/Fahrenheit specifically, often written as 25°C"}
{"unnormalised": "", "normalised": "    def replace_degree_unit(match):"}
{"unnormalised": "", "normalised": "        number_str = match.group(1)"}
{"unnormalised": "", "normalised": "        unit = match.group(2).upper() # 'C', 'F'"}
{"unnormalised": "", "normalised": "        spoken_number = convert_number_to_words(number_str)"}
{"unnormalised": "", "normalised": "        unit_name = 'celsius' if unit == 'C' else 'fahrenheit' if unit == 'F' else 'kelvin' if unit == 'K' else ''"}
{"unnormalised": "", "normalised": "        return f\"{spoken_number} degree {unit_name}\""}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\b(\\d+(?:\\.\\d+)?)\\s*degree\\s*([CFK])\\b', replace_degree_unit, text, flags=re.IGNORECASE) # After 'degree' symbol is replaced"}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\b(\\d+(?:\\.\\d+)?)\\s*degree\\s*(celsius|fahrenheit|kelvin)\\b', lambda m: f\"{convert_number_to_words(m.group(1))} degree {m.group(2)}\", text, flags=re.IGNORECASE)"}
{"unnormalised": "", "normalised": "    # --- 3. Numbers → Spoken form (general) ---"}
{"unnormalised": "", "normalised": "    # Apply to any remaining standalone numbers. This should be late."}
{"unnormalised": "", "normalised": "    # Exclude numbers that are part of file names or mixed alphanumeric strings that don't look like numbers."}
{"unnormalised": "", "normalised": "    def replace_general_number(match):"}
{"unnormalised": "", "normalised": "        number_str = match.group(0)"}
{"unnormalised": "", "normalised": "        # Avoid converting numbers that are part of other identifiers (e.g., H2O, ID123)"}
{"unnormalised": "", "normalised": "        if re.match(r'^[A-Za-z]+$', number_str): # If it's pure alphabet, ignore"}
{"unnormalised": "", "normalised": "            return number_str"}
{"unnormalised": "", "normalised": "        "}
{"unnormalised": "", "normalised": "        # Avoid converting if it's a floating point number with only zero after decimal and num2words gives full stop"}
{"unnormalised": "", "normalised": "        if '.' in number_str and float(number_str) == int(float(number_str)):"}
{"unnormalised": "", "normalised": "            return convert_number_to_words(str(int(float(number_str))))"}
{"unnormalised": "", "normalised": "            "}
{"unnormalised": "", "normalised": "        return convert_number_to_words(number_str)"}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\b\\d+(?:\\.\\d+)?\\b', replace_general_number, text)"}
{"unnormalised": "", "normalised": "    # --- 8. Mathematical notation → Spoken form ---"}
{"unnormalised": "", "normalised": "    # Ensure this happens after general symbol/number conversions to avoid conflicts"}
{"unnormalised": "", "normalised": "    text = re.sub(r'(\\w)\\^2', r'\\1 squared', text)"}
{"unnormalised": "", "normalised": "    text = re.sub(r'(\\w)\\^3', r'\\1 cubed', text)"}
{"unnormalised": "", "normalised": "    text = re.sub(r'(\\w)\\^(\\w+)', r'\\1 to the power of \\2', text) # General power"}
{"unnormalised": "", "normalised": "    text = re.sub(r'(\\w)_(\\w+)', r'\\1 sub \\2', text) # Subscript"}
{"unnormalised": "", "normalised": "    text = re.sub(r'summation\\s*x\\s*sub\\s*i', 'summation of x sub i', text) # Common summation form"}
{"unnormalised": "", "normalised": "    text = re.sub(r'integral\\s*(\\d+)\\s*to\\s*(\\d+)\\s*of\\s*(\\w)\\s*d\\s*(\\w)',"}
{"unnormalised": "", "normalised": "                  lambda m: f\"integral from {convert_number_to_words(m.group(1))} to {convert_number_to_words(m.group(2))} of {m.group(3)} d {m.group(4)}\","}
{"unnormalised": "", "normalised": "                  text) # Specific integral form ∫ 0→1 x dx"}
{"unnormalised": "", "normalised": "    text = re.sub(r'integral\\s*(\\w)\\s*d\\s*(\\w)', r'integral of \\1 d \\2', text) # General integral form ∫ x dx"}
{"unnormalised": "", "normalised": "    # --- Final Space Normalization ---"}
{"unnormalised": "", "normalised": "    text = re.sub(r'\\s+', ' ', text).strip()"}
{"unnormalised": "", "normalised": "    return text"}
{"unnormalised": "", "normalised": "def process_folder(input_folder, output_folder):"}
{"unnormalised": "", "normalised": "    \"\"\""}
{"unnormalised": "", "normalised": "    Walks through the input folder, normalizes .txt files, and copies others."}
{"unnormalised": "", "normalised": "    \"\"\""}
{"unnormalised": "", "normalised": "    os.makedirs(output_folder, exist_ok=True)"}
{"unnormalised": "", "normalised": "    unnormalized_txt_files = []"}
{"unnormalised": "", "normalised": "    for root, dirs, files in os.walk(input_folder):"}
{"unnormalised": "", "normalised": "        relative_path = os.path.relpath(root, input_folder)"}
{"unnormalised": "", "normalised": "        current_output_dir = os.path.join(output_folder, relative_path)"}
{"unnormalised": "", "normalised": "        os.makedirs(current_output_dir, exist_ok=True)"}
{"unnormalised": "", "normalised": "        for file_name in files:"}
{"unnormalised": "", "normalised": "            input_file_path = os.path.join(root, file_name)"}
{"unnormalised": "", "normalised": "            output_file_path = os.path.join(current_output_dir, file_name)"}
{"unnormalised": "", "normalised": "            if file_name.lower().endswith('.txt'):"}
{"unnormalised": "", "normalised": "                try:"}
{"unnormalised": "", "normalised": "                    with open(input_file_path, 'r', encoding='utf-8') as f_in:"}
{"unnormalised": "", "normalised": "                        content = f_in.read()"}
{"unnormalised": "", "normalised": "                    "}
{"unnormalised": "", "normalised": "                    normalized_content = normalize_text(content)"}
{"unnormalised": "", "normalised": "                    with open(output_file_path, 'w', encoding='utf-8') as f_out:"}
{"unnormalised": "", "normalised": "                        f_out.write(normalized_content)"}
{"unnormalised": "", "normalised": "                except Exception as e:"}
{"unnormalised": "", "normalised": "                    print(f\"Error processing {input_file_path}: {e}\")"}
{"unnormalised": "", "normalised": "                    unnormalized_txt_files.append(input_file_path)"}
{"unnormalised": "", "normalised": "                    # If error, copy the original file to output"}
{"unnormalised": "", "normalised": "                    shutil.copy2(input_file_path, output_file_path)"}
{"unnormalised": "", "normalised": "            else:"}
{"unnormalised": "", "normalised": "                shutil.copy2(input_file_path, output_file_path)"}
{"unnormalised": "", "normalised": "    "}
{"unnormalised": "", "normalised": "    if unnormalized_txt_files:"}
{"unnormalised": "", "normalised": "        print(\"\\n--- List of .txt files that could not be normalized (original copied instead) ---\")"}
{"unnormalised": "", "normalised": "        for f in unnormalized_txt_files:"}
{"unnormalised": "", "normalised": "            print(f)"}
{"unnormalised": "", "normalised": "if __name__ == \"__main__\":"}
{"unnormalised": "", "normalised": "    # Example usage:"}
{"unnormalised": "", "normalised": "    # Create a dummy dataset structure for testing"}
{"unnormalised": "", "normalised": "    if not os.path.exists(\"dataset\"):"}
{"unnormalised": "", "normalised": "        os.makedirs(\"dataset/subfolder1\", exist_ok=True)"}
{"unnormalised": "", "normalised": "        os.makedirs(\"dataset/subfolder2\", exist_ok=True)"}
{"unnormalised": "", "normalised": "        with open(\"dataset/test1.txt\", \"w\", encoding=\"utf-8\") as f:"}
{"unnormalised": "", "normalised": "            f.write(\"The price is $20B. NASA launched in 1958. Approx ~5% gain.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"Today's date is 10/09/2024. Dr. Smith works for the U.S.A. government.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"The temperature is 25°C. Water boiled at 100°C. Total 5km run.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"The equation is 2+2=4. Area is πr^2. Sum is Σ x_i. Consider x^2 and x^3. Also x^n.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"The fraction is 3/4. We need 1/2 kg of sugar. The report covers QA/Dev and art/craft. GDP growth is strong. Adv. Ram is here.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"Math: ∫ x^2 dx. Or ∫ 0→1 x dx. If x != y, then x <= z or z >= x. He runs 100M dash.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"He ran 10km in 45 min. His speed was 100km/hr. The battery is 12V and 50A.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"Product IDs: PROD123, PROD456.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"₹500M was invested. The value is 99. The number is 7.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"This has a decimal 12.5 kg. A total of 1.0 M people. Test 1.0 kg and 1.00 kg.\\n\")"}
{"unnormalised": "", "normalised": "        with open(\"dataset/subfolder1/test2.txt\", \"w\", encoding=\"utf-8\") as f:"}
{"unnormalised": "", "normalised": "            f.write(\"Project Alpha started 2023-12-01. Prof. Jones gave a lecture on ∫ x^n dx.\\n\")"}
{"unnormalised": "", "normalised": "            f.write(\"He spent 2.5 hrs studying. The data is 1.2M records. He earns 50K per month.\\n\")"}
{"unnormalised": "", "normalised": "        with open(\"dataset/subfolder2/image.jpg\", \"w\", encoding=\"utf-8\") as f:"}
{"unnormalised": "", "normalised": "            f.write(\"This is not a text file.\") # Dummy content for non-txt file"}
{"unnormalised": "", "normalised": "        with open(\"dataset/subfolder2/another.txt\", \"w\", encoding=\"utf-8\") as f:"}
{"unnormalised": "", "normalised": "            f.write(\"Special characters: ≠, ≤, ≥. Test approximately five percent ~5%. Hash #tag. At @user. And & more.\")"}
{"unnormalised": "", "normalised": "    input_data_folder = \"dataset\""}
{"unnormalised": "", "normalised": "    output_normalized_folder = \"dataset_normalized\""}
{"unnormalised": "", "normalised": "    print(f\"Starting normalization for '{input_data_folder}' into '{output_normalized_folder}'...\")"}
{"unnormalised": "", "normalised": "    process_folder(input_data_folder, output_normalized_folder)"}
{"unnormalised": "", "normalised": "    print(\"Normalization complete.\")"}
{"unnormalised": "", "normalised": "    # --- Verification ---"}
{"unnormalised": "", "normalised": "    print(\"\\n--- Verifying a sample normalized file ---\")"}
{"unnormalised": "", "normalised": "    try:"}
{"unnormalised": "", "normalised": "        with open(os.path.join(output_normalized_folder, \"test1.txt\"), 'r', encoding='utf-8') as f:"}
{"unnormalised": "", "normalised": "            print(f.read())"}
{"unnormalised": "", "normalised": "    except FileNotFoundError:"}
{"unnormalised": "", "normalised": "        print(\"Sample normalized file 'test1.txt' not found in output folder.\")"}
{"unnormalised": "", "normalised": "```"}
{"unnormalised": "", "normalised": "**Explanation and Design Choices:**"}
{"unnormalised": "", "normalised": "1.  **`num2words` Library:** This is a crucial dependency for natural number conversion. Make sure to install it: `pip install num2words`."}
{"unnormalised": "", "normalised": "2.  **Order of Operations:** The order of `re.sub` calls is critical."}
{"unnormalised": "", "normalised": "    *   **Specific Symbols First:** `+/-`, `!=`, `<=`, `>=` are handled before general symbols like `@`, `&` to ensure correct replacement."}
{"unnormalised": "", "normalised": "    *   **`/` Handling:** The `/` symbol has complex rules. It's handled in a specific order: fractions with units, then general fractions, then \"or\" between words, then \"slash\" for mixed cases. This cascade ensures the most appropriate meaning is applied."}
{"unnormalised": "", "normalised": "    *   **Dates:** Processed early to avoid `DD/MM/YYYY` being interpreted as fractions or just numbers."}
{"unnormalised": "", "normalised": "    *   **Currency + Number + Suffix:** This is a very specific pattern, so it's handled early."}
{"unnormalised": "", "normalised": "    *   **Numeric Suffixes:** Handled before general number conversion. `20K` should not become `twenty K` and then `twenty thousand`."}
{"unnormalised": "", "normalised": "    *   **Units:** Handled before general number conversion. `10cm` should not become `ten cm` then `ten centimeter`."}
{"unnormalised": "", "normalised": "    *   **Acronyms:** Handled after special prefixes and before general numbers to avoid misinterpretation. Exclusions are important."}
{"unnormalised": "", "normalised": "    *   **General Numbers:** Applied relatively late to catch any remaining digits that haven't been covered by more specific rules."}
{"unnormalised": "", "normalised": "    *   **Mathematical Notation:** Applied towards the end, as many math components (like `^`, `_`, `∫`, `Σ`, numbers) might have been touched by earlier symbol or number rules. The math-specific regex then ties them into spoken forms."}
{"unnormalised": "", "normalised": "3.  **Regular Expressions:**"}
{"unnormalised": "", "normalised": "    *   `\\b`: Word boundary is used extensively to match whole words/numbers and avoid partial replacements within other words or identifiers."}
{"unnormalised": "", "normalised": "    *   `(?:\\.\\d+)?`: Non-capturing group for optional decimal parts in numbers (e.g., `10` or `10.5`)."}
{"unnormalised": "", "normalised": "    *   `re.IGNORECASE`: Used for unit matching to catch `KG`, `kg`, etc."}
{"unnormalised": "", "normalised": "4.  **`convert_number_to_words` helper:** Wraps `num2words` and adds a simple check for decimal numbers to ensure they are handled gracefully (e.g., `12.5` becomes `twelve point five`). It also handles the case where `1.0` or `1.00` should simply be \"one\" not \"one point zero\"."}
{"unnormalised": "", "normalised": "5.  **Ordinal Numbers:** `num2words(day, to='ordinal')` is used for date conversion, ensuring \"tenth\", \"first\", etc."}
{"unnormalised": "", "normalised": "6.  **Error Handling:** A `try-except` block is included during file processing to catch potential `IOError` or other issues during normalization, logging the problematic files, and copying the original in such cases."}
{"unnormalised": "", "normalised": "7.  **`unicodedata`:** While not explicitly used for `normalize_text` in this version (as `re` handles most of it, and `unicodedata` is more for text canonicalization), it's a good tool to keep in mind for more advanced symbol handling if needed."}
{"unnormalised": "", "normalised": "8.  **Output Folder Mirroring:** `os.makedirs(output_folder, exist_ok=True)` and `os.path.relpath` correctly reconstruct the directory structure."}
{"unnormalised": "", "normalised": "This script should robustly handle the described normalization tasks. Remember to test it thoroughly with diverse input examples!"}
