{"unnormalised": "ٹھیک ہے، تو کسی نے مجھ سے پوچھا کہ لینیئر الجبرا کتنا اہم ہے، خاص طور پر اگر آپ ڈیٹا سائنس جیسے شعبوں کو دیکھ رہے ہیں۔ تو، میرا یقین کرو، یہ بہت اہم ہے! آپ شاید سوچیں کہ کیلک 1، 2، اور 3 ریاضی کے مقدس ترین حصے ہیں، اور وہ بھی اہم ہیں، کوئی شک نہیں. لیکن مشین لرننگ کے بنیادی ریاضی کو سمجھنے کے لیے؟ لینیئر الجبرا آپ کا دوست ہے۔ یہ تقریباً 80% وہ ریاضی ہے جو آپ روزانہ استعمال کریں گے۔ اس اہم بنیاد کو مت چھوڑیں۔", "normalised": "ٹھیک ہے، تو کسی نے مجھ سے پوچھا کہ لینیئر الجبرا (Linear Algebra) کتنا اہم ہے، خاص طور پر اگر آپ ڈیٹا سائنس جیسے شعبوں کو دیکھ رہے ہیں۔ تو، میرا یقین کریں، یہ بہت ضروری ہے! آپ کو شاید لگتا ہو کہ کیلک (Calc) ون، ٹو، اور تھری ریاضی کے مقدس ترین حصے ہیں، اور وہ بھی اہم ہیں، اس میں کوئی شک نہیں۔ لیکن مشین لرننگ (Machine Learning) کی بنیاد میں موجود ریاضی کو سمجھنے کے لیے؟ لینیئر الجبرا آپ کا دوست ہے۔ یہ تقریباً اسی فیصد ریاضی ہے جو آپ روزانہ کی بنیاد پر استعمال کریں گے۔ اس اہم بنیاد کو مت چھوڑیں۔"}
{"unnormalised": "اس کے بارے میں سوچیں: ڈیٹا اکثر میٹرکس میں ترتیب دیا جاتا ہے۔ تصاویر کو پکسل ویلیوز کے میٹرکس کے طور پر پیش کیا جاتا ہے (مثال کے طور پر، ایک 256x256 تصویر)۔ مشین لرننگ کے لیے ڈیٹا سیٹس اکثر میٹرکس کے طور پر پیش کیے جاتے ہیں، جس میں قطاریں نمونوں کی نمائندگی کرتی ہیں اور کالم خصوصیات کی نمائندگی کرتے ہیں۔ لینیئر الجبرا ان میٹرکس کو جوڑنے اور تجزیہ کرنے کے لیے ٹولز فراہم کرتا ہے۔ میٹرکس ضرب، لینیئر مساوات کے نظام کو حل کرنا (جیسے Ax = b)، اور ایگین ویلیو ڈی کمپوزیشن جیسے آپریشنز مشین لرننگ الگورتھم کے لیے بنیادی ہیں۔ یہاں تک کہ گردش جیسی کوئی آسان چیز بھی میٹرکس استعمال کرتی ہے! آپ کو SVD اور PCA جیسی اصطلاحات کا سامنا ہو سکتا ہے۔ SVD، مثال کے طور پر، تصویر کو کمپریس کرنے اور تجویز کرنے والے نظاموں میں استعمال ہوتا ہے۔ PCA (پرنسپل کمپوننٹ اینالسس) جہت کو کم کرنے کے لیے استعمال ہوتا ہے، مثال کے طور پر 1000 جہتوں کو 10 تک لانا۔", "normalised": "اس بارے میں سوچیں: ڈیٹا کو اکثر میٹرکس (Matrices) میں منظم کیا جاتا ہے۔ تصاویر کو پکسل ویلیوز (Pixel Values) کے میٹرکس کے طور پر ظاہر کیا جاتا ہے (مثال کے طور پر، دو سو چھپن ضرب دو سو چھپن کی تصویر)۔ مشین لرننگ کے لیے ڈیٹا سیٹس (Datasets) کو اکثر میٹرکس کے طور پر ظاہر کیا جاتا ہے، جس میں قطاریں نمونوں (Samples) کی نمائندگی کرتی ہیں اور کالم خصوصیات (Features) کی نمائندگی کرتے ہیں۔ لینیئر الجبرا ان میٹرکس کو جوڑنے اور تجزیہ کرنے کے لیے اوزار فراہم کرتا ہے۔ میٹرکس ضرب (Matrix Multiplication)، لینیئر مساوات کے نظام کو حل کرنا (جیسے A x برابر ہے b کے)، اور آئیگن ویلیو ڈی کمپوزیشن (Eigenvalue Decomposition) جیسے آپریشن مشین لرننگ الگورتھمز کے لیے بنیادی ہیں۔ یہاں تک کہ کوئی سادہ سی چیز جیسے گردش (Rotation) بھی میٹرکس استعمال کرتی ہے! آپ کو شاید ایس-وی-ڈی (S-V-D) اور پی-سی-اے (P-C-A) جیسی اصطلاحات ملیں۔ ایس-وی-ڈی، مثال کے طور پر، امیج کمپریشن (Image Compression) اور ریکمینڈر سسٹمز (Recommender Systems) میں استعمال ہوتا ہے۔ پی-سی-اے (پرنسپل کمپوننٹ اینالیسس - Principal Component Analysis) جہتی تخفیف (Dimensionality Reduction) کے لیے استعمال ہوتا ہے، مثال کے طور پر ایک ہزار جہتوں کو دس تک کم کرنا۔"}
{"unnormalised": "تو ہاں، لینیئر الجبرا صرف ایک تجریدی ریاضی کا کورس نہیں ہے۔ یہ آپ کو وہ مہارتیں فراہم کرتا ہے جن سے آپ اصل میں _سمجھ_ سکتے ہیں کہ مشین لرننگ ماڈلز کیسے کام کرتے ہیں۔ صرف مساوات کو یاد رکھنا بھول جائیں، آپ لینیئر الجبرا سے چیزیں بنا سکتے ہیں۔ اگر آپ AI/ML کے بارے میں سنجیدہ ہیں، تو اسے صحیح طریقے سے سیکھنے میں وقت لگائیں۔ آپ کو پچھتاوا نہیں ہوگا! سنجیدگی سے، اپنی کلاس سے اپنے نوٹس پر واپس جائیں یا شاید MIT 18.06 لیکچرز جیسے ذرائع سے جائزہ لیں۔ آپ کو بنیادی تصورات کو سمجھنے اور عملی طور پر ان کا اطلاق کرنے کے قابل ہونے کی ضرورت ہے۔", "normalised": "تو ہاں، لینیئر الجبرا صرف کوئی تجریدی ریاضی کا کورس نہیں ہے۔ یہ آپ کو یہ مہارتیں فراہم کرتا ہے کہ آپ اصل میں سمجھ سکیں کہ مشین لرننگ ماڈلز کیسے کام کرتے ہیں۔ صرف مساوات کو یاد کرنا بھول جائیں، آپ لینیئر الجبرا سے چیزیں بنا سکتے ہیں۔ اگر آپ اے-آئی (A-I) یا ایم-ایل (M-L) کے بارے میں سنجیدہ ہیں، تو اسے صحیح طریقے سے سیکھنے میں وقت لگائیں۔ آپ کو پچھتاوا نہیں ہوگا! سنجیدگی سے، اپنی کلاس کے نوٹس پر واپس جائیں یا ایم-آئی-ٹی (M-I-T) اٹھارہ اعشاریہ صفر چھ لیکچرز (Lectures) جیسے وسائل سے جائزہ لیں۔ آپ کو بنیادی تصورات کو سمجھنے اور انہیں عملی طور پر لاگو کرنے کے قابل ہونے کی ضرورت ہے۔"}
