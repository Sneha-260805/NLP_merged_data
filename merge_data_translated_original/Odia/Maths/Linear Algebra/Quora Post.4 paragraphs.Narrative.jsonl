{"unnormalised": "ମୋର ମନେ ଅଛି IIT ଦିଲ୍ଲୀରେ ଇଞ୍ଜିନିୟରିଂ ପଢ଼ିବା ସମୟରେ ମୁଁ ଲିନିୟର ଆଲଜେବ୍ରା ଦେଖି ସମ୍ପୂର୍ଣ୍ଣ ଭାବେ ବାଟବଣା ହୋଇ ଯାଇଥିଲି। ପ୍ରଫେସର ଶର୍ମା Eigenvectors ଏବଂ Eigenvalues ବିଷୟରେ କିଛି ବୁଝାଉଥିଲେ, ଏବଂ ମୁଁ କେବଳ ଏତିକି ଭାବୁଥିଲି, \"ୟେ କ୍ୟା ହୋ ରହା ହୈ?!\" ଏହା ଏକ ସମ୍ପୂର୍ଣ୍ଣ ଭିନ୍ନ ଭାଷା ପରି ଲାଗୁଥିଲା। ପ୍ରଥମ କୁଇଜରେ ମୋର ନମ୍ବର ଲଜ୍ଜାଜନକ ଭାବେ କମ୍ ଥିଲା - ୬/୨୦!", "normalised": "ମୋର ମନେ ଅଛି, ଆଇ-ଆଇ-ଟି ଦିଲ୍ଲୀରେ ଇଞ୍ଜିନିୟରିଂ ପଢ଼ିବା ସମୟରେ ମୁଁ ଲିନିୟର ଆଲଜେବ୍ରା ଦ୍ୱାରା ସମ୍ପୂର୍ଣ୍ଣ ଭାବେ ବାଧାପ୍ରାପ୍ତ ହୋଇଥିଲି। ପ୍ରଫେସର ଶର୍ମା କିଛି ଇଗେନଭେକ୍ଟର ଏବଂ ଇଗେନମୂଲ୍ୟ ବିଷୟରେ ବୁଝାଉଥିଲେ, ଏବଂ ମୁଁ କେବଳ ଭାବୁଥିଲି, \"ୟେ କ୍ୟା ହୋ ରହା ହୈ?!\" ଏହା ଏକ ସମ୍ପୂର୍ଣ୍ଣ ଭିନ୍ନ ଭାଷା ପରି ଲାଗୁଥିଲା। ପ୍ରଥମ କୁଇଜରେ ମୋର ମାର୍କ ଅତ୍ୟନ୍ତ ନିମ୍ନ ଥିଲା - କୋଡ଼ିଏରୁ ଛଅ ଭାଗ!"}
{"unnormalised": "କିନ୍ତୁ ପ୍ରକୃତରେ ଯାହା ମୋତେ ସାହାଯ୍ୟ କଲା, ତାହା ହେଉଛି ବ୍ୟାବହାରିକ ପ୍ରୟୋଗ ଉପରେ ଧ୍ୟାନ ଦେବା। କେବଳ ଫର୍ମୁଲା ମନେ ରଖିବା ପରିବର୍ତ୍ତେ, ମୁଁ ଏହି ଧାରଣାଗୁଡ଼ିକ *କାହିଁକି* ଗୁରୁତ୍ୱପୂର୍ଣ୍ଣ ତାହା ବୁଝିବାକୁ ଚେଷ୍ଟା କଲି। ଉଦାହରଣ ସ୍ୱରୂପ, ପ୍ରିନ୍ସିପାଲ କମ୍ପୋନେଣ୍ଟ ଆନାଲିସିସ୍ (PCA) ଡାଟାର ଡାଇମେନ୍ସନାଲିଟି କମ୍ କରିବା ପାଇଁ eigenvectors ବ୍ୟବହାର କରେ। ଏହା ବିଷୟରେ ଚିନ୍ତା କରନ୍ତୁ: ଇମେଜ୍ କମ୍ପ୍ରେସନ୍! ତାହା କାର୍ଯ୍ୟରେ ଲିନିୟର ଆଲଜେବ୍ରା ଅଟେ। ମୁଁ ଘଣ୍ଟା ଘଣ୍ଟା ଧରି ଖାନ୍ ଏକାଡେମୀ ଏବଂ MIT ଓପନ୍‌କୋର୍ସୱେୟାର ପରି ସାଇଟ୍‌ରେ ବିତାଇଲି, ଯେଉଁଠାରେ ଜଟିଳ ଗଣିତକୁ ସରଳ ଭାବରେ ବୁଝାଯାଇଥିଲା। ମୁଁ ଏକ ଭିଜୁଆଲାଇଜର ମଧ୍ୟ ପାଇଲି ଯାହା ଦେଖାଉଥିଲା କିପରି ମାଟ୍ରିକ୍ସ ଗୁଣନ ଭେକ୍ଟରଗୁଡିକୁ ରିଅଲ୍-ଟାଇମରେ ରୂପାନ୍ତର କରେ - ଏହା ପ୍ରକୃତରେ ମୋର ଅନୁଭୂତିକୁ ସାହାଯ୍ୟ କଲା।", "normalised": "କିନ୍ତୁ ଯାହା ପ୍ରକୃତରେ ମୋତେ ସାହାଯ୍ୟ କଲା, ତାହା ହେଉଛି ବ୍ୟାବହାରିକ ପ୍ରୟୋଗ ଉପରେ ଧ୍ୟାନ ଦେବା। କେବଳ ଫର୍ମୁଲା ମନେ ରଖିବା ପରିବର୍ତ୍ତେ, ମୁଁ ବୁଝିବାକୁ ଚେଷ୍ଟା କଲି ଯେ ଏହି ଧାରଣାଗୁଡ଼ିକ କାହିଁକି ଗୁରୁତ୍ୱପୂର୍ଣ୍ଣ। ଉଦାହରଣ ସ୍ୱରୂପ, ପ୍ରିନ୍ସିପାଲ କମ୍ପୋନେଣ୍ଟ ଆନାଲିସିସ (ପି-ସି-ଏ) ଡାଟାର ଡାଇମେନ୍ସନାଲିଟି ହ୍ରାସ କରିବା ପାଇଁ ଇଗେନଭେକ୍ଟର ବ୍ୟବହାର କରେ। ଏହା ବିଷୟରେ ଚିନ୍ତା କର: ଇମେଜ କମ୍ପ୍ରେସନ! ଏହା କାର୍ଯ୍ୟରେ ଥିବା ଲିନିୟର ଆଲଜେବ୍ରା। ମୁଁ ଘଣ୍ଟା ଘଣ୍ଟା ଖାନ ଏକାଡେମୀ ଏବଂ ଏମ-ଆଇ-ଟି ଓପନକୋର୍ସୱେୟାର ପରି ସାଇଟରେ ବିତାଇଲି, ଯେଉଁଥିରେ ଜଟିଳ ଗଣିତକୁ ଛୋଟ ଛୋଟ ଭାଗରେ ଭାଙ୍ଗି ଦିଆଯାଇଥିଲା। ମୁଁ ଏକ କୁଲ ଭିଜୁଆଲାଇଜର ମଧ୍ୟ ପାଇଲି ଯାହା ଦେଖାଇଲା ଯେ ମାଟ୍ରିକ୍ସ ଗୁଣନ କିପରି ରିଅଲ-ଟାଇମରେ ଭେକ୍ଟରଗୁଡ଼ିକୁ ରୂପାନ୍ତର କରେ - ପ୍ରକୃତରେ ମୋର ଅନୁଭୂତିକୁ ସାହାଯ୍ୟ କଲା।"}
{"unnormalised": "ତା’ପରେ, ମୁଁ ଅନେକ ସମସ୍ୟା ଉପରେ କାମ କରିବା ଆରମ୍ଭ କଲି। କେବଳ ପାଠ୍ୟପୁସ୍ତକର ସମସ୍ୟା ନୁହେଁ, ପୁରୁଣା GATE ପରୀକ୍ଷାର ସମସ୍ୟା ମଧ୍ୟ (ଯାହାକି, BTW, ଏକ ବଡ଼ ସାହାଯ୍ୟକାରୀ)। ମୁଁ ଯେତେ ଅଧିକ ଅଭ୍ୟାସ କଲି, ଧାରଣାଗୁଡ଼ିକ ସେତେ ଅଧିକ ସ୍ପଷ୍ଟ ହେବାକୁ ଲାଗିଲା। ମୁଁ ଅନୁଭବ କଲି ଯେ determinants ଏବଂ matrix inverses କେବଳ ସମୀକରଣର ସମାଧାନ ପାଇଁ ଉପକରଣ ଅଟନ୍ତି। ୧୦୦ଟି ସମସ୍ୟା ସମାଧାନ କର ଏବଂ ତୁରନ୍ତ ଅନ୍ଧକାର ଦୂର ହୋଇଯିବ। ମୋର ମିଡଟର୍ମ ସ୍କୋର ୧୭/୨୦କୁ ବୃଦ୍ଧି ପାଇଲା!", "normalised": "ତା’ପରେ, ମୁଁ ଟନ୍ସ ଅଫ୍ ସମସ୍ୟା ସମାଧାନ କରିବା ଆରମ୍ଭ କଲି। କେବଳ ପାଠ୍ୟପୁସ୍ତକ ନୁହେଁ, ବରଂ ପୁରୁଣା ଜି-ଏ-ଟି-ଇ ପରୀକ୍ଷାରୁ ମଧ୍ୟ ସମସ୍ୟା ସମାଧାନ କଲି (ଯାହାକି, ଉଲ୍ଲେଖ କରିବାକୁ ଗଲେ, ଏକ ମହାନ ଉତ୍ସ)। ମୁଁ ଯେତେ ଅଧିକ ଅଭ୍ୟାସ କଲି, ଧାରଣାଗୁଡ଼ିକ ସେତେ ଅଧିକ ସ୍ପଷ୍ଟ ହେବାକୁ ଲାଗିଲା। ମୁଁ ଅନୁଭବ କଲି ଯେ ଡିଟରମିନାଣ୍ଟ ଏବଂ ମାଟ୍ରିକ୍ସ ଇନଭର୍ସ ପରି ଜିନିଷଗୁଡ଼ିକ କେବଳ ସମୀକରଣର ସିଷ୍ଟମଗୁଡ଼ିକୁ ସମାଧାନ କରିବାର ଉପକରଣ। ଶହେ ସମାଧାନ କର ଏବଂ ହଠାତ୍ କୁହୁଡ଼ି ଦୂର ହୋଇଯିବ। ମୋର ମିଡଟର୍ମ ସ୍କୋର କୋଡ଼ିଏରୁ ସତରକୁ ବୃଦ୍ଧି ପାଇଲା!"}
{"unnormalised": "ଅବଶେଷରେ, ଲିନିୟର ଆଲଜେବ୍ରା ମୋର ଶତ୍ରୁ ହେବା ପରିବର୍ତ୍ତେ ମୋର ପ୍ରିୟ ବିଷୟ ମଧ୍ୟରୁ ଗୋଟିଏ ହୋଇଗଲା। ଏହା ସବୁ ସଂଯୋଗଗୁଡ଼ିକୁ ଦେଖିବା ଏବଂ ମୂଳ ନିୟମଗୁଡ଼ିକୁ ବୁଝିବା ବିଷୟରେ ଅଟେ। ଯଦି ମୁଁ କୌଣସି ପରାମର୍ଶ ଦେଇପାରେ, ତାହା ହେଉଛି: ହାର ମାନନ୍ତୁ ନାହିଁ! ଅଭ୍ୟାସ ଜାରି ରଖନ୍ତୁ, ପ୍ରଶ୍ନ ପଚାରିବା ଜାରି ରଖନ୍ତୁ, ଏବଂ ଆପଣ ନିଶ୍ଚୟ ସଫଳ ହେବେ। ଏବଂ ମନେ ରଖନ୍ତୁ, ପ୍ରଫେସର ଶର୍ମା ମଧ୍ୟ କେଉଁଠାରୁ ଆରମ୍ଭ କରିଥିଲେ। ତୁମେ କରିପାରିବ!", "normalised": "ଅବଶେଷରେ, ଲିନିୟର ଆଲଜେବ୍ରା ମୋର ଶତ୍ରୁ ହେବାରୁ ମୋର ପ୍ରିୟ ବିଷୟ ମଧ୍ୟରୁ ଗୋଟିଏ ହୋଇଗଲା। ଏହା ସବୁ ସଂଯୋଗ ଦେଖିବା ଏବଂ ଅନ୍ତର୍ନିହିତ ନୀତିଗୁଡ଼ିକୁ ବୁଝିବା ବିଷୟରେ। ଯଦି ମୁଁ ଗୋଟିଏ ଉପଦେଶ ଦେଇପାରିବି, ତାହା ହେଉଛି: ହାର ମାନନ୍ତୁ ନାହିଁ! ଅଭ୍ୟାସ ଜାରି ରଖନ୍ତୁ, ପ୍ରଶ୍ନ ପଚାରିବା ଜାରି ରଖନ୍ତୁ, ଏବଂ ଆପଣ ନିଶ୍ଚୟ ସଫଳ ହେବେ। ଏବଂ ମନେ ରଖନ୍ତୁ, ପ୍ରଫେସର ଶର୍ମା ମଧ୍ୟ କେଉଁଠାରୁ ଆରମ୍ଭ କରିଥିଲେ। ତୁମେ ଏହା କରିପାରିବ!"}
