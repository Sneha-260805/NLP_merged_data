{"unnormalised": "प्रतिष्ठित आयआयटी दिल्ली येथे एका आश्चर्यकारक घटनेत, गणित विषयात पीएचडी करत असलेल्या रोहन शर्मा नावाच्या विद्यार्थ्याने एक पूर्वीचे न सुटलेले समीकरण कथितरित्या \"सोडवले\" आहे. ही घटना १२/१०/२०२४ रोजी उशिरा घडली, ज्यामुळे शैक्षणिक क्षेत्रात उत्साह आणि आश्चर्याची लाट पसरली आहे. शर्मा प्रगत बीजगणितीय भूमितीशी संबंधित आपल्या प्रबंधावर काम करत असताना, काही अत्यंत क्लिष्ट लॅटेक्स कोडमध्ये फेरफार करताना त्याला एक सरळ सोपा उपाय सापडला.", "normalised": "प्रतिष्ठित आय-आय-टी दिल्लीमध्ये एका आश्चर्यकारक घटनेत, रोहन शर्मा नावाच्या गणित विषयांतील पी-एच-डीच्या विद्यार्थ्याने कथितरित्या एक पूर्वीचे न सुटलेले समीकरण \"सोडवले\" आहे. ही घटना १२ ऑक्टोबर, दोन हजार चोवीस रोजी उशिरा घडली, ज्यामुळे शैक्षणिक समुदायात उत्साह आणि अविश्वास निर्माण झाला आहे. शर्मा प्रगत बीजगणितीय भूमितीशी संबंधित आपल्या प्रबंधावर काम करत असताना, काही अत्यंत क्लिष्ट एल-ए-टी-ई-एक्स कोडमध्ये फेरफार करताना त्याला एक सोपा उपाय सापडला."}
{"unnormalised": "\"रात्रीचे सुमारे ११ वाजले होते, चहा घेतल्यानंतर,\" शर्माने आमच्या बातमीदाराला सांगितले. \"मी एका विशेषतः किचकट समीकरणाच्या लॅटेक्स रेंडरिंगशी झगडत होतो - ज्यामध्ये इंटिग्रल्स आणि समेशन्सचा समावेश होता, ज्याला `\\int_{a}^{b} f(x) dx + \\sum_{i=1}^{n} a_i` असे कोड केले होते. मी त्याचे अलाइनमेंट बरोबर करण्याचा प्रयत्न करत होतो, आणि मग ते अचानक... क्लिक झाले.\" हे समीकरण, ज्याला लॅटेक्समध्ये `\\frac{d}{dx} (x^2 + 2x + 1) = 2x + 2` असे दर्शविले जाते, त्याने दशकानुदशके गणितज्ञांना गोंधळात पाडले होते, याचे मुख्य कारण म्हणजे त्याच्या पहिल्या स्वरूपाच्या मूळ प्रकाशनात असलेली एक अस्पष्ट टायपोग्राफिकल चूक.", "normalised": "\"रात्रीचे सुमारे अकरा वाजले होते, चहाच्या ब्रेकनंतर,\" शर्माने आमच्या बातमीदाराला सांगितले. \"मी एका विशेषतः किचकट समीकरणाच्या एल-ए-टी-ई-एक्स रेंडरिंगशी झगडत होतो - ज्यामध्ये इंटिग्रल्स आणि समेशन्स (integrals and summations) समाविष्ट होते, ज्याला a ते b पर्यंत इंटिग्रल f ऑफ x d x अधिक i बरोबर एक ते n पर्यंत a सब i असे कोड केले होते. मी अलाइनमेंट योग्य करण्याचा प्रयत्न करत होतो, आणि मग ते अचानक... क्लिक झाले.\" एल-ए-टी-ई-एक्स मध्ये d भागिले d x ऑफ x स्क्वेअरड प्लस टू x प्लस वन इक्वल्स टू x प्लस टू (d divided by d x of x squared plus two x plus one equals two x plus two) असे दर्शविलेले समीकरण अनेक दशकांपासून गणितज्ञांना गोंधळात टाकत होते, याचे मुख्य कारण म्हणजे त्याच्या मूळ स्वरूपाच्या पहिल्या प्रकाशनातील एक अस्पष्ट टायपोग्राफिकल त्रुटी होती."}
{"unnormalised": "शर्माचे मार्गदर्शक प्राध्यापक मीरा अय्यर यांनी हा शोध लागल्याची पुष्टी केली. \"रोहनने मला त्याचे काम दुसऱ्या दिवशी सकाळी दाखवले. सुरुवातीला मला शंका आली. हे समीकरण, `E=mc^2` ने दर्शविल्याप्रमाणे, एका जुन्या मित्रासारखे होते - निराशाजनकपणे न सुटणारे, पण परिचित. पण त्याची पद्धत, लॅटेक्स रेंडरिंगची एक चतुर हाताळणी, निर्णायक ठरली.\" अय्यर यांच्या म्हणण्यानुसार, शर्माने टायपोग्राफिकलErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorErrorError", "normalised": "शर्माच्या मार्गदर्शिका प्राध्यापक मीरा अय्यर यांनी हा शोध নিশ্চিত केला. \"रोहनने त्याचे काम मला दुसऱ्या दिवशी सकाळी दाखवले. सुरुवातीला, मला शंका आली. E इक्वल्स m c स्क्वेअरड (E equals m c squared) द्वारे दर्शविलेले समीकरण एका जुन्या मित्रासारखे होते – निराशाजनकपणे न सुटणारे, पण परिचित. पण त्याची पद्धत, एल-ए-टी-ई-एक्स रेंडरिंगची एक चतुर हाताळणी, हीच गुरुकिल्ली ठरली.\" अय्यर यांच्या म्हणण्यानुसार, शर्माने टायपोग्राफिकल त्रुटी \"पाहण्यासाठी\" एल-ए-टी-ई-एक्स इंजिनमधील पूर्वी अज्ञात असलेल्या एका वैशिष्ट्याचा उपयोग केला, ज्यामुळे योग्य उपाय उघड झाला."}
{"unnormalised": "", "normalised": "शर्माच्या शोधाचे दूरगामी परिणाम आहेत. यामुळे केवळ दशकांपासूनचे गणिताचे कोडे सुटले नाही, तर आंतरdisciplinary विचारसरणीचे महत्त्व देखील अधोरेखित होते. \"कोणाला वाटले असेल,\" प्राध्यापक अय्यर हसून म्हणाल्या, \"एका जटिल गणिताच्या समस्येचे समाधान एल-ए-टी-ई-एक्स कोडच्या आत लपलेले असेल, जे मॅट्रिक्स a b c d एंड मॅट्रिक्स (matrix a b c d end matrix) सारखे दिसत होते?\""}
{"unnormalised": "", "normalised": "विद्यापीठाने शर्माचे निष्कर्ष एका अग्रगण्य गणितीय জার্নলে प्रकाशित करण्याची योजना आखली आहे, ज्यामध्ये एल-ए-टी-ई-एक्स-संबंधित उपायाचे स्पष्टीकरण देणारा एक समर्पित विभाग असेल. शर्मा यांच्या यशाचा सन्मान करण्यासाठी ২৬ जानेवारी, दोन हजार पंचवीस रोजी, भारताच्या प्रजासत्ताक दिनी एका भव्य सोहळ्याचे आयोजन करण्यात आले आहे, ज्यासाठी ५० हजार रुपयांचे बजेट अपेक्षित आहे. या कार्यक्रमात समीकरणाच्या उपायाचे थेट प्रदर्शन, उत्कृष्ट এল-এ-টি-ई-এক্স मध्ये सादर केले जाईल, अशी अफवा आहे."}
