{"unnormalised": "अरे मित्रांनो, लीनियर अल्जेब्राबद्दल (Linear Algebra) एक छोटा प्रश्न आहे. मी एका परीक्षेची तयारी करत आहे आणि एका गोष्टीमध्ये अडकलो आहे. मॅट्रिक्स ट्रान्सफॉर्मेशन (matrix transformations) व्यतिरिक्त, प्रत्यक्ष जगात आयगेनव्हॅल्यूज (eigenvalues) आणि आयगेनव्हेक्टर्सचा (eigenvectors) उपयोग कसा करतात? माझ्या पाठ्यपुस्तकात फक्त सैद्धांतिक उदाहरणे आहेत, पण मला हे जाणून घ्यायचे आहे की हे (linear algebra) कुठे उपयुक्त आहे. सिग्नल प्रोसेसिंगमध्ये (signal processing) किंवा अगदी एआयमध्ये (AI) याचा वापर होतो का? साधे स्पष्टीकरण किंवा उदाहरणे खूप उपयुक्त ठरतील!", "normalised": "मित्रांनो, लीनियर अलजेब्राबद्दल एक साधा प्रश्न आहे. मी परीक्षेची तयारी करत आहे आणि एका गोष्टीमध्ये अडकलो आहे. मॅट्रिक्स ट्रान्सफॉर्मेशन व्यतिरिक्त, खरंचEigenvalues आणि Eigenvectors वास्तविक जगात कसे वापरायचे? माझ्या पाठ्यपुस्तकात फक्त सैद्धांतिक उदाहरणे आहेत, पण मला हे जाणून घ्यायचे आहे की हे कुठे उपयुक्त आहे, तुम्हाला माहीत आहे? विचार करा, ते सिग्नल प्रोसेसिंगमध्ये किंवा कदाचित ए-आय मध्ये वापरले जाते का? कोणतीही सोपी स्पष्टीकरणे किंवा उदाहरणे खूप उपयुक्त ठरतील!"}
{"unnormalised": "मला आठवतंय, आपले प्रोफेसर, डॉ. वर्मा यांनी गुगलच्या (Google) ओरिजनल (original) पेज रँक (pagerank) अल्गोरिदममध्ये (algorithm) याचा वापर करण्याबद्दल काहीतरी सांगितलं होतं. मला वाटतं ते वेबच्या (web) लिंक स्ट्रक्चरचे (link structure) प्रतिनिधित्व करणाऱ्या एका मोठ्या मॅट्रिक्सच्या (matrix) आयगेनव्हेक्टरवर (eigenvector) आधारित होतं. सर्वात मोठ्या आयगेनव्हॅल्यूजचा (eigenvalues) आयगेनव्हेक्टर (eigenvector) तुम्हाला प्रत्येक पेजसाठी महत्त्वाचा स्कोअर (score) देतो. खूप छान आहे, नाही का? जवळजवळ जादूच वाटते, हा हा. लीनियर अल्जेब्रामध्ये (linear algebra) आणखी कोणत्या छान युक्त्या लपलेल्या आहेत, हे जाणून घ्यायला आवडेल.", "normalised": "तर, मला आठवतंय, आपले प्राध्यापक, डॉक्टर वर्मा, यांनी पेज रँक अल्गोरिदममध्ये, Google च्या मूळ अल्गोरिदममध्ये याचा उपयोग करण्याबद्दल काहीतरी सांगितले होते. मला वाटतं ते वेबच्या लिंक स्ट्रक्चरचे प्रतिनिधित्व करणार्‍या एका मोठ्या मॅट्रिक्सच्या eigenvectors वर आधारित होते. सर्वात मोठ्या eigenvalue असलेला eigenvector तुम्हाला प्रत्येक पेजसाठी महत्त्वाचा स्कोअर देतो. खूप छान आहे, नाही का? जवळजवळ जादू असल्यासारखे वाटते, हा हा. लीनियर अलजेब्रामध्ये आणखी कोणत्या युक्त्या दडलेल्या आहेत, असा प्रश्न पडतो."}
{"unnormalised": "मी आणखी एक ॲप्लिकेशन (application) कुठेतरी पाहिलं होत, ते इंजिनीअरिंग सिस्टीममधील (engineering system) स्टॅबिलिटी ॲनालिसिसशी (stability analysis) संबंधित होत. उदाहरणार्थ, तुमच्याकडे डिफरेंशियल इक्वेशनने (differential equations) दर्शविलेली सिस्टीम (system) असल्यास, सिस्टीम स्थिर आहे की नाही हे निर्धारित करण्यासाठी तुम्ही सिस्टीमच्या (system) मॅट्रिक्सच्या (matrix) आयगेनव्हॅल्यूजचा (eigenvalues) वापर करू शकता. जर सर्व आयगेनव्हॅल्यूजचे (eigenvalues) रिअल पार्टस (real parts) निगेटिव्ह (negative) असतील, तर ती सिस्टीम (system) स्थिर असते. जर तुम्हाला कॅपेसिटर (capacitors) (C= 10μF), इंडक्टर (inductors) (L = 5mH), आणि रेझिस्टरसह (resistors) (R=10 Ohms) इलेक्ट्रिकल सर्किटचे (electrical circuits) मॉडेल (model) बनवायचे असेल, तर आयगेनव्हॅल्यूज (eigenvalues) शोधणे तुम्हाला सर्किट ऑसिलेट (oscillate) होते की क्षीण होते हे समजून घेण्यास मदत करते.", "normalised": "मला दुसरी एक गोष्ट अभियांत्रिकी प्रणालीतील स्थिरता विश्लेषणाशी संबंधित दिसली. जसे की, तुमच्याकडे डिफरेंशियल समीकरणांद्वारे वर्णन केलेली प्रणाली असल्यास, तुम्ही प्रणाली स्थिर आहे की नाही हे निर्धारित करण्यासाठी प्रणालीच्या मॅट्रिक्सचे eigenvalues वापरू शकता. जर सर्व eigenvalues चे वास्तव भाग नकारात्मक असतील, तर प्रणाली स्थिर असते. जर तुम्हाला कॅपेसिटर (C = 10 microfarad), इंडक्टर (L = 5 millihenry) आणि रेझिस्टर (R = 10 Ohms) असलेले इलेक्ट्रिकल सर्किट मॉडेल करायचे असेल, तर eigenvalues शोधणे तुम्हाला सर्किट दोलन करते की क्षीण होते हे समजून घेण्यास मदत करते."}
{"unnormalised": "आणि हो, निश्चितपणे एआय (AI) मध्ये. आयगेनव्हॅल्यूज (eigenvalues) आणि आयगेनव्हेक्टर्स (eigenvectors) डायमेन्शनॅलिटी रिडक्शन (dimensionality reduction) तंत्र जसे की प्रिन्सिपल कंपोनंट ॲनालिसिसमध्ये (Principal Component Analysis (PCA)) मोठी भूमिका बजावतात. कल्पना करा की तुम्ही चेहऱ्यांच्या इमेजच्या (image) डेटासेटसारख्या (dataset) भरपूर वैशिष्ट्यांसह (features) डेटासेटवर (dataset) काम करत आहात. प्रत्येक इमेजमध्ये (image) 1000 वैशिष्ट्ये (features) (1000 पिक्सेल) आहेत, तुम्ही तुमच्या डेटाच्या (data) कोव्हेरिएन्स मॅट्रिक्सच्या (covariance matrix) सर्वात मोठ्या आयगेनव्हॅल्यूजशी (eigenvalues) संबंधित \"प्रिन्सिपल कंपोनंट्स\" (principal components) शोधण्यासाठी पीसीएचा (PCA) वापर करू शकता, जे मुळात आयगेनव्हेक्टर्स (eigenvectors) आहेत. तुम्ही तुमचा डेटा (data) दर्शवण्यासाठी आणि डायमेन्शन्स (dimensions) ½ ने कमी करण्यासाठी त्या काही कंपोनंट्सचा (components) वापर करू शकता. मग मॉडेल (models) तयार करणे सोपे होते (उदा. इमेज रिकग्निशनमध्ये (image recognition)).", "normalised": "आणि हो, निश्चितपणे ए-आय. Eigenvalues आणि eigenvectors प्रिंसिपल कंपोनंट एनालिसिस (P-C-A) सारख्या डायमेन्शनॅलिटी रिडक्शन तंत्रांमध्ये मोठी भूमिका बजावतात. कल्पना करा की तुम्ही चेहऱ्यांच्या इमेजच्या डेटासेटसारख्या अनेक वैशिष्ट्यांसह (features) डेटासेटवर काम करत आहात. प्रत्येक इमेजमध्ये एक हजार वैशिष्ट्ये (एक हजार पिक्सेल) आहेत, तुम्ही तुमच्या डेटाच्या कोव्हेरिएन्स मॅट्रिक्सच्या सर्वात मोठ्या eigenvalues शी संबंधित \"प्रिंसिपल कंपोनंट्स\" शोधण्यासाठी P-C-A वापरू शकता, जे मुळात eigenvectors आहेत. तुम्ही तुमचा डेटा दर्शवण्यासाठी आणि डायमेन्शन एक छेद दोन ने कमी करण्यासाठी त्या काही कंपोनंट्सचा वापर करू शकता. मग मॉडेल (उदाहरणार्थ, इमेज रेकग्निशनमध्ये) तयार करणे सोपे होते."}
{"unnormalised": "आशा आहे की यामुळे थोडी मदत होईल! लीनियर अल्जेब्रा (Linear algebra) कधीकधी अमूर्त वाटू शकते, परंतु जर तुम्ही शोधले तर आयगेनव्हॅल्यूज (eigenvalues) आणि आयगेनव्हेक्टर्सचे (eigenvectors) भरपूर ॲप्लिकेशन्स (applications) आहेत. आणि हे लक्षात ठेवा, सराव महत्त्वाचा आहे! तुमच्या परीक्षेसाठी शुभेच्छा भावा!", "normalised": "आशा आहे की यामुळे थोडी मदत होईल! लीनियर अलजेब्रा कधीकधी अमूर्त वाटू शकते, पण eigenvalues आणि eigenvectors चे अनेक उपयोग आहेत, जर तुम्ही ते शोधले तर. आणि हे लक्षात ठेवा, सराव महत्त्वाचा आहे! तुमच्या परीक्षेसाठी शुभेच्छा भावा!"}
