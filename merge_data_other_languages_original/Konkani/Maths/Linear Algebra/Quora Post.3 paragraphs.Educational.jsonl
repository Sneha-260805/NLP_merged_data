{"unnormalised": "म्हाका लीनियर अलजेब्रा समजून घेवपाक त्रास जाता. कोणेतरी मला आइगनवेक्टर्स आनी आइगनव्हॅल्यूज साध्या शब्दांनी समजावन सांगू शकता काय, खास करून तीं खऱ्या जगांत कशे वापरतात? म्हजें पाठ्यपुस्तक तें खूब स्पश्टपणान सांगना.", "normalised": "म्हाका लीनियर अलजेब्रा समजपाक त्रास जाता. कोण तरी eigenvectors आनी eigenvalues सोप्या उतरांनी समजायतले काय, खास करून ते खऱ्या संवसारांत कशे उपेगी पडटात? म्हजें पाठ्यपुस्तक ते खूब स्पश्टपणान सांगना."}
{"unnormalised": "ठीक आसा, तर कल्पना करा की तुमच्या लागीं 'A' नांवाचें मॅट्रिक्स आसा. आतां, जर तुमी 'A' क 'v' वेक्टरान गुणल्यार, तुमकां आनीक एक वेक्टर मेळटा. आइगनवेक्टर एक खाशेलो वेक्टर 'v' आसा, जाका 'A' न गुणल्यार तो फकत स्केलांत बदलता, दिशेंत न्हय. जें प्रमाणान तें स्केल जाता, ताका आइगनव्हॅल्यू म्हणटात, जाका 'λ' म्हूण दर्शयतात. देखून, समीकरण A * v = λ * v. अशें समजा की: जर 'A' बदलाचें प्रतिनिधित्व करता, तर आइगनवेक्टर 'v' एक असो वेक्टर आसा जो बदला उपरांतय सरळ रेंवत उरता, फकत λ घटकान लांबायता वा दाबून उडयता. आइगनव्हॅल्यूज आनी आइगनवेक्टर्स मेळोवपांत चड करून बहुपदीय समीकरणां सोडोवपाचो आस्पाव आसा; कॅरेक्टरिस्टिक बहुपदी det(A - λI) = 0 चीं मुळां सोदून काडल्यार तुमकां आइगनव्हॅल्यूज मेळटात, जंय 'I' म्हळ्यार आयडेंटिटी मॅट्रिक्स. 3x3 मॅट्रिक्समध्ये, हातूंत थोडें चड काम करचें पडटा, खास करून जेन्ना आइगनव्हॅल्यूज कॉम्प्लेक्स आसतात. तुमकां इयत्ता 11 वींतल्या गणितांतले कॉम्प्लेक्स नंबर मॅनिप्युलेशन्स याद दवरचे पडूं शकतात!", "normalised": "बरें, मानून घेयात तुमच्या लागीं एक मॅट्रिक्स आसा, ताका 'A' म्हणूंया. आतां, जर तुमकां 'A' क एका वेक्टरान, 'v' न गुणल्यार, तुमकां दुसरो वेक्टर मेळटा. eigenvector म्हळ्यार एक खाशेलो वेक्टर 'v' , जंय 'A' न गुणल्या उपरांत, ताचो आकार बदलता, दिशा न्हय. जितलो आकार बदलता ताका eigenvalue म्हणटात, आनी ताका 'lambda' म्हणटात. देखून, समीकरण अशें आसा: A गुणीले v बरोबर lambda गुणीले v. अशें चिंतचें: जर 'A' एक रूपांतरण दाखयता, तर eigenvector 'v' एक असो वेक्टर आसा जो रूपांतरणा उपरांत सरळ रेंवत रावता, फकत lambda न ताणलो वा दाबून उडयल्लो. eigenvalues आनी eigenvectors काडपाक खूबदां बहुपदीय समीकरण सोडवपाची गरज पडटा; A उणे lambda I चें वैशिष्ट्यपूर्ण बहुपदीय निर्धारकाचीं मुळां सोदल्यार तुमकां eigenvalues मेळटा, जंय 'I' म्हळ्यार आयडेंटिटी मॅट्रिक्स. तीन गुणीले तीन मॅट्रिक्स म्हळ्यार हें काम थोडें कठीण, खास करून जंय eigenvalues जटिल आसतात. तुमकां इयत्ता इकरावींतल्या गणितांतले जटिल आंकड्यांचे बदल याद दवरचे पडूं शकतात!"}
{"unnormalised": "तर, हीं खंय वापरतात? गूगलच्या पेज रँक अल्गोरिदममध्यें एक म्हत्वाचो उपेग आसा. इंटरनॅट एक व्हडलें जाळें म्हूण दाखोवपाक जाता, जातूंत वेब पानां नोड्स म्हूण आनी लिंक्स एडजेस म्हूण आसतात. पेज रँक लिंक मॅट्रिक्सच्या सगळ्यांत व्हडल्या आइगनव्हॅल्यूक अनुरूप आशिल्लो आइगनवेक्टर वापरून दरेक पानाचें सापेक्ष म्हत्व थारायता. आनीक एक उपेग म्हळ्यार इमेज कॉम्प्रेस करपाचीं तंत्र जशीं प्रिंसिपल कंपोनेंट एनालिसिस (PCA). PCA इमेजचे प्रिंसिपल कंपोनेंट्स वळखुपाक आइगनवेक्टर्स वापरता, जाका लागून खूब माहिती ना करतना डेटा आकार कमी करपाक मदत जाता. मानून घेयात तुमच्या लागीं 1024x768 पिक्सेल्सची इमेज आसा, तुमी PCA वापरूंक शकतात आनी इमेजची चडशी माहिती दाखोवपी फकत वयलें 100 आइगनवेक्टर्स दवरूंक शकतात. फिजिक्समध्ये, तीं प्रणालीच्या सामान्य कंपनाचे प्रकार (normal modes of vibration) सोदून काडपाक वापरतात, तीं मॉलिक्यूल्स आसूं वा पूल!", "normalised": "देखून, हे खंय वापरतात? Google च्या Page Rank अल्गोरिदम हें एक म्हत्वाचें उपेग आसा. इंटरनेट एक व्हडलें जाळें म्हणून दाखोवंक येता, जंय वेब पानां नोड्स आनी लिंक्स कडां म्हणून दाखोवंक येतात. Page Rank लिंक मॅट्रिक्सच्या सगळ्यांत व्हडल्या eigenvalue कडेन जुळपी eigenvector वापरून दरेक पानाचें सापेक्ष म्हत्व थारयता. दुसरो उपेग P-C-A सारक्या इमेज कॉम्प्रेसर तंत्रांनी आसा. P-C-A चित्राचे मुखेल घटक वळखूंक eigenvectors वापरता, जें तुमकां खूब माहिती ना करतना डेटा आकार कमी करपाक मदत करता. मानून घेयात तुमच्या लागीं एक हजार आनी चोवीस गुणीले सातशें आनी सत्तर पिक्सलंचें चित्र आसा, तुमकां P-C-A वापरून चित्राची चडशी माहिती दाखोवपी फकत शंभर eigenvectors दवरपाक शकतात. फिजिक्स मदीं, तांचो उपेग प्रणालीच्या सामान्य कंपन मोड सोदपाक करतात, मग तीं रेणू आसूं वा पूल!"}
{"unnormalised": "मुखेलपणान, आइगनव्हॅल्यूज आनी आइगनवेक्टर्स गुंतागुंतीच्यो प्रणाली सोपे करपाक मदत करतात. हे \"इनव्हेरिएंट\" दिशानिर्देश आनी स्केलिंग घटक वळखून, एक रेषीय बदल एका जागेचेर कसो परिणाम करता तें आमी समजूंक शकतात आनी ह्या ज्ञानाचो उपेग विविध क्षेत्रांतल्या समस्यांचो सोद लावपाक करूंक शकतात. रेषीय अवकल समीकरणांची प्रणाली सोडोवपा सारकें कांयतरी (देखीक dx/dt = Ax), 'A' मॅट्रिक्सचे आइगनव्हॅल्यूज λ1 आनी λ2 सोदून काडप हें एक म्हत्वाचें पयलें पावल आसा. कांय उदाहरणां सोदून काडात आनी तीं सोडोवपाचो प्रयत्न करात; सरावान खूब मदत जाता!", "normalised": "खऱ्या अर्थान eigenvalues आनी eigenvectors गुंतागुंतीच्या प्रणाली सोपे करपाक मदत करतात. ह्या \"अपरिवर्तनीय\" दिशा आनी स्केलिंग घटक वळखून, आम्हीं एक रेषीय रूपांतरण एका जागेचेर कशें वागता तें समजून घेवंक शकतात आनी ह्या ज्ञानाचो उपेग वेगवेगळ्या क्षेत्रांतल्यो समस्या सोडवपाक करूंक शकतात. रेषीय अवकल समीकरणांची प्रणाली सोडवपा सारक्या कामांत लेगीत (देखीक d x भागिले d t बरोबर A x), मॅट्रिक्स 'A' चे eigenvalues lambda एक आनी lambda दोन सोदप हें म्हत्वाचें पयलें पावल आसा. कांय उदाहरणां सोदून काडात आनी तीं सोडवपाचो प्रयत्न करात; सरावान खूब मदत जाता!"}
