{"unnormalised": "हे दोस्तों, लीनियर अलजेब्रा बारे इक झटपट सवाल ऐ। मैं इक परीक्षा दी तैयारी करदा ऐं ते कुसी चीज च फँस्या होआ ऐं। मैं असल च वास्तविक-दुनिया दी चीज च eigenvalues ते eigenvectors किवें लागू करां, मेट्रिक्स ट्रांसफार्मेशन तो अलावा? मेरी किताब च बस सैद्धांतिक उदाहरण ऐ, पर मैं जानना चांह्दा ऐं जे ऐ सामान कित्थे कम औंदा ऐ, तुस समझदे ओ ना? सोचदे ओ जे, की ऐ सिग्नल प्रोसेसिंग या शायद एआई सामान च बी इस्तेमाल होंदा ऐ? कोई बी आसान स्पष्टीकरण या उदाहरण बड़ी मददगार होनगे!", "normalised": "हे दोस्तों, लीनियर अलजेब्रा बारै चा जल्दी सवाल ऐ। मैं इक परीक्षा दी तैयारी करदा ऐ ते कुसै गल्ल च फसी गेआं। मैं असलियत च रियल-वर्ल्ड चीजें च eigenvalues ते eigenvectors गी केवें लागू करां, सिर्फ, मैट्रिक्स ट्रांसफॉर्मेशन दे अलावा? मेरी किताब च सिर्फ सैद्धांतिक उदाहरण न, पर मैं जानना चांह्दा ऐं जे एह् सामान कित्थें उपयोगी ऐ, तुहां गी पता ऐ? सोचदा ऐ जे, क्या एह् सिग्नल प्रोसेसिंग च इस्तेमाल होंदा ऐ या शायद ए-आई सामान च बी? कोई बी आसान स्पष्टीकरण या उदाहरण बड़ा मददगार होग!"}
{"unnormalised": "तांह्, मैनु याद ऐ जे हमारे प्रोफेसर, डॉ वर्मा, ने पेजरांक एल्गोरिथम च उन्हे इस्तेमाल करने बारे कुसी चीज दा जिक्र कीता, गूगल दा मूल एल्गोरिथम। मैनु लगदा ऐ जे ऐ वेब दे लिंक संरचना का प्रतिनिधित्व करने वाले इक बड़े मैट्रिक्स दे eigenvectors पर आधारित था। सबसे बड़े eigenvalue वाला eigenvector तुहानूं हर पेज के लिए अहमियत का स्कोर देता है। खूब चोखा ऐ, है ना? लगभग जादू की तरह लगदा ऐ, हाहा। ऐ तुहानूं सोचने पर मजबूर करदा ऐ जे लीनियर अलजेब्रा च होर केह् चोखे ट्रिक लुके दे हन।", "normalised": "तां, मैनूं याद ऐ जे साढ़े प्रोफेसर, डॉक्टर वर्मा जी ने पेज रैंक एल्गोरिथ्म च इनें गी इस्तेमाल करने बारै कुछ दस्सेआ हा, गूगल दा असली इक। मैनूं लगदा ऐ जे एह् वेब दी लिंक संरचना गी दर्शाने आह्ले इक बड़े मैट्रिक्स दे eigenvectors उप्पर आधारित हा। सब्भनें शा बड्डे eigenvalue आह्ले eigenvector इक चा हर पेज आस्तै महत्व स्कोर दिंदा ऐ। बड़ा साफ़, सही ऐ ना? लगभग जादू जिया महसूस होंदा ऐ, हा हा। तुहां गी हैरानी होंदी ऐ जे लीनियर अलजेब्रा च होर केह् मजेदार चालाकी लुकी देई ऐ।"}
{"unnormalised": "इक होर एप्लीकेशन जे मैं कुत्थै देखेया उह इंजीनियरिंग प्रणालियां च स्थिरता विश्लेषण कन्नै संबंधित था। जिਵੇਂ, जेकर तुहाडे कोल डिफरेंशियल समीकरणें कन्नै वर्नित इक प्रणाली ऐ, तां तुस प्रणाली दे मेट्रिक्स दे eigenvalues दी बरतों ऐ निधारत करने लेई करी सकदे ओ जे की प्रणाली स्थिर ऐ या नेईं। जेकर सारे eigenvalues दे नकारात्मक वास्तविक भाग हन, तां प्रणाली स्थिर ऐ। जेकर तुस कैपेसिटर (C= 10μF), इंडक्टर (L = 5mH), ते प्रतिरोधक (R=10 Ohms) कन्नै बिजली दे सर्किट दा मॉडल बनाना चांह्दे ओ, तां eigenvalues पता लाना तुहानूं ऐ समझने च मदद करदा ऐ जे की सर्किट दोलन करदा ऐ या खराब होंदा ऐ।", "normalised": "इक होर एप्लीकेशन जे मैं कित्थें दिक्खेया हा ओह् इंजीनियरिंग सिस्टम च स्थिरता विश्लेषण कन्नै जुड़ा हा। जियां, जे तुहां दे कोल डिफरेनशियल समीकरणें कन्नै दस्से दा इक सिस्टम ऐ, तां तुस सिस्टम दे मैट्रिक्स दे eigenvalues दा इस्तेमाल एह् जानने आस्तै करी सकदे ओ जे सिस्टम स्थिर ऐ जां नेईं। जे सब्भनें eigenvalues दे नकारात्मक वास्तविक हिस्से होंदे न, तां सिस्टम स्थिर ऐ। जे तुस कैपेसिटर (C दस माइक्रोफराड दे बराबर), इंडक्टर (L पांच मिलीहेनरी दे बराबर), ते रेसिटर (R दस ओम दे बराबर) कन्नै बिजली दे सर्किट गी मॉडल करना चांह्दे ओ, तां eigenvalues गी ढूंढना तुहां गी समझने च मदद करदा ऐ जे सर्किट ऑसिलेट करदा ऐ जां खत्म होंदा ऐ।"}
{"unnormalised": "ते हां, पूरी तरह कन्नै एआई। eigenvalues ते eigenvectors प्रमुख घटक विश्लेषण (PCA) जेह्ही आयाम कमी तकनीकों च इक भारी भूमिका निभांदे न। कल्पना करो जे तुस टनें फीचर आह्ले डेटासेट कन्नै कम्म करी करदे ओ, जिਵੇਂ जे चेहरें दी इमेज दा डेटासेट। हर इमेज च 1000 फीचर (1000 पिक्सेल) हन, तुस PCA दी बरतों \"प्रमुख घटक\" पता लाने लेई करी सकदे ओ, जेह्ड़े मूल रूप कन्नै तुहाडे डेटा दे सहप्रसरण मैट्रिक्स दे सबसे बड़े eigenvalues कन्नै संबंधित eigenvectors हन। तुस उह्ना कुच्छ घटकों दी बरतों अपने डेटा का प्रतिनिधित्व करने ते आयाम को ½ च काटने लेई करी सकदे ओ। फिर मॉडल बनाना आसान है (जैसे, छवि पहचान में)।", "normalised": "ते हां, बिल्कुल ए-आई। eigenvalues ते eigenvectors आयाम घटाने आह्ली तकनीक जियां प्रिंसिपल कंपोनेंट एनालिसिस (पी-सी-ए) च बड्डी भूमिका निभांदे न। कल्पना करो जे तुस टनें फीचर आह्ले इक डेटासेट कन्नै कम्म करदे ओ, जियां चेहरें दी इमेजां दा डेटासेट। हर इमेज च इक हजार फीचर (इक हजार पिक्सेल) होंदे न, तुस पी-सी-ए दा इस्तेमाल \"प्रधान घटक\" गी ढूंढने आस्तै करी सकदे ओ, जे बुनियादी तौर उप्पर तुहाडे डेटा दे सहप्रसरण मैट्रिक्स दे सब्भनें शा बड्डे eigenvalues दे अनुरूप eigenvectors न। तुस उनें थोह्ड़े घटकें दा इस्तेमाल अपने डेटा गी दर्शाने आस्तै करी सकदे ओ ते आयामें गी इक कन्नै दो कन्नै विभाजित करी सकदे ओ। फिर मॉडलें गी बनाना (जियां इमेज पहचान च) आसान ऐ।"}
{"unnormalised": "उम्मीद ऐ जे ऐ कुच्छ मददगार होई। लीनियर अलजेब्रा कदे-कदे अमूर्त लगग सकदा ऐ, पर eigenvalues ते eigenvectors दे टनें एप्लीकेशन बाहर हन, जेकर तुस बस उन्हां दी खोज करो। ते न भूलना, अभ्यास जरूरी ऐ! तुंदी परीक्षा कन्नै शुभकामनाएं भाई!", "normalised": "उम्मीद ऐ जे इस कन्नै थोड़ी मदद मिलदी होग! लीनियर अलजेब्रा कदे-कदे अमूर्त लग सकदा ऐ, पर eigenvalues ते eigenvectors दी टनें एप्लीकेशन न, जे तुस सिर्फ इनें गी तलाश करो। ते ना भूल्लना, अभ्यास ही कुंजी ऐ! तुहाडी परीक्षा आस्तै शुभकामना ब्रो!"}
