{"unnormalised": "किसै ने मेरे शा मशीन लर्निंग च लीनियर अलजेब्रा दी एप्लिकेशन दे बारे च पुच्छया। ठीक ऐ, ऐह् मता जरूरी ऐ। इक बुनियादी न्यूरल नेटवर्क परत पर विचार करो; ऐह् असल च इक मैट्रिक्स गुणा ऐ। हर न्यूरॉन दा आउटपुट अपने इनपुट दा भारित योग ऐ, ते इन भारें गी मैट्रिक्स च व्यवस्थित कीता जंदा ऐ। उदाहरण दे तौर पर, इक परत च आयाम (100 x 50) कन्नै वजन डब्ल्यू होई सकदा ऐ, जिसदा मतलब ऐ जे ऐह् 50 आयामी इनपुट गी 100 आयामी आउटपुट च बदलदा ऐ। फारवर्ड पास च Wx + b दी गणना करना शामल ऐ, जित्थें x इनपुट वेक्टर ऐ ते b इक पूर्वाग्रह वेक्टर ऐ। ऐह् 'Wx' बिल्कुल उह थाह् ऐ जित्थें लीनियर अलजेब्रा चमकदा ऐ।", "normalised": "केईं इक म्ही मशीन लर्निंग च लीनियर अलजेब्रा दे एप्लीकेशन बारै पुच्छया। खैर, एह् ब'त्त जरूरी ऐ। इक बुनियादी न्यूरल नेटवर्क लेयर गी दिक्खो; एह् असल च इक मैट्रिक्स गुणा ऐ। हर न्यूरॉन दा आउटपुट अपने इनपुट दा भारित जोड़ ऐ, ते इह् भार मैट्रिक्स च संगठित कीते जांदे न। उदाहरण आस्तै, इक लेयर च सौ बाई पंजाह आयाम दे भार W हो सकदे न, जिसदा मतलब ऐ जे एह् पंजाह-आयामी इनपुट गी इक सौ-आयामी आउटपुट च बदलदा ऐ। फॉरवर्ड पास च W x जमा b दी गणना करना शामल ऐ, जित्थें x इनपुट वेक्टर ऐ ते b इक पूर्वाग्रह वेक्टर ऐ। इह् 'W x' बिल्कुल ओह् जगह ऐ जित्थें लीनियर अलजेब्रा चमकदा ऐ।"}
{"unnormalised": "फिर तुम्हारे कोल इमेज प्रोसेसिंग ऐ। इक इमेज गी इक मैट्रिक्स (जां कलर इमेज दे सारें मैट्रिक्स) दे तौर पर दर्शाया जाई सकदा ऐ। धुंधलापन, किनारे दा पता लगाने, ते घुमावदारें जेह् ले ऑपरेशन सारें लीनियर अलजेब्रा अवधारणाएं पर निर्भर करदे न। उदाहरण दे तौर पर, इक 3x3 कनवल्शन कर्नेल गी लागू करने च तत्व-वार गुणा ते जोड़ शामल ऐ जिस गी मैट्रिक्स ऑपरेशन दा इस्तेमाल करदे होए दर्शाया जाई सकदा ऐ। इमेज गी रीसाइज करने जां उस्सै गी कटने जेह् ले सरल कम्म गी बी लीनियर ट्रांसफार्मेशन दे तौर पर दिक्खेआ जाई सकदा ऐ। पीसीए जेह् ही इमेज कंप्रेशन तकनीक बी लीनियर अलजेब्रा दा मता इस्तेमाल करदी ऐ।", "normalised": "फिर तुसांऽदे कोल इमेज प्रोसेसिंग ऐ। इक इमेज गी रंगीन इमेज आस्तै इक मैट्रिक्स या मैट्रिक्स दे सेट दे रूप च दर्शाया जाई सकदा ऐ। धुंधलाने, किनारे दी पहचान ते घुमावने जेह्े ऑपरेशन सारे लीनियर अलजेब्रा अवधारणाएं पर निर्भर करदे न। उदाहरण आस्तै, त्रै बाई त्रै कंवल्शन कर्नेल लगाने च तत्व-वार गुणा ते योग शामल ऐ जिस गी मैट्रिक्स संचालन दे माध्यम कन्नै दर्शाया जाई सकदा ऐ। इमेज दा आकार बदलने या इस गी क्रॉप करने जेह्े सरल कार्यें गी बी लीनियर ट्रांसफॉर्मेशन दे रूप च दिक्खेआ जाई सकदा ऐ। इमेज कंप्रेशन तकनीकें जेह्े के पी-सी-ए बी लीनियर अलजेब्रा दा भारी इस्तेमाल करदे न।"}
{"unnormalised": "अगें, लीनियर अलजेब्रा मशीन लर्निंग च इस्तेमाल होने आलें कई अनुकूलन एल्गोरिदम गी रेखांकित करदा ऐ जेह् ड़े ग्रेडिएंट डिसेंट जेह् हे न। ऐह् एल्गोरिदम मॉडल गी कुशलता कन्नै प्रशिक्षित करने लेई मता जरूरी न। ते इस वास्ते, भले ई तुस हर वेले स्पष्ट रूप कन्नै मैट्रिक्स नईं लिखदे ओ, पर लीनियर अलजेब्रा दी मजबूत समझ निश्चित रूप कन्नै तुंदी मदद करी सकदी ऐ के तुस कई एमएल मॉडल दे अंदरूनी कामकाज गी समझो, ते तुंदी मदद बी करो तुंदे कोड गी डीबग करने च। तुस हर वेले आइगेनवैल्यू, आइगेनवेक्टर, मैट्रिक्स डिकम्पोजिशन, ते वेक्टर स्पेस जेह् ही चीजें दा सामना करगे।", "normalised": "इसके अलावा, लीनियर अलजेब्रा मशीन लर्निंग च इस्तेमाल कीते जाने आह्ले कई ऑप्टिमाइजेशन एल्गोरिदम गी मजबूत करदा ऐ, जि’यां ग्रेडिएंट डिसेंट। इह् एल्गोरिदम कुशलता कन्नै मॉडल गी प्रशिक्षित करने लेई जरूरी न। इस करी, भलेई तुस हर ब'र matrices गी स्पष्ट रूप कन्नै नेईं लिखी दे हो, पर लीनियर अलजेब्रा दी मजबूत समझ तुंदी कई M-L मॉडलां दी आंतरिक कार्यप्रणाली गी समझने च जरूर मदद करदी, ते तुंदी कोड गी डीबग करने च बी मदद करदी। तुसेंगी हर ब'र eigenvectors, eigenvalues, मैट्रिक्स अपघटन, ते वेक्टर स्पेस जेह्े चीजें दा सामना करना पौग।"}
