{"unnormalised": "ठीक ऐ, इथे तुंदी दित्ती गिया खासियतां पर आधारित इक ब्लॉग पोस्ट ऐ।", "normalised": "ठीक ऐ, मैं समझ गयां जे तुसां चांह्दे ओ जे मैं टेक्स्ट फाइलें दा इक संग्रह प्रोसेस करां। हालाँकि, तुसां जेह्ड़ी इनपुट दित्ती ऐ ओ इक सिंगल ब्लॉग पोस्ट *पाठ दे रूप च* ऐ, कोई फाइल जां फोल्डर ढांचा नेईं।", "text": "ठीक ऐ, इथे टेक्स्ट फाइलें दा इक संग्रह ऐ। पर, तुसां जेह्ड़ी इनपुट दित्ती ऐ, ओह् तुसां दी दित्ती गेई स्पेसिफिकेशन्स उप्पर आधारित इक सिंगल ब्लॉग पोस्ट ऐ।"}
{"unnormalised": "अनुवाद विच घुम्मी-पुम्मी: मेरे हिन्दुस्तानी पत्तें कन्नै साहसिक कम्म (ते तुसां गी जीपीएस दी लोड़ क्यों ऐ)", "normalised": "तुम्हारी फाइलें प्रोसेस करने ते फोल्डर स्ट्रक्चरें गी मिरर करने दी रिक्वेस्ट पूरी करने आस्तै, मैनु फोल्डर दे अंदर असल फाइलें मिलनी ज़रूरी ऐ।", "text": "अनुवाद विच घुम्मी-पुम्मी: मेरे हिन्दुस्तानी पत्तें कन्नै साहसिक कम्म (ते तुसां गी जीपीएस दी लोड़ क्यों ऐ)"}
{"unnormalised": "ते, मैं सोचदा हा कि मैं बड़ा सयाना हां, तुसां जानदे ओ? मैं दिल्ली मेट्रो विच भीड-भाड़ वाले समय विच नेविगेट कीता ऐ, चांदनी चौक विच इक साड़ी पर बढ़िया कीमत लाने खातर मोल-भाव कीता ऐ, ते इथे तक कि चाय विच दुद्ध पौने थ्हो बिना चाय मंगवाने दा प्रबंध वी कीता ऐ (मैनु भरोसा ऐ, इक कमाल ऐ)। पर फिर आए पता। ओह, पता!", "normalised": "मिंजो माफ करो, पर मिंजो Dogri च अनुवाद करने के लिए कोई पाठ नेईं दित्ता गेया।", "text": "ते, मैं सोचदा हा कि मैं बड़ा सयाना हां, तुसां जानदे ओ? मैं दिल्ली मेट्रो विच भीड-भाड़ वाले समय विच नेविगेट कीता ऐ, चांदनी चौक विच इक साड़ी पर बढ़िया कीमत लाने खातर मोल-भाव कीता ऐ, ते इथे तक कि चाय विच दुद्ध पौने थ्हो बिना चाय मंगवाने दा प्रबंध वी कीता ऐ (मैनु भरोसा ऐ, इक कमाल ऐ)। पर फिर आए पता। ओह, पता!"}
{"unnormalised": "मैनु मंजर दस्सन दे: मैं गोवा च एह् मनमोहक निक्का गेस्टहाउस लभने दे मिशन पर हा। स्वर्ग जियां लग्गदा हा, है ना? बुकिंग पुष्टीकरण खुश होईये ऐ ऐलान कित्ता: \"आनंद विला, एच. नं. 147/ए, सेंट एलेक्स चर्च दे नेड़े, कलंगुट, बारदेज़, गोवा 403516।\" मै सोचिया बड़ा आसान ऐ। आखरी शब्द मशहूर।", "normalised": "में सीधे तोर पर तुंदे लोकल फाइल सिस्टम कन्नै गल्लबात नहीं करी सकदा, मैं ओह् पाइथन कोड दस्सां जेह्ड़ा *तुस* चलाई सकदे ओ।", "text": "मैनु मंजर दस्सन दे: मैं गोवा च एह् मनमोहक निक्का गेस्टहाउस लभने दे मिशन पर हा। स्वर्ग जियां लग्गदा हा, है ना? बुकिंग पुष्टीकरण खुश होईये ऐ ऐलान कित्ता: \"आनंद विला, एच. नं. 147/ए, सेंट एलेक्स चर्च दे नेड़े, कलंगुट, बारदेज़, गोवा 403516।\" मै सोचिया बड़ा आसान ऐ। आखरी शब्द मशहूर।"}
{"unnormalised": "पहले, \"एच. नंबर 147/ए.\" मैं समझया कि एह घर दा नंबर ऐ, धुह। पर ओह नईं, गोआ च, एह इक पक्की निशानी तों ज़्यादा इक सलाह लगदी ऐ। मैं इक घंटा मता उसी जगह गै घूम्दा रेहा जिसदा मैं पक्का हा कि एह इक नारियल दा बाग ऐ, लोकें तों पुछदा रेहा जे उन्होंने \"एच. नंबर 147/ए, कोई स्लेश कुछ वी\" दिक्खेआ ऐ। जवाब खाली नज़रें तों लेइयै मददगार (पर आख़िर च ग़लत) दिशाएं तक बदले।", "normalised": "मैं ठीक हूँ, धन्यवाद।\nतुसां क्या करदे ओ?", "text": "पहले, \"एच. नंबर 147/ए.\" मैं समझया कि एह घर दा नंबर ऐ, धुह। पर ओह नईं, गोआ च, एह इक पक्की निशानी तों ज़्यादा इक सलाह लगदी ऐ। मैं इक घंटा मता उसी जगह गै घूम्दा रेहा जिसदा मैं पक्का हा कि एह इक नारियल दा बाग ऐ, लोकें तों पुछदा रेहा जे उन्होंने \"एच. नंबर 147/ए, कोई स्लेश कुछ वी\" दिक्खेआ ऐ। जवाब खाली नज़रें तों लेइयै मददगार (पर आख़िर च ग़लत) दिशाएं तक बदले।"}
{"unnormalised": "फिर इक होया \"नियर सेंट एलेक्स चर्च।\" हुण, सेंट एलेक्स चर्च तां इक मता बड्डा लैंडमार्क ऐ। तुसां सोचदे होगे जे \"नियर\" दा मतलब होग, जियां, अग्गे आले डंडयां थमां दिखदा होग। ना। गोवा च, \"नियर\" दा मतलब ऐ \"जनरल विसिनिटी च कुतै बी, शायद इक्का रिक्शा दी सवारी ते इक गऊएं कन्नै गल्लबात बी शामिल होग।\" आखिर च मिगी ऐ मिल गया... 3 बक्ख-बक्ख ऑटो-रिक्शा वालेयां थमां पुच्छने दे बाद जिन्नां च हर इक ने मिगी 500 रुपये चार्ज करने दी कोशश कीती जिदी सवारी दा 100 रुपये होणा चाहिदा हा।", "normalised": "ऐह् तुह्आड़े नॉर्मलाईजेशन दे लक्ष्शां गी हासल करने लेई पाइथन स्क्रिप्ट ऐ:", "text": "फिर इक होया \"नियर सेंट एलेक्स चर्च।\" हुण, सेंट एलेक्स चर्च तां इक मता बड्डा लैंडमार्क ऐ। तुसां सोचदे होगे जे \"नियर\" दा मतलब होग, जियां, अग्गे आले डंडयां थमां दिखदा होग। ना। गोवा च, \"नियर\" दा मतलब ऐ \"जनरल विसिनिटी च कुतै बी, शायद इक्का रिक्शा दी सवारी ते इक गऊएं कन्नै गल्लबात बी शामिल होग।\" आखिर च मिगी ऐ मिल गया... 3 बक्ख-बक्ख ऑटो-रिक्शा वालेयां थमां पुच्छने दे बाद जिन्नां च हर इक ने मिगी 500 रुपये चार्ज करने दी कोशश कीती जिदी सवारी दा 100 रुपये होणा चाहिदा हा।"}
{"unnormalised": "ते मेनू तां \"Bardez\" पर शुरू वी नी करो। के ऐ इक कस्बा ऐ? इक जिला? इक एहसास? मेनू अजें वी पूरी तरह यकीन नी ऐ। पिन कोड, \"403516,\" इकल्ल ही चीज ही जेह्दे च कुझ समझ आंदी ही, ते उस वेले वी, गूगल मैप्स मेरे पर हंसी करदा रिया।", "normalised": "एह् स्क्रिप्ट कराेगा:", "text": "ते मेनू तां \"Bardez\" पर शुरू वी नी करो। के ऐ इक कस्बा ऐ? इक जिला? इक एहसास? मेनू अजें वी पूरी तरह यकीन नी ऐ। पिन कोड, \"403516,\" इकल्ल ही चीज ही जेह्दे च कुझ समझ आंदी ही, ते उस वेले वी, गूगल मैप्स मेरे पर हंसी करदा रिया।"}
{"unnormalised": "आखिरकार, इक छोटी तीर्थ यात्रा (ते किंगफिशर दीयां केई बोतलें पीने दे बाद) जेह्‌ने बाद, मैं आनंद विला पर पुज्जा। एह् बड़ा प्यारा हा, सचमुच। पर यात्रा? आओ बस आह्‌निए जेह्‌ड़ी मैं हुण \"गुम ते परेशान\" दी गोआ बोली विच माहिर होई गेआं।", "normalised": "1.  इक `source_folder` इनपुट दे तौर पर लैओ।", "text": "आखिरकार, इक छोटी तीर्थ यात्रा (ते किंगफिशर दीयां केई बोतलें पीने दे बाद) जेह्‌ने बाद, मैं आनंद विला पर पुज्जा। एह् बड़ा प्यारा हा, सचमुच। पर यात्रा? आओ बस आह्‌निए जेह्‌ड़ी मैं हुण \"गुम ते परेशान\" दी गोआ बोली विच माहिर होई गेआं।"}
{"unnormalised": "कहानी दा मतलब ऐ? हमेषां, *हमेषां* GPS कोआर्डिनेट ज़रूर रक्खो। ते हो सकदा ऐ इक लोकल सिम कार्ड बी। ते पक्का ही हास्से दी भावना बी। क्योंकि भारत च पता ढूँढना अपने आप च इक साहसिक कम्म होई सकदा ऐ, ते कदे कदे, बेहतरीन कहानियां उही होंदियां न जिंदे च तुसीं मायूसी कन्नै, हास्यास्पद ढंग कन्नै गुम होई जांदे ओ। अगली बारी, मैं अपनी बुकिंग नोट्स च सिर्फ \"अक्षांश: [अक्षांश ऐत्थे डालो], देशांतर: [देशांतर ऐत्थे डालो]\" लिखदां। दिखदे आं कि ओह् ऐह्दे च कन्फ्यूज होन दी कोशिश करदे न!", "normalised": "२. सारे सबफोल्डरां च बारी-बारी शा मिलो।", "text": "कहानी दा मतलब ऐ? हमेषां, *हमेषां* GPS कोआर्डिनेट ज़रूर रक्खो। ते हो सकदा ऐ इक लोकल सिम कार्ड बी। ते पक्का ही हास्से दी भावना बी। क्योंकि भारत च पता ढूँढना अपने आप च इक साहसिक कम्म होई सकदा ऐ, ते कदे कदे, बेहतरीन कहानियां उही होंदियां न जिंदे च तुसीं मायूसी कन्नै, हास्यास्पद ढंग कन्नै गुम होई जांदे ओ। अगली बारी, मैं अपनी बुकिंग नोट्स च सिर्फ \"अक्षांश: [अक्षांश ऐत्थे डालो], देशांतर: [देशांतर ऐत्थे डालो]\" लिखदां। दिखदे आं कि ओह् ऐह्दे च कन्फ्यूज होन दी कोशिश करदे न!"}
{"unnormalised": "", "normalised": "3. हर `.txt` फाइल लेई, दित्ते गेदे सारे सामान्यीकरण दे नियम लागू करो।", "text": "3. हर इक `.txt` फाइल लेई, दित्ते गेदे सारे नॉर्मलाइजेशन दे नियम लागू करो।"}
{"unnormalised": "", "normalised": "4.  नार्मलाईज़्ड `.txt` फाइल गी ओरिजिनल फोल्डर स्ट्रक्चर बरकरार रखदे होई, इक `destination_folder` विच सेव करो (जियां कि `dataset_normalized`)।", "text": "4.  नॉर्मलाईज़्ड `.txt` फाइल गी इक `destination_folder` विच सेव करो (जियां के, `dataset_normalized`) मूल फोल्डर स्ट्रक्चर गी बरकरार रखदे होई।"}
{"unnormalised": "", "normalised": "५. `.txt` फाइलें गी छेड्दे बगैर गै बाकी फाइलें गी मंजिल पर कॉपी करो।", "text": "५. गैर-`.txt` फाइलें गी बिना बदलाव कीते मंजिल पर कॉपी करो।"}
{"unnormalised": "", "normalised": "६. उन `.txt` फाइलें दे नां छापो जिह्ड़ियां नॉर्मलाइज नीं होईयां (हालांकि मौजूदा लॉजिक कन्नै, सारियां `.txt` फाइलें गी करने दी कोशिश कीती जाग)।", "text": "६. `.txt` फाइलें दे नां छपो जिह्ड़ियां नॉर्मलाइज़ नेईं कीतियां (हालांकि मौजूदा लॉजिक कन्नै, सारियां `.txt` फाइलें दी कोशिश कीत्ती जाग)।"}
{"unnormalised": "", "normalised": "ह्न तोड़ी करीं।\n```", "text": "ह्न तोड़ी करीं।\n```"}
{"unnormalised": "", "normalised": "इम्पोर्ट री", "text": "इम्पोर्ट री"}
{"unnormalised": "", "normalised": "ओस ऐस।", "text": "ओस ऐस।"}
{"unnormalised": "", "normalised": "शटल आयात करो", "text": "शटल आयात करो"}
{"unnormalised": "", "normalised": "इम्पोर्ट इन्फ्लेक्ट", "text": "इम्पोर्ट इन्फ्लेक्ट"}
{"unnormalised": "", "normalised": "गिनती गी शब्दें च बदलने आस्तै इन्फ्लेक्ट इंजन गी शुरू करो।", "text": "गिनती गी शब्दें च बदलने आस्तै इन्फ्लेक्ट इंजन गी शुरू करो।"}
{"unnormalised": "", "normalised": "p = इन्फ्लेक्ट.इंजन()", "text": "p = इन्फ्लेक्ट.इंजन()"}
{"unnormalised": "", "normalised": "# --- नॉर्मलाइजेशन लेई सहायक फ़ंक्शन ---", "text": "# --- नॉर्मलाइजेशन लेई सहायक फ़ंक्शन ---"}
{"unnormalised": "", "normalised": "डेफ नंबर-टू-वर्ड्स(नंबर_स्ट्र):", "text": "डेफ नंबर-टू-वर्ड्स(नंबर_स्ट्र):"}
{"unnormalised": "", "normalised": "\"\"\"इक नंबर स्ट्रिंग गी उसदे बोले जाने आह्ले अंग्रेजी रूप च बदल्दा ऐ।\"\"\"", "text": "\"\"\"इक नंबर स्ट्रिंग गी उसदे बोले जाने वाले अंग्रेजी रूप च बदलदा ऐ।\"\"\""}
{"unnormalised": "", "normalised": "कोशिश करो:", "text": "कोशिश करो:"}
{"unnormalised": "", "normalised": "# दशांश संभालो", "text": "दशमलवें गी संभाळो"}
{"unnormalised": "", "normalised": "जे '.' number_str च है:", "text": "जेकर '.' नंबर_स्ट्रिंग च ऐ तां:"}
{"unnormalised": "", "normalised": "हिस्से = नंबर_स्ट्रिंग.बांटी दित्ती '. ' कन्नै", "text": "हिस्से = नंबर_स्ट्रिंग.स्प्लिट('.')"}
{"unnormalised": "", "normalised": "सारा = p.number_to_words(int(parts[0])) जे parts[0] ऐ तां नीं तां ''", "text": "पूरे = p.number_to_words(int(parts[0])) जे parts[0] होऐ तां नेई ते ''"}
{"unnormalised": "", "normalised": "दशमलव = 'बिंदु ' + ' '.join(p.number_to_words(int(d)) for d in parts[1]) जे parts[1] ऐ तां ''", "text": "दशमलव = 'बिंदु ' + ' '.join(p.number_to_words(int(d)) for d in parts[1]) अगर parts[1] है तो नहीं तो ''"}
{"unnormalised": "", "normalised": "वापस करो (f\"{पूरा} {दशमलव}\").trim()", "text": "रिटर्न (f\"{होल} {डेसिमल}\").ट्रिम()"}
{"unnormalised": "", "normalised": "नै तां:", "text": "नैं तां:"}
{"unnormalised": "", "normalised": "वापस करो p.number_to_words(int(number_str))", "text": "वापस करा p.number_to_words(int(number_str))"}
{"unnormalised": "", "normalised": "बजाए ValueError दे:", "text": "बेशक, लोआ इस कन्नै अनुवाद:\n\nअगर वैल्यू एरर नेईं औंदी:"}
{"unnormalised": "", "normalised": "वापस करो नंबर_स्ट्रिंग # अगर सही नंबर नेईं ऐ तां मूल वापस करो (उदाहरण देई दा ऐ, पैह्ले गै शब्द शामल न)", "text": "रिटर्न नंबर_स्ट्रिंग # ओरिजनल वापस करो जेकर ठीक नंबर नेईं ऐ (मिसाल दे तौर पर, पैह्लेई शब्द शामल न)"}
{"unnormalised": "", "normalised": "डिफाइन नॉर्मलाइज़_सिंबलस्(टेक्स्ट):", "text": "डिफाइन नॉर्मलाइज़_सिंबलस्(टेक्स्ट):"}
{"unnormalised": "", "normalised": "\"\"\"आम निशानें गी उन्दे बोलने आले रूपें कन्नै बदल्दा ऐ।\"\"\"", "text": "आम सिंबलें गी उनदे बोलने आले रूपें कन्नै बदल्दा ऐ।"}
{"unnormalised": "", "normalised": "# कुसै बदलावां आस्तै तरतीब जरूरी ऐ", "text": "कूंझ बदलावें आहस्ते तरतीब ज़रूरी ऐ।"}
{"unnormalised": "", "normalised": "text = re.sub(r'≠', ' बराबर नेईं ऐ ', text)", "text": "text = re.sub(r'≠', ' बराबर नेईं ऐ ', text)"}
{"unnormalised": "", "normalised": "पाठ = re.sub(r'≤', ' कम जां बराबर ', पाठ)", "text": "text = re.sub(r'≤', ' याहदे बराबर या ओह्दे शां घट ', text)"}
{"unnormalised": "", "normalised": "टेक्स्ट = री.सब(आर'>=', ' ग्रेटर दैन आर इक्वल टू ', टेक्स्ट)", "text": "text = re.sub(r'≥', ' बड्ढा या बराबर दे ', text)"}
{"unnormalised": "", "normalised": "text = text.replace('√', ' दा वर्गमूल ')", "text": "टेक्स्ट = री.सब(r'√', ' स्क्वायर रूट ऑफ़ ', टेक्स्ट)"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'%', ' percent ', टेक्स्ट)", "text": "टेक्स्ट = रे.सब(r'%', ' प्रतिशत ', टेक्स्ट)"}
{"unnormalised": "", "normalised": "text = re.sub(r'\\+', ' जमा ', text)", "text": "टेक्स्ट = री.सब(r'\\+', ' प्लस ', टेक्स्ट)"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.सब(r'=', ' बराबर ', टेक्स्ट)", "text": "text = re.sub(r'=', ' बराबर है ', text)"}
{"unnormalised": "", "normalised": "टेक्स्ट = रे.सब(r'@', ' एट ', टेक्स्ट)", "text": "पाठ = re.sub(r'@', ' एट ', पाठ)"}
{"unnormalised": "", "normalised": "टेक्स्ट = रे.सब(r'&', ' एंड ', टेक्स्ट)", "text": "टेक्स्ट = re.sub(r'&', ' and ', टेक्स्ट)"}
{"unnormalised": "", "normalised": "text = re.sub(r'#', ' हैश ', text)", "text": "टेक्स्ट = re.sub(r'#', ' hash ', टेक्स्ट)"}
{"unnormalised": "", "normalised": "पाठ = re.sub(r'\\*', ' तारा चिन्ह ', पाठ)", "text": "text = text.replace('*', ' asterisk ')"}
{"unnormalised": "", "normalised": "टेक्स्ट = रे.सब(r'~', ' लगभग ', टेक्स्ट)", "text": "टेक्स्ट = री.सब(r'~', ' लगभग ', टेक्स्ट)"}
{"unnormalised": "", "normalised": "# प्रसन्गै दे आधार पर \"/\" गी ध्यानै कन्नै बरततरा", "text": "संदर्भ दे मुजब \"/\" गी ध्यान कन्नै बरतो"}
{"unnormalised": "", "normalised": "टेक्स्ट = री.सब(आर'( \\b[a-zA-Z]+)/( [a-zA-Z]+\\b)', आर'\\1 या \\2', टेक्स्ट) # शब्द/शब्द -> शब्द या शब्द", "text": "ऐह् टेक्स्ट दा इक हिस्सा ऐ जिह्दे च इक पैटर्न `(\\b[a-zA-Z]+)/([a-zA-Z]+\\b)` गी सब्स्टिट्यूट कीता जा करदा ऐ, जिसदे च इक शब्द/शब्द गी शब्द या शब्द च बदली दिता जा करदा ऐ।"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'(\\b[A-Z0-9]+)/([A-Z0-9]+\\b)', r'\\1 स्लैश \\2', टेक्स्ट) # एक्रोनियम/संक्षेप -> एक्रोनियम स्लैश संक्षेप", "text": "टेक्स्ट = re.sub(r'(\\b[A-Z0-9]+)/([A-Z0-9]+\\b)', r'\\1 स्लैश \\2', टेक्स्ट) # संक्षिप्त रूप/संक्षिप्तीकरण -> संक्षिप्त रूप स्लैश संक्षिप्तीकरण"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'(\\d+)/(\\d+)', r'\\1 नूँ \\2 कन्नै डिवाइड कीता गेआ', टेक्स्ट) # नंबर/नंबर -> नंबर नूँ नंबर कन्नै डिवाइड कीता गेआ", "text": "ये टेक्स्ट = re.sub(r'(\\d+)/(\\d+)', r'\\1 divided by \\2', टेक्स्ट) # नंबर/नंबर -> नंबर डिवाइडेड बाय नंबर"}
{"unnormalised": "", "normalised": "टेक्स्ट = रे.सब(r'(?<!\\s)/', ' स्लैश ', टेक्स्ट) # बाकी बचे स्लैश पकडो (उदाहरण के तौर पर, पाथ, मिक्सड केस उपर ना पकड्या गया)", "text": "टेक्स्ट = re.sub(r'(?<!\\s)/', ' स्लैश ', टेक्स्ट) # बची स्लैशें गी पकड़ो (उदाहरण के तौर पर, पाथ, मिक्सड केस जिआं उप्पर नईं पकड़ी गेई)"}
{"unnormalised": "", "normalised": "टेक्स्ट = रे.सब(r'°C', ' डिग्री सेल्सियस ', टेक्स्ट) # डिग्री सेल्सियस पैह्ले", "text": "text = re.sub(r'°C', ' डिग्री सेल्सियस ', text) # डिग्री सेल्सियस पैह्ले"}
{"unnormalised": "", "normalised": "वापस टेक्स्ट करो", "text": "वापस पाठ करा।"}
{"unnormalised": "", "normalised": "डेफ नोर्मलाइज़ एक्रोनिम्स(टेक्स्ट):", "text": "डेफ नोर्मलाइज़ एक्रोनिम्स(टेक्स्ट):"}
{"unnormalised": "", "normalised": "\"\"\"अक्षर-संक्षेपें गी हाइफन लाए अक्षरें च बदलदा ऐ.\"\"\"", "text": "\"\"\"अक्षर-संक्षेपें गी हाइफन-युक्त अक्षरें च बदल्दा ऐ।\"\"\""}
{"unnormalised": "", "normalised": "डिफाइन रिप्लेस_एक्रॉनिम(मैच):", "text": "कुस्से भी अक्खरें दा मतालब बदलो:"}
{"unnormalised": "", "normalised": "एक्रोनियम = match.group(0)", "text": "अक्रोनिम = match.group(0)"}
{"unnormalised": "", "normalised": "# पक्का करो के एह इकल्ला अक्षर नईं ऐ, जां आम संकुचन (मसलन, I'M) नईं ऐ।", "text": "# यकीन करो जेह् एह् इक अक्षर जां आम संकुचन (मिसाल के तौर पर, मैं) नेईं ऐ।"}
{"unnormalised": "", "normalised": "अगर acronym दी लम्बाई 1 शा म्मतै है ते ऐ नहीं है कि (acronym सारे uppercase च है ते acronym दी लम्बाई 1 बराबर है):", "text": "अगर acronym दी लंबाई 1 तूं मता ऐ ते (acronym सारै बड्डे अक्षरें च नई ऐ ते acronym दी लंबाई 1 बराबर ऐ) नई ऐ तां:"}
{"unnormalised": "", "normalised": "# अनुमान: जेह्ड़े शब्द दे टूटने दी संभावना निंहीं ऐ, उसलै तोड़ने थमां बचो (उदाहरण लेई, \"IT\" जिਵੇਂ के \"इट इज\" च)", "text": "# ہیورسٹک: اگر اے شبد ہوݨ دا امکان اے تے اِس نوں ونڈݨ توں بچو (جیسے کہ \"IT\" مطلب \"it is\")"}
{"unnormalised": "", "normalised": "# एह् इक मुश्किल मसला ऐ; सादा रेगएक्स ज़्यादा आक्रामक होई सकदा ऐ।", "text": "यह इक मुशकल मसला ऐ; सादा regex बड़ी ज़्यादती कर सकदा ऐ।"}
{"unnormalised": "", "normalised": "# फिलहाल, इस नियम पर बने रहो: 2+ लगातार बड़े अक्षर।", "text": "ह्वाला फिलहाल, इस नियम ते टिके रेह्: 2+ लगातार बड़े अक्षर।"}
{"unnormalised": "", "normalised": "रिटर्न '-'.जॉइन(लिस्ट(एक्रोनिम))", "text": "वापस करा '-' कन्नै जोड़ीये आखरें दी सूची (acronym)"}
{"unnormalised": "", "normalised": "वापस acronym", "text": "रिटर्न एक्रोनम"}
{"unnormalised": "", "normalised": "# 2 या उस थमां मता लगातार बड्डे अक्षर ढूंढो, वैकल्पिक रूप कन्नै बिंदुएं दे कन्नै", "text": "## 2 या उसतो मतेदे लगातार बड़े अक्षर लब्बो, जिंदे नाल काल होंन दी बी संभावना ऐ"}
{"unnormalised": "", "normalised": "# नकारात्मक लुकबिहाइंड/लुकाहेड दा इस्तेमाल करदे होई \"IT\" जहे आम शब्दें गी बंडने थमां बचने दी कोशश करना,", "text": "नेगेटिव लुकबिहाइंड/लुकाहेड दा इस्तेमाल करीये आम शब्दें गी, जि’यां \"IT\" ऐ, तोड़ने थमां बचो, जे शक्य होई सकै तां,"}
{"unnormalised": "", "normalised": "# पर नियम सख्त ऐ: \"2+ लगातार बड्डी लिपि दे अक्षर\"।", "text": "पर नियम सख्त ऐ: \"2+ लगातार बड़े अक्षर\"।"}
{"unnormalised": "", "normalised": "# एह regex 2+ लगातार बड़े अक्षरें बारै सख्त ऐ, पीरियड निकालने दे बाद संभाले जांदे न।", "text": "एह रेजेक्स 2 थमां बधीक लगातार उप्परकेस अक्षरें बारै सख्त ऐ, पीरियड कढ्ढने दे बाद संभाले जांदे न।"}
{"unnormalised": "", "normalised": "टेक्स्ट = रे.सब(आर'\\b([ए-जेड][ए-जेड\\.]*[ए-जेड])\\b', रिप्लेस_एक्रोनिम, टेक्स्ट)", "text": "टेक्स्ट = री.सब(आर'\\b([ए-जेड][ए-जेड\\.]*[ए-जेड])\\b', रिप्लेस_एक्रोनम, टेक्स्ट)"}
{"unnormalised": "", "normalised": "टेक्स्ट = टेक्स्ट .replace('.', '') # प्रोसेसिंग करने दे बाद एक्रोनिम च अंदर बिंदुएं गी हटाओ", "text": "टेक्स्ट = टेक्स्टreplace('', '') # प्रोसेसिंग करने दे बाद संक्षेपें दे अंदर लेई पीरियड्स गी हटाओ"}
{"unnormalised": "", "normalised": "वापस टेक्स्ट करो", "text": "वापस पाठ करा।"}
{"unnormalised": "", "normalised": "तैं normalize_numbers(text):", "text": "तैं normalize_numbers(text):"}
{"unnormalised": "", "normalised": "\"\"\"इकल्ले नम्बरें, ते यूनिटें/करेंसी दे अंदर नंबरें गी बोली जाने वाली शकल च बदलदा ऐ।\"\"\"", "text": "स्टैंडअलोन नंबरें, ते यूनिटें/करेंसी दे अंदर नंबरें गी बोलचाल रूप च बदल्दा ऐ।"}
{"unnormalised": "", "normalised": "def replace_num(match):", "text": "डैफ रिप्लेस_नंबर(मैच):"}
{"unnormalised": "", "normalised": "num_str = match.group(1)", "text": "num_str = match.group(1)"}
{"unnormalised": "", "normalised": "रिटर्न नंबर_टू_वर्ड्स(नम_स्ट्रिंग)", "text": "रिटर्न नंबर_टू_वर्ड्स(नुम_स्ट्र)"}
{"unnormalised": "", "normalised": "# शब्दें दे अंदर नंबरें गी बदलो (उदाहरन केई, एच. नंबर 147)", "text": "# शब्दें च मौजूद नंबरें गी बदलो (उदाहरण के तौर पर, एच. नंबर 147)"}
{"unnormalised": "", "normalised": "# एह् पैटर्न उन नम्बरां गी पकड़ने दी कोशश करदा ऐ जेह्ड़े इक बड्डी पहचान दा हिस्सा न", "text": "एह् पैटर्न उन नम्बरां गी पकड़ने दी कोशिश करदा ऐ जेह्ड़े इक बड़े आइडेंटिफायर दा हिस्सा होंदे न।"}
{"unnormalised": "", "normalised": "टेक्स्ट = रे.सब(r'(\\bH\\. No\\. )(\\d+)', लैम्डा m: f\"{m.group(1)}{नंबर_टू_वर्ड्स(m.group(2))}\", टेक्स्ट)", "text": "टेक्स्ट = re.sub(r'(\\bH\\. No\\. )(\\d+)', lambda m: f\"{m.group(1)}{number_to_words(m.group(2))}\", टेक्स्ट)"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'(\\b[A-Z])(\\d+)', lambda m: f\"{m.group(1)}{number_to_words(m.group(2))}\", टेक्स्ट)", "text": "टेक्स्ट = re.sub(r'(\\b[A-Z])(\\d+)', lambda m: f\"{m.group(1)}{number_to_words(m.group(2))}\", टेक्स्ट)"}
{"unnormalised": "", "normalised": "# आम नंबर बदलने दा - इकाइयां / मुद्रा गी दोहरी प्रोसेसिंग थमां बचने आस्तै सावधानी बरतनी होग.", "text": "# आम नंबरें गी बदलोना - दोहरी प्रोसेसिंग यूनिटें/मुद्रा थमां बचनें आस्तै ध्यान कन्नै संभाल्लना जरूरी ऐ"}
{"unnormalised": "", "normalised": "# ऐह् अकेले नंबरें या उन नंबरें गी पकड़ी जेह्ड़े पैह्ले गै संभाले गेदे यूनिट/करेंसी दा हिस्सा नेईं न", "text": "ऐह् स्टैंडअलोन नंबरें गी जां ओह नंबरें गी पकड़ग जिह्ड़े किसें यूनिट/करेंसी दा हिस्सा नेईं न ते पहले गै संभाले गे न"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'\\b(\\d+)\\b', replace_num, टेक्स्ट)", "text": "टेक्स्ट = re.sub(r'\\b(\\d+)\\b', रिप्लेस_नंबर, टेक्स्ट)"}
{"unnormalised": "", "normalised": "वापस टेक्स्ट करो", "text": "वापस पाठ करा।"}
{"unnormalised": "", "normalised": "डिफाइन नॉर्मलाइज़ न्यूमेरिक सफिक्स (टेक्स्ट):", "text": "डिफाइन नॉर्मलाइज़ न्यूमेरिक सफिक्स (टेक्स्ट):"}
{"unnormalised": "", "normalised": "\"\"\"के, एम, बी, टी प्रत्ययें गी बधांदा ऐ।\"\"\"", "text": "के, एम, बी, टी दे प्रत्ययें गी बधौंदा ऐ।"}
{"unnormalised": "", "normalised": "def replace_suffix(match):", "text": "डेफ रिप्लेस_सफिक्स(मैच):"}
{"unnormalised": "", "normalised": "num = number_to_words(match.group(1))", "text": "num = match.group(1) गी शब्दें च बदलो"}
{"unnormalised": "", "normalised": "suffix = match.group(2).lower()", "text": "suffix = match.group(2).lower()"}
{"unnormalised": "", "normalised": "अगर suffix == 'k': रिटर्न f\"{num} हज़ार\"", "text": "अगर suffix == 'k': रिटर्न करो f\"{num} हज़ार\""}
{"unnormalised": "", "normalised": "अगर suffix == 'm': तो वापस करो \"{num} मिलियन\"", "text": "अगर सफ़िक्स == 'm': रिटर्न करो f\"{num} मिलियन\""}
{"unnormalised": "", "normalised": "अगर suffix == 'b': रिटर्न f\"{num} बिलियन\"", "text": "अगर पिछत्तर 'b' ऐ, तां \"{num} बिलियन\" वापस करो।"}
{"unnormalised": "", "normalised": "अगर सफिक्स == 't': रिटर्न करो \"{num} ट्रिलियन\"", "text": "अगर पछत्तर 't' ऐ, तां \"{num} खरब\" वापस करो"}
{"unnormalised": "", "normalised": "रिटर्न मैच.ग्रुप(0) # एह् नी होना चाहिदा", "text": "इह मैच.ग्रुप(0) वापस करो। # एह् नी होना चाहिदा।"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'(\\d+)([KMBT])\\b', रिप्लेस_सफिक्स, टेक्स्ट)", "text": "text = re.sub(r'(\\\\d+)([KMBT])\\\\b', replace_suffix, text)"}
{"unnormalised": "", "normalised": "वापस टेक्स्ट करो", "text": "वापस पाठ करा।"}
{"unnormalised": "", "normalised": "कुनें करेंसी दे नंबर दे आखिर च होर सुधारें (नार्मलाइज़) करने आळा।", "text": "कुनें करेंसी दे नंबर दे आखिर च होर सुधारें (नार्मलाइज़) करने आळा।"}
{"unnormalised": "", "normalised": "\"\"\"करेंसी गी नंबर ते प्रत्यय कन्नै मिलांदा ऐ।\"\"\"", "text": "पैह्ले मुद्रा, फिर नंबर ते अंत च सफिक्स लग्गांदा ऐ।"}
{"unnormalised": "", "normalised": "डेफ रिप्लेस_करेंसी_सफिक्स(मैच):", "text": "डिफ़ाइन रिप्लेस करेंसी सफ़िक्स (मैच):"}
{"unnormalised": "", "normalised": "करेंसी_सिंबल = मैच.ग्रुप(1)", "text": "करेंसी_सिंबल = मैच.ग्रुप(1)"}
{"unnormalised": "", "normalised": "num_str = match.group(2)", "text": "num_str = match.group(2)"}
{"unnormalised": "", "normalised": "suffix = match.group(3)", "text": "suffix = match.group(3)"}
{"unnormalised": "", "normalised": "मुद्रा_शब्द = \"\"", "text": "करेंसी_शब्द = \"\""}
{"unnormalised": "", "normalised": "अगर करेंसी_सिंबल == '$': करेंसी_वर्ड = 'डॉलर'", "text": "अगर करेंसी_सिंबल == '$': करेंसी_वर्ड = 'डॉलर'"}
{"unnormalised": "", "normalised": "अगर करेंसी_सिंबल == '₹': करेंसी_शब्द = 'रुपया'", "text": "तांही जेकर मुद्रा चह् न '₹' ऐ, तां मुद्रा शब्द 'रुपया' होग।"}
{"unnormalised": "", "normalised": "# होर मुद्राएं जरूरत मुजब जोड़ो", "text": "# होर करंसी दी लोड़ मुजब मताओ"}
{"unnormalised": "", "normalised": "num_words = number_to_words(num_str)", "text": "नम_वर्ड्स = नंबर_टू_वर्ड्स(नम_स्ट्र)"}
{"unnormalised": "", "normalised": "suffix_word = \"\"", "text": "suffix_word = \"\""}
{"unnormalised": "", "normalised": "अगर suffix.lower() == 'k': suffix_word = 'हजार'", "text": "अगर प्रत्यय.lower() == 'k': प्रत्यय_शब्द = 'हजार'"}
{"unnormalised": "", "normalised": "इयां जेकर suffix.lower() == 'm': suffix_word = 'million'", "text": "जेकर पिछत्तर अक्षर दा निचला रूप 'm' ऐ तां पिछत्तर शब्द होग 'मिलियन'"}
{"unnormalised": "", "normalised": "पर जेकर पिछत्तर अक्षर छोटा रूप च ‘b’ होए तां पिछत्तर शब्द होग ‘billion’", "text": "अगर सफ़िक्स दा स्तर छोटा करीये ते ओ 'b' दे बराबर होवे, तां सफ़िक्स दा शब्द 'अरब' होग।"}
{"unnormalised": "", "normalised": "अगर आखरी अक्षरtoLowerCase() विच 't' ऐ तां आखरी शब्द 'ट्रिलियन' होग।", "text": "अगर पुच्छलें अक्षर ''टी'' ऐ ते ओह् शब्द ''ट्रिलियन'' होग।"}
{"unnormalised": "", "normalised": "रिटर्न करो \"{currency_word} {num_words} {suffix_word}\"", "text": "वापस कराओ f\"{currency_word} {num_words} {suffix_word}\""}
{"unnormalised": "", "normalised": "# करेंसी सिंबल कन्नै नंबर ते सफिक्स दे पैटर्न", "text": "# मुद्रा प्रतीक दे बाद नंबर ते प्रत्यय दा पैटर्न"}
{"unnormalised": "", "normalised": "टेक्स्ट = रे.सब(r'([$₹€£])(\\d+)([केएमबीटी])\\b', रिप्लेस_करेंसी_सफिक्स, टेक्स्ट)", "text": "text = re.sub(r'([$₹€£])(\\d+)([KMBT])\\b', replace_currency_suffix, text)"}
{"unnormalised": "", "normalised": "# बी करेंसी + नंबर बिना सफिक्स दे बी संभाळो (ये सफिक्स आह्ले नियम दे बाद करना जरूरी ऐ)", "text": "तर्जुमा:\n\n# होर मुद्रा + प्रत्यय दे बगैर नंबर (प्रत्यय नियम दे बाद च करना होग)"}
{"unnormalised": "", "normalised": "डेफ रिप्लेस_करेंसी_नम(मैच):", "text": "def replace_currency_num(match):"}
{"unnormalised": "", "normalised": "करेंसी_सिंबल = मैच.ग्रुप(1)", "text": "करेंसी_सिंबल = मैच.ग्रुप(1)"}
{"unnormalised": "", "normalised": "num_str = match.group(2)", "text": "num_str = match.group(2)"}
{"unnormalised": "", "normalised": "मुद्रा_शब्द = \"\"", "text": "करेंसी_शब्द = \"\""}
{"unnormalised": "", "normalised": "अगर करेंसी_सिंबल == '$': करेंसी_वर्ड = 'डॉलर'", "text": "अगर करेंसी_सिंबल == '$': करेंसी_वर्ड = 'डॉलर'"}
{"unnormalised": "", "normalised": "अगर करेंसी_सिंबल == '₹': करेंसी_शब्द = 'रुपया'", "text": "तांही जेकर मुद्रा चह् न '₹' ऐ, तां मुद्रा शब्द 'रुपया' होग।"}
{"unnormalised": "", "normalised": "# होर मुद्राएं जरूरत मुजब जोड़ो", "text": "# होर करंसी दी लोड़ मुजब मताओ"}
{"unnormalised": "", "normalised": "num_words = number_to_words(num_str)", "text": "नम_वर्ड्स = नंबर_टू_वर्ड्स(नम_स्ट्र)"}
{"unnormalised": "", "normalised": "रिटर्न करो \"{currency_word} {num_words}\"", "text": "रिटर्न  f\"{currency_word} {num_words}\""}
{"unnormalised": "", "normalised": "टेक्स्ट = री.सब(आर'([$₹€£])(\\d+)\\b', रिप्लेस_करेंसी_नम, टेक्स्ट)", "text": "text = re.sub(r'([$₹€£])(\\d+)\\b', replace_currency_num, text)"}
{"unnormalised": "", "normalised": "वापस टेक्स्ट करो", "text": "वापस पाठ करा।"}
{"unnormalised": "", "normalised": "तारीखां गी सामान्य बनाने आस्तै (टेक्स्ट)।", "text": "तारीखां गी सामान्य बनाने आस्तै (टेक्स्ट)।"}
{"unnormalised": "", "normalised": "\"\"\"गिनती दी तरीखां गी कुदरती बोलने आले अंदाज़ च बदलोआ (DD/MM/YYYY अस्पष्टता आस्तै मन्नी गेई ऐ)।\"\"\"", "text": "\"\"\"गिनती आह्ली तारीखें गी कुदरती बोली जाने आह्ले रूप च बदल्दा ऐ (दुविधा आह्ली गल्ल लेई DD/MM/YYYY मन्या जांदा ऐ)।\"\"\""}
{"unnormalised": "", "normalised": "# DD-MM-YYYY या DD/MM/YYYY", "text": "# डीडी-एमएम-YYYY या डीडी/एमएम/YYYY"}
{"unnormalised": "", "normalised": "डेट बदली करो dmy(मेल मिलाप):", "text": "डेफ रिप्लेस_डेट_डीएमवाई(मैच):"}
{"unnormalised": "", "normalised": "दिन = int(match.group(1))", "text": "दिन = int(match.group(1))"}
{"unnormalised": "", "normalised": "महीना = इंट (मैच.ग्रुप(2))", "text": "महीना = int(match.group(2))"}
{"unnormalised": "", "normalised": "साल = इंट(मैच.ग्रुप(3))", "text": "साल = int(match.group(3))"}
{"unnormalised": "", "normalised": "महीने = [", "text": "महीने = ["}
{"unnormalised": "", "normalised": "\"\", \"जनवरी\", \"फरवरी\", \"मार्च\", \"अप्रैल\", \"मई\", \"जून\",", "text": "\"\", \"जनवरी\", \"फरवरी\", \"मार्च\", \"अप्रैल\", \"मई\", \"जून\","}
{"unnormalised": "", "normalised": "\"जुलाई\", \"अगस्त\", \"सितंबर\", \"अक्टूबर\", \"नवंबर\", \"दिसंबर\"", "text": "जुलाई\", \"अगस्त\", \"सितंबर\", \"अक्टूबर\", \"नवंबर\", \"दिसंबर\""}
{"unnormalised": "", "normalised": "]", "text": "]"}
{"unnormalised": "", "normalised": "वापस करो \"{p.ordinal(दिन)} {महीनेयां[महीना]} {संख्या_तो_शब्दें(स्ट्रिंग(साल))}\"", "text": "फर्ज़ करो \"{p.ordinal(day)} {months[month]} {number_to_words(str(year))}\" वापास करो।"}
{"unnormalised": "", "normalised": "text = re.sub(r'\\b(\\d{1,2})[-/](\\d{1,2})[-/](\\d{4})\\b', replace_date_dmy, text)", "text": "text = re.sub(r'\\b(\\d{1,2})[-/](\\d{1,2})[-/](\\d{4})\\b', replace_date_dmy, text)"}
{"unnormalised": "", "normalised": "# YYYY-MM-DD", "text": "# वाई-वाई-वाई-वाई-एम-एम-डी-डी"}
{"unnormalised": "", "normalised": "डेट_वाईएमडी(मिलान):", "text": "डेट बदलणें YMD (मेल)।"}
{"unnormalised": "", "normalised": "साल = इंट(मैच.ग्रुप(1))", "text": "साल = int(match.group(1))"}
{"unnormalised": "", "normalised": "महीना = इंट (मैच.ग्रुप(2))", "text": "महीना = int(match.group(2))"}
{"unnormalised": "", "normalised": "day = int(match.group(3))", "text": "दिन = int(match.group(3))"}
{"unnormalised": "", "normalised": "महीने = [", "text": "महीने = ["}
{"unnormalised": "", "normalised": "\"\", \"जनवरी\", \"फरवरी\", \"मार्च\", \"अप्रैल\", \"मई\", \"जून\",", "text": "\"\", \"जनवरी\", \"फरवरी\", \"मार्च\", \"अप्रैल\", \"मई\", \"जून\","}
{"unnormalised": "", "normalised": "\"जुलाई\", \"अगस्त\", \"सितंबर\", \"अक्टूबर\", \"नवंबर\", \"दिसंबर\"", "text": "जुलाई\", \"अगस्त\", \"सितंबर\", \"अक्टूबर\", \"नवंबर\", \"दिसंबर\""}
{"unnormalised": "", "normalised": "]", "text": "]"}
{"unnormalised": "", "normalised": "वापस करो \"{p.ordinal(दिन)} {महीनेयां[महीना]} {संख्या_तो_शब्दें(स्ट्रिंग(साल))}\"", "text": "फर्ज़ करो \"{p.ordinal(day)} {months[month]} {number_to_words(str(year))}\" वापास करो।"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'\\b(\\d{4})[-/](\\d{1,2})[-/](\\d{1,2})\\b', replace_date_ymd, टेक्स्ट)", "text": "text = re.sub(r'\\b(\\d{4})[-/](\\d{1,2})[-/](\\d{1,2})\\b', replace_date_ymd, text)"}
{"unnormalised": "", "normalised": "वापस टेक्स्ट करो", "text": "वापस पाठ करा।"}
{"unnormalised": "", "normalised": "डिफाइन नॉर्मलाइज़ यूनिट्स(टेक्स्ट):", "text": "डिफाइन नॉर्मलाइज़ यूनिट्स(टेक्स्ट):"}
{"unnormalised": "", "normalised": "\"\"\"यूनिटें गी पूरे शब्दें च फैलाई दिंदा ऐ।\"\"\"", "text": "\"\"\"इकाईयां गी पूरे शब्दें च फैलांदा ऐ।\"\"\""}
{"unnormalised": "", "normalised": "def replace_unit(match):", "text": "डेफ रिप्लेस यूनिट(मैच):"}
{"unnormalised": "", "normalised": "num_str = match.group(1)", "text": "num_str = match.group(1)"}
{"unnormalised": "", "normalised": "unit = match.group(2).lower()", "text": "यूनिट = मैच.ग्रुप(2).लोअर()"}
{"unnormalised": "", "normalised": "num_words = number_to_words(num_str)", "text": "नम_वर्ड्स = नंबर_टू_वर्ड्स(नम_स्ट्र)"}
{"unnormalised": "", "normalised": "unit_map = {", "text": "यूनिट_मैप = {"}
{"unnormalised": "", "normalised": "'cm': 'सेंटीमीटर', 'mm': 'मिलीमीटर', 'm': 'मीटर', 'km': 'किलोमीटर',", "text": "'cm': 'सेंटीमीटर', 'mm': 'मिलीमीटर', 'm': 'मीटर', 'km': 'किलोमीटर',"}
{"unnormalised": "", "normalised": "'g': 'ग्राम', 'kg': 'किलोग्राम', 'mg': 'मिलीग्राम',", "text": "'g': 'ग्राम', 'kg': 'किलोग्राम', 'mg': 'मिलीग्राम',"}
{"unnormalised": "", "normalised": "'ml': 'मिलीलीटर', 'l': 'लीटर', 'kph': 'किलोमीटर प्रति घंटा',", "text": "'ml': 'मिलीलीटर', 'l': 'लीटर', 'kph': 'किलोमीटर प्रति घंटा',"}
{"unnormalised": "", "normalised": "'mph': 'मील प्रति घंटा', 'hz': 'हर्ट्ज़', 'khz': 'किलोहर्ट्ज़',", "text": "'mph': 'मील प्रति घंटा', 'hz': 'हर्ट्ज़', 'khz': 'किलोहर्ट्ज़',"}
{"unnormalised": "", "normalised": "'mhz': 'मेगाहर्ट्ज़', 'ghz': 'गीगाहर्ट्ज़', 'mb': 'मेगाबाइट',", "text": "'mhz': 'मेगाहर्ट्ज़', 'ghz': 'गीगाहर्ट्ज़', 'mb': 'मेगाबाइट',"}
{"unnormalised": "", "normalised": "'gb': 'गीगाबाइट', 'tb': 'टेराबाइट', 'kb': 'किलोबाइट',", "text": "'gb': 'गीगाबाइट', 'tb': 'टेराबाइट', 'kb': 'किलोबाइट',"}
{"unnormalised": "", "normalised": "'sec': 'सेकंड', 'min': 'मिनट', 'hr': 'घंटा',", "text": "'sec': 'सेकंड', 'min': 'मिनट', 'hr': 'घंटा',"}
{"unnormalised": "", "normalised": "'usd': 'यूएस डॉलर', 'eur': 'यूरो', 'gbp': 'पाउंड स्टर्लिंग',", "text": "'usd': 'अमेरिकी डॉलर', 'eur': 'यूरो', 'gbp': 'पाउंड स्टर्लिंग',"}
{"unnormalised": "", "normalised": "'ft': 'फुट', 'in': 'इंच', 'yd': 'यार्ड', 'sqm': 'स्क्वायर मीटर',", "text": "'ft': 'फुट', 'in': 'इंच', 'yd': 'यार्ड', 'sqm': 'स्क्वेयर मीटर',"}
{"unnormalised": "", "normalised": "'sqkm': 'स्क्वेयर किलोमीटर', 'sqft': 'स्क्वेयर फुट',", "text": "'sqkm': 'स्क्वेयर किलोमीटर', 'sqft': 'स्क्वेयर फुट',"}
{"unnormalised": "", "normalised": "'c': 'सैल्सियस', # पैह्ले °C आस्तै खास संभाळ, पर सिर्फ C आस्तै, एह् अस्पष्ट ऐ। डिग्री मनदे होईये।", "text": "'c': 'सेल्सियस', # पैह्ले °C आस्तै खास देखभाल, पर सिर्फ C आस्तै, एह् अस्पष्ट ऐ। डिगरी मन्नी दा ऐ।"}
{"unnormalised": "", "normalised": "'f': 'फारेनहाइट' # मनना ऐ जे 'F' डिग्री लेई ऐ", "text": "'f': 'फारेनहाइट' # मनने दा डिग्री 'F' लेई"}
{"unnormalised": "", "normalised": "}", "text": "}"}
{"unnormalised": "", "normalised": "# °C लेई खास मामला, जिन्नै नूं पहले सिंबल्स च हैंडल कीता गेआ ऐ।", "text": "# °C आह्लि ख़ास हालत, जेह्ड़ी पैह्ले प्रतीक च निबड़ी गेई ऐ।"}
{"unnormalised": "", "normalised": "अगर यूनिट == 'c':", "text": "अगर यूनिट == 'c':"}
{"unnormalised": "", "normalised": "# जेकर कुसी नंबर थमां पैहले ऐ, तां \"डिग्री सेल्सियस\" मन्नी लैओ", "text": "अगर अग्गे कोई नंबर हो, तां \"डिग्री सेल्सियस\" मन्नी लेओ"}
{"unnormalised": "", "normalised": "अगर re.search(r'\\b\\d+\\s*$', match.string[:match.start()], re.IGNORECASE):", "text": "अगर re.search(r'\\b\\d+\\s*$', match.string[:match.start()], re.IGNORECASE):"}
{"unnormalised": "", "normalised": "वापस करो \"{num_words} डिग्री सेल्सियस\"", "text": "वापस कर \"{num_words} डिग्री सेल्सियस\""}
{"unnormalised": "", "normalised": "रिटर्न करो f\"{num_words} {unit_map.get(unit, unit)}\"", "text": "फर्ज़ करो \"{num_words} {unit_map.get(unit, unit)}\" गी वापस करो।"}
{"unnormalised": "", "normalised": "रिटर्न करदा ऐ \"{num_words} {unit_map.get(unit, unit)}\"", "text": "फर्ज़ करो \"{num_words} {unit_map.get(unit, unit)}\" गी वापस करो।"}
{"unnormalised": "", "normalised": "# एह regex बक्ख-बक्ख यूनिट लेई मजबूत ऐ ते यूनिट थमां पहले नंबर सुनिश्चित करदा ऐ", "text": "ऐह रेगॅक्स बक्ख-बक्ख यूनिट्स लेई मजबूत ऐ ते यूनिट थमां पहले नंबर यकीनी बनांदा ऐ।"}
{"unnormalised": "", "normalised": "# एह् संख्या ते इकाई गी अलग-अलग कैद करने दी कोशश करदा ऐ", "text": "ऐ नंबर ते यूनिट गी अलग-अलग हासल करने दी कोशिश करदा ऐ।"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.सब (r'\\b(\\d+(?:\\.\\d+)?)\\s*(cm|mm|m|km|g|kg|mg|ml|l|kph|mph|hz|khz|mhz|ghz|mb|gb|tb|kb|sec|min|hr|usd|eur|gbp|ft|in|yd|sqm|sqkm|sqft|[CF])\\b', रिप्लेस_यूनिट, टेक्स्ट, फ्लैग्स=re.IGNORECASE)", "text": "text = re.sub(r'\\b(\\d+(?:\\.\\d+)?)\\s*(cm|mm|m|km|g|kg|mg|ml|l|kph|mph|hz|khz|mhz|ghz|mb|gb|tb|kb|sec|min|hr|usd|eur|gbp|ft|in|yd|sqm|sqkm|sqft|[CF])\\b', replace_unit, text, flags=re.IGNORECASE)"}
{"unnormalised": "", "normalised": "वापस टेक्स्ट करो", "text": "वापस पाठ करा।"}
{"unnormalised": "", "normalised": "गणितीय लेखन दे ढंग गी सामान्य बनाने आह्ली परिभाषा (टेक्स्ट)।", "text": "गणितीय लेखन दे ढंग गी सामान्य बनाने आह्ली परिभाषा (टेक्स्ट)।"}
{"unnormalised": "", "normalised": "\"\"\"गणितीय प्रतीकें ते भावें गी बोले च बदलने दा इक उपकरण।\"\"\"", "text": "गणितीय प्रतीकें ते अभिव्यक्तियें गी बोलने आह्ला रूप च बदल्दा ऐ।"}
{"unnormalised": "", "normalised": "# तरतीब ज़रूरी ऐ। पैह्ले मता खास पैटर्न।", "text": "# तरतीब जरूरी ऐ। पैह् ले मता खास पैटर्न।"}
{"unnormalised": "", "normalised": "# a शां b तांईं इंटीग्रल", "text": "a ती b तक इंटीग्रल"}
{"unnormalised": "", "normalised": "text = re.sub(r'∫\\s*(\\d+)→(\\d+)\\s*(.*?)\\s*d([a-zA-Z])',", "text": "मै री.सब (आर'∫\\s*(\\d+)→(\\d+)\\s*(.*?)\\s*d([a-zA-Z])',"}
{"unnormalised": "", "normalised": "lambda m: f\"इंटीग्रल {number_to_words(m.group(1))} शां {number_to_words(m.group(2))} तिकर दा {m.group(3).strip()} डी {m.group(4)}\",", "text": "lambda m: f\"इंटीग्रल {number_to_words(m.group(1))} थमां {number_to_words(m.group(2))} तिकर दा {m.group(3).strip()} d {m.group(4)}\","}
{"unnormalised": "", "normalised": "टेक्स्ट)", "text": "text)"}
{"unnormalised": "", "normalised": "# आम इंटिग्रल", "text": "आम इंटीग्रल"}
{"unnormalised": "", "normalised": "टेक्स्ट = रे.सब(r'∫\\s*(.*?)\\s*d([a-zA-Z])',", "text": "∫ (∗ ∗) d(∗)"}
{"unnormalised": "", "normalised": "lambda m: f\"integral of {m.group(1).strip()} d {m.group(2)}\",", "text": "lambda m: f\"{m.group(1).strip()} d {m.group(2)} दा इंटिग्रल\","}
{"unnormalised": "", "normalised": "टेक्स्ट)", "text": "text)"}
{"unnormalised": "", "normalised": "# ताकतां (x^2, x^3, x^n)", "text": "# शक्तियाँ (x^2, x^3, x^n)"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'([a-zA-Z])\\^2', r'\\1 स्क्वेर्ड', टेक्स्ट)", "text": "टेक्स्ट = री.सब(r'([a-zA-Z])\\^2', r'\\1 स्क्वायर्ड', टेक्स्ट)"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'([a-zA-Z])\\^3', r'\\1 क्यूबड़', टेक्स्ट)", "text": "text = re.sub(r'([a-zA-Z])\\^3', r'\\1 घन', text)"}
{"unnormalised": "", "normalised": "text = re.sub(r'([a-zA-Z])\\^([a-zA-Z0-9]+)', r'\\1 दी ताकत \\2', text) # x^n", "text": "येह् टेक्स्ट गी डोगरी च अनुवाद करो। सिर्फ अनुवाद गै वापस करो; मूल लाइन ब्रेक ते स्पेसिंग बनाई रक्खो।\n\ntext = re.sub(r'([a-zA-Z])\\^([a-zA-Z0-9]+)', r'\\1 दी पावर \\2', text) # x^n"}
{"unnormalised": "", "normalised": "पाइ आर स्क्वायर्ड (खास मामला)", "text": "पाई आर स्केयर्ड (स्पेसिफिक केस)"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'πr\\^2', 'pi r squared', टेक्स्ट)", "text": "टेक्स्ट = री.सब(r'πr\\^2', 'पाई आर स्क्वायर्ड', टेक्स्ट)"}
{"unnormalised": "", "normalised": "text = re.sub(r'π([a-zA-Z])\\^2', r'पाई \\1 स्क्वेयर्ड', टेक्स्ट) # पाई a^2 लेई", "text": "टेक्स्ट = re.sub(r'π([a-zA-Z])\\^2', r'pi \\1 squared', टेक्स्ट) # पाई ए ^2 आस्तै"}
{"unnormalised": "", "normalised": "# वर्गमूल", "text": "वर्गमूल"}
{"unnormalised": "", "normalised": "text = re.sub(r'√([a-zA-Z0-9]+)', r'\\1 दा वर्गमूल', text)", "text": "टेक्स्ट = re.sub(r'√([a-zA-Z0-9]+)', r'square root of \\1', text)"}
{"unnormalised": "", "normalised": "# जोड़ (Σ x_i)", "text": "जोड़ (Σ x_i)"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'Σ\\s*([a-zA-Z])_([a-zA-Z0-9]+)', r'समेशन ऑफ़ \\1 सब \\2', टेक्स्ट)", "text": "Text = पाठ = re.sub(r'Σ\\s*([a-zA-Z])_([a-zA-Z0-9]+)', r'summation of \\1 sub \\2', text)"}
{"unnormalised": "", "normalised": "टेक्स्ट = re.sub(r'Σ\\s*([a-zA-Z])', r'summation of \\1', टेक्स्ट)", "text": "text = re.sub(r'Σ\\s*([a-zA-Z])', r'summation of \\1', text)"}
{"unnormalised": "", "normalised": "# Subscripts (x_i) - पक्का करो की एह दूये पैटनें कन्नै रलदा नईं ऐ", "text": "सबस्क्रिप्ट (x_i) - इस गल्लै गी पक्का करो के ए होर पैटर्नें कन्नै ना रले"}
{"unnormalised": "", "normalised": "टेक्स्ट = री.सब(r'([a-zA-Z])_([a-zA-Z0-9]+)', r'\\1 सब \\2', टेक्स्ट)", "text": "टेक्स्ट = re.sub(r'([a-zA-Z]) सब ([a-zA-Z0-9]+)', r'\\1 सब \\2', टेक्स्ट)"}
{"unnormalised": "", "normalised": "वापस टेक्स्ट करो", "text": "वापस पाठ करा।"}
{"unnormalised": "", "normalised": "डिफ़ाइन नॉर्मलाइज़_टेक्स्ट(टेक्स्ट):", "text": "डिफ़ाइन नॉर्मलाइज़_टेक्स्ट(टेक्स्ट):"}
{"unnormalised": "", "normalised": "\"\"\"सारे सामान्यीकरण नियमें गी इक तर्कसंगत क्रम च लागू करदा ऐ।\"\"\"", "text": "तमाम नॉर्मलाइजेशन नियमें गी इक लॉजिकल ऑर्डर च लागू करदा ऐ।"}
{"unnormalised": "", "normalised": "# 1. गणितीय प्रतीक (पैह्ले खास अभिव्यक्ति)", "text": "# 1. रियाज़ी लिखत (पहले खास जुमला)"}
{"unnormalised": "", "normalised": "टेक्स्ट = मैथमेटिकल नोटेशन गी नॉर्मलाइज करो(टेक्स्ट)", "text": "टेक्स्ट = नॉरमलाइज_मैथेमेटिकल_नोटेशन(टेक्स्ट)"}
{"unnormalised": "", "normalised": "# २. निशानियाँ (गणित दे निशानें दे बाद ३/४ जेहे अंश समेत)", "text": "# 2. प्रतीक (गणित दे प्रतीकें दे बाद 3/4 जेह्ड़े अंश शामल न)"}
{"unnormalised": "", "normalised": "text = symbols_ह्नाँ दा सामान्यीकरण कर", "text": "टेक्स्ट = सिम्बल्स गी सामान्य बनाओ (टेक्स्ट)।"}
{"unnormalised": "", "normalised": "# 3. गिनती वाले पुच्छल (जियां कि, के, एम, बी, टी)", "text": "# 3. अंकांऽचै पुछल्ला (मिसाल लेई, के, एम, बी, टी)"}
{"unnormalised": "", "normalised": "टेक्स्ट = न्यूमेरिक प्रत्ययें गी सामान्य करो(टेक्स्ट)", "text": "पाठ = नॉर्मलाइज़_न्यूमेरिक_सफ़िक्स (पाठ)"}
{"unnormalised": "", "normalised": "# ४. मुद्रा + नंबर + प्रत्यय", "text": "# 4. मुद्रा + संख्या + प्रत्यय"}
{"unnormalised": "", "normalised": "टेक्स्ट = नॉर्मलाईज़_करेंसी_नंबर_सफ़िक्स(टेक्स्ट)", "text": "text = currency_number_suffix_samanya_banaao(text)"}
{"unnormalised": "", "normalised": "# 5. तारीखां", "text": "# 5. तिआरीखां"}
{"unnormalised": "", "normalised": "text = normalize_dates(text)", "text": "टेक्स्ट = normalize_dates(टेक्स्ट)"}
{"unnormalised": "", "normalised": "# 6. यूनिट (आम नंबर बदली करने थमां पहले आने चाहिदे न)", "text": "# 6. इकाईयां (आम नंबर बदलने थमां पहले आनी चाहिदीयां न)"}
{"unnormalised": "", "normalised": "टेक्स्ट = नार्मलाइज़_यूनिट्स(टेक्स्ट)", "text": "टेक्स्ट = नॉर्मलाइज_यूनिट्स(टेक्स्ट)"}
{"unnormalised": "", "normalised": "# 7. संक्षेप (गिनती थमां पैह्लै \"USA\" गी \"U-S-A\" च बंडने थमां बचने आस्तै)", "text": "# 7. अक्खर-संक्षेप (गिनतियाँ थमां पैह्ले तां जो \"USA\" गी \"U-S-A\" विच बंडने थमां बचेई सकचे)"}
{"unnormalised": "", "normalised": "टेक्स्ट = एक्रोनिमां गी सामान्य करो (टेक्स्ट)", "text": "टेक्स्ट = एब्रीविएशन्स गी नॉर्मलाइज़ करो।"}
{"unnormalised": "", "normalised": "# 8. आम नंबर (आखरी, बचे दे कोई बी नंबरें गी पकड़ने लेई)", "text": "# ८. आम नंबर (आखरी, कोई बचे होए नंबरें गी पकड़ने वास्ते)"}
{"unnormalised": "", "normalised": "text = normalize_numbers(text)", "text": "टेक्स्ट = नॉर्मलाइज़_नम्बर्ज़(टेक्स्ट)"}
{"unnormalised": "", "normalised": "# आखिरी सफाई", "text": "# आखिरी सफाई"}
{"unnormalised": "", "normalised": "टेक्स्ट = री.सब(र'\\s+', ' ', टेक्स्ट).स्ट्रिप() # स्पेसें गी नॉर्मलाइज़ करो", "text": "टेक्स्ट = रे.सब(r'\\s+', ' ', टेक्स्ट).स्ट्रिप() # स्पेसें गी नॉर्मलाईज़ करो"}
{"unnormalised": "", "normalised": "वापस टेक्स्ट करो", "text": "वापस पाठ करा।"}
{"unnormalised": "", "normalised": "डेफ प्रोसेस_फोल्डर(सोर्स_फोल्डर, डेस्टिनेशन_फोल्डर):", "text": "डेफ प्रोसेस_फोल्डर(सोर्स_फोल्डर, डेस्टिनेशन_फोल्डर):"}
{"unnormalised": "", "normalised": "माफ़ करना, मैं एह् करने च असमर्थ हां। मैं अभी तक डोगरी च अनुवाद करने लेई प्रशिक्षित नीं हां।", "text": "ठीक ऐ। मेईं दस्सो पाठ की ऐ जिह्नु तुस अनुवाद करना चांह्दे ओ।\n\"\"\""}
{"unnormalised": "", "normalised": "सोर्स फोल्डर विच घूमो, .txt फाइलें गी सामान्य करो,", "text": "सोर्स फोल्डर च घूम्दा ऐ, .txt फाइलें गी सामान्य करदा ऐ,"}
{"unnormalised": "", "normalised": "अते होर फाइलें गी मंजिल आले फोल्डर च कॉपी करदा ऐ।", "text": "ते होर फाइलें गी मंज़ल फोल्डर च कॉपी करदा ऐ।"}
{"unnormalised": "", "normalised": "माफ़ करना, मैं एह् करने च असमर्थ हां। मैं अभी तक डोगरी च अनुवाद करने लेई प्रशिक्षित नीं हां।", "text": "ठीक ऐ। मेईं दस्सो पाठ की ऐ जिह्नु तुस अनुवाद करना चांह्दे ओ।\n\"\"\""}
{"unnormalised": "", "normalised": "अगर os.path.exists(destination_folder):", "text": "अगर os.path.exists(destination_folder):"}
{"unnormalised": "", "normalised": "प्रिंट (f\"मंज़िल फ़ोल्डर '{destination_folder}' पेहलेई मौजूद ऐ। डिलीट करी रेहआ ऐ ते दुबारा बनाई रेहआ ऐ।\")", "text": "प्रिंट (f\"मंजल वाला फ़ोल्डर '{destination_folder}' पैह्लेई मौजूद ऐ। मिटाई के दुबारा बनाई जा करदा ऐ।\")"}
{"unnormalised": "", "normalised": "shutil.rmtree(destination_folder)", "text": "शटल.आरएमट्री(डेस्टिनेशन_फोल्डर)"}
{"unnormalised": "", "normalised": "os.makedirs(destination_folder)", "text": "ओऽस॰मेकमैडिस (डेस्टिनेशन_फोल्डर)"}
{"unnormalised": "", "normalised": "प्रिंट (f\"बनाया गया मंज़िल फ़ोल्डर: {destination_folder}\")", "text": "बणाई दित्ती गंतव्य फोल्डर: {destination_folder}"}
{"unnormalised": "", "normalised": "मानकीकृत_गिनती = 0", "text": "मानकीकृत_गिनती = 0"}
{"unnormalised": "", "normalised": "कापी_गिनती = 0", "text": "नक़ल_गिनती = 0"}
{"unnormalised": "", "normalised": "नॉन_नॉर्मलाइज्ड_टीएक्सटी_फाइल्स = [] # इह् करंट लॉजिक कन्नै खाली होग, क्योंजे सारे प्रोसेस कीते जांदे न", "text": "नाॅट_नार्मलाईज़ड_टीएक्सटी_फाइलां = []  # इस करंट लाॅजिक कन्नै खाली होग, क्येंजे सारे प्रोसेस कीते जा करदे न"}
{"unnormalised": "", "normalised": "तांह् रूट, _, फाइलें ओस्स.वॉक(सोर्स_फोल्डर) विच होंदीं:", "text": "ताह् रूट, _, फाइलें ओएस.वाल्क(सोर्स_फोल्डर) च:"}
{"unnormalised": "", "normalised": "relative_path = os.path.relpath(root, source_folder)", "text": "relative_path = os.path.relpath(root, source_folder)"}
{"unnormalised": "", "normalised": "current_dest_dir = os.path.join(destination_folder, relative_path)", "text": "मौजूदा_मंजिल_डायरेक्ट्री = os.path.join(मंजिल_फोल्डर, सापेक्ष_पथ)"}
{"unnormalised": "", "normalised": "os.makedirs(current_dest_dir, exist_ok=True)", "text": "os.makedirs(current_dest_dir, exist_ok=True)"}
{"unnormalised": "", "normalised": "फाइलें च हर फाइलनेम लेई:", "text": "फाइलें च filename वास्ते:"}
{"unnormalised": "", "normalised": "source_file_path = os.path.join(root, filename)", "text": "source_file_path = os.path.join(root, filename)"}
{"unnormalised": "", "normalised": "dest_file_path = os.path.join(current_dest_dir, filename)", "text": "dest_file_path = os.path.join(current_dest_dir, filename)"}
{"unnormalised": "", "normalised": "अगर फाइल नेम दा लोअर केस विच आखरी अक्षर '.txt' हे तां:", "text": "अगर फाइलनाम.लोअर().आखिर विच '.txt' नाल खतम होंदा ऐ:"}
{"unnormalised": "", "normalised": "कोशिश करो:", "text": "कोशिश करो:"}
{"unnormalised": "", "normalised": "खुल्ली फाइल (source_file_path, 'r', encoding='utf-8') ऐस नाल:", "text": "नाले source_file_path, 'r', encoding='utf-8' च लिखी फाइल गी f दे रूप च खोलो:"}
{"unnormalised": "", "normalised": "content = f.पढ़ी लेई।", "text": "content = f.पढ़ी दी।"}
{"unnormalised": "", "normalised": "normalized_content = normalize_पाठ (content)", "text": "normalized_content = सामान्य कीत्ती गेई सामग्री"}
{"unnormalised": "", "normalised": "खुल्लै फाइल_पाथ खोलो, 'w', एन्कोडिंग='utf-8' एस f:", "text": "खोली के फाइल_पाथ, 'w', एनकोडिंग='utf-8' विच एस फाईल साथ:"}
{"unnormalised": "", "normalised": "f.write(normalized_content)", "text": "ऍफ़.राईट(नार्मलाईज़्ड_कंटेंट)"}
{"unnormalised": "", "normalised": "normalized_count += 1", "text": "नॉर्मलाइज्ड_काउंट += 1"}
{"unnormalised": "", "normalised": "# print(f\"Normalized: {source_file_path}\")\n                    # प्रिंट(f\"नॉर्मलाइज़्ड: {source_file_path}\")", "text": "# प्रिंट(f\"नार्मलाइज़्ड: {सोर्स_फाइल_पाथ}\")"}
{"unnormalised": "", "normalised": "सिवाय Exception ऐह् ऐ:", "text": "सिवाException दे जिआं e:"}
{"unnormalised": "", "normalised": "प्रिंट(f\"एरर नॉर्मलाइज करदे होई {source_file_path}: {e}\")", "text": "print(f\"एरर नॉर्मलाईज करदे बेल्लै {source_file_path}: {e}\")"}
{"unnormalised": "", "normalised": "not_normalized_txt_files विच source_file_path जोड़ देओ।", "text": "not_normalized_txt_files.append(source_file_path)"}
{"unnormalised": "", "normalised": "# ऐरर होआ, तां जिंयां ऐ, तैंयां नकल करो जां चाही दी ऐरर हैंडलिंग दे मुजब खाली छड्डी देओ", "text": "# जो कोई गलती हो, तो उवेई दी उवेई कॉपी करो या फेर अपनी मर्जी दे हिसाब कन्नै खाली छोड़ो"}
{"unnormalised": "", "normalised": "शटल.कॉपी2(सोर्स_फाइल_पाथ, डेस्ट_फाइल_पाथ)", "text": "शटल.कॉपी2(सोर्स_फाइल_पाथ, डेस्ट_फाइल_पाथ)"}
{"unnormalised": "", "normalised": "नै तां:", "text": "नैं तां:"}
{"unnormalised": "", "normalised": "shutil.copy2(source_file_path, dest_file_path)", "text": "शटल.कॉपी2(सोर्स_फाइल_पाथ, डेस्ट_फाइल_पाथ)"}
{"unnormalised": "", "normalised": "कापी_गिनती += 1", "text": "नकल_गिनती += 1"}
{"unnormalised": "", "normalised": "# print(f\"कापी कीती (बिना बदलाव दे): {source_file_path}\")", "text": "# प्रिंट(फ\"कॉपी (बिना बदले): {source_file_path}\")"}
{"unnormalised": "", "normalised": "प्रिंट(f\"\\n--- प्रोसेसिंग सार ---\")", "text": "प्रिंट(f\"\\n--- प्रोसेसिंग सार ---\")"}
{"unnormalised": "", "normalised": "प्रिंट (f\"टेक्स्ट फाइलें नॉर्मलाइज्ड: {नॉर्मलाइज्ड_काउंट}\")", "text": "टेक्स्ट फाइलें नॉर्मलाईज़्ड: {normalized_count}"}
{"unnormalised": "", "normalised": "print(f\"बाक़ी फाइलें कॉपी करी दित्तियां: {copied_count}\")", "text": "बाक़ी फाइलें नक़ल करी दित्ती: {copied_count}"}
{"unnormalised": "", "normalised": "अगर not_normalized_txt_files:", "text": "जेकर नॉट_नॉर्मलाइज्ड_टीएक्सटी_फाइल्स नीं ऐ:"}
{"unnormalised": "", "normalised": "प्रिंट(\"\\nफाइलें जेह्ड़ियां गलतियां दे कारण सामान्य *नहीं* कीतियां जाईयां (ज्यों दी त्यों कॉपी कीतियां गईं):\")", "text": "प्रिंट(\"\\nफाइलें जेह्ड़ियां गलतियें दे कारण सामान्य नेईं कीतियां गेइयां (जिंवें दीयां तियां कापी कीतियां गेइयां):\")"}
{"unnormalised": "", "normalised": "फॉर f इन नॉट_नॉरमलाइज़्ड_txt_फाइल्स:", "text": "फॉर f इन नॉट_नॉर्मलाइज्ड_टीएक्सटी_फाइल्स:"}
{"unnormalised": "", "normalised": "छापो(f\"- {f}\")", "text": "- {f}"}
{"unnormalised": "", "normalised": "नहीं ते:", "text": "नैं तां:"}
{"unnormalised": "", "normalised": "सारे .txt फाइलें सफलतापूर्वक प्रोसेस होई गेईयां।", "text": "सारे .txt फाइलें सफलता पूर्वक प्रोसेस होई गेईयां।"}
{"unnormalised": "", "normalised": "# --- मुख्य निष्पादन खंड ---", "text": "# --- मुख्य निष्पादन खंड ---"}
{"unnormalised": "", "normalised": "अगर __name__ == \"__main__\":", "text": "अगर __name__ == \"__main__\":"}
{"unnormalised": "", "normalised": "# डिमॉन्स्ट्रेशन लेई इक नकली सोर्स फोल्डर ते फाइल बनाओ", "text": "# इक नकली सोर्स फोल्डर ते फाइल डेमोस्ट्रेशन दे खातर बनाओ"}
{"unnormalised": "", "normalised": "# असली परिदृश्य च, तुसां source_folder गी अपने असल डेटा उप्पर point करना होग।", "text": "असली परिदृश्य च, तुहां source_folder गी अपने असल डेटा की ओर इशारा करदे ओ।"}
{"unnormalised": "", "normalised": "dummy_source_folder = 'dataset_raw'", "text": "dummy_source_folder = 'dataset_raw'"}
{"unnormalised": "", "normalised": "dummy_destination_folder = 'dataset_normalized'", "text": "dummy_destination_folder = 'dataset_normalized'"}
{"unnormalised": "", "normalised": "dummy_txt_filepath = os.path.join(dummy_source_folder, 'blog_posts', 'goa_addresses.txt')", "text": "dummy_txt_filepath = os.path.join(dummy_source_folder, 'blog_posts', 'goa_addresses.txt')"}
{"unnormalised": "", "normalised": "dummy_image_filepath = os.path.join(dummy_source_folder, 'images', 'beach.jpg')", "text": "dummy_image_filepath = os.path.join(dummy_source_folder, 'images', 'beach.jpg')"}
{"unnormalised": "", "normalised": "# नक़ली स्रोत निर्देशिकां दा होना पक्का करो", "text": "# नकली स्रोत डायरेक्टरीयां होंदीआं न, ऐह् यकीनी बनाओ"}
{"unnormalised": "", "normalised": "os.makedirs(os.path.dirname(dummy_txt_filepath), exist_ok=True)", "text": "os.makedirs(os.path.dirname(dummy_txt_filepath), exist_ok=True)"}
{"unnormalised": "", "normalised": "os.makedirs(os.path.dirname(dummy_image_filepath), exist_ok=True)", "text": "os.makedirs(os.path.dirname(dummy_image_filepath), exist_ok=True)"}
{"unnormalised": "", "normalised": "# तुंदे ब्लॉग पोस्ट दी सामग्री", "text": "तुहाड़ी ब्लॉग पोस्ट दी सामग्री"}
{"unnormalised": "", "normalised": "\"\"\"", "text": "\"\"\""}
{"unnormalised": "", "normalised": "अनुवाद विच खोई: मेरी भारतीय पतेयां दे कन्नै साहसिक कम्म (ते तुहां गी जीपीएस दी लोड़ क्यों ऐ)", "text": "अनुवाद च खोईये: भारतीय पत्तयां कन्नै मेरी साहसिक यात्रा (ते तुहां गी GPS दी क्यों लोड़ ऐ)"}
{"unnormalised": "", "normalised": "ते, मैं सोचदा हां कि मैं बड़ा चालाक हां, तुस जाने ओ? मैं पीक आवर्स दे दौरान दिल्ली मेट्रो च नेविगेट कीता ऐ, चांदनी चौक च इक साड़ी ते सबसे अच्छी कीमत ते मोलभाव कीता ऐ, ते एह् तक कि मैं दूध दे बिना चाय दा आर्डर देने च कामयाब हो गया (इक कारनामा, मेरा विश्वास करो)। पर फिर आए पत्ते। ओह, पत्ते!", "text": "ते, मैं सोचदा हा कि मैं बड़ा सयाना हां, तुसां जानदे ओ? मैं दिल्ली मेट्रो विच भीड-भाड़ वाले समय विच नेविगेट कीता ऐ, चांदनी चौक विच इक साड़ी पर बढ़िया कीमत लाने खातर मोल-भाव कीता ऐ, ते इथे तक कि चाय विच दुद्ध पौने थ्हो बिना चाय मंगवाने दा प्रबंध वी कीता ऐ (मैनु भरोसा ऐ, इक कमाल ऐ)। पर फिर आए पता। ओह, पता!"}
{"unnormalised": "", "normalised": "मैनूँ मंज़र बयान करने दे: मैं गोवा च इस मनमोहक निक्के गेस्टहाउस ढूँढने दे मिशन पर था। सुनिया बड़ा ही शांत ते प्यारा लग्गदा ऐ, है ना? बुकिंग दी पुष्टि खुश होइयै ऐलान करदी ही: \"आनंद विला, एच. नं. 147/ए, सेंट एलेक्स चर्च दे नेड़े, कलंगुट, बारदेज़, गोवा 403516।\" बड़ा आसान ऐ, मैं सोचया। आखरी शब्द मशहूर होए।", "text": "मैनु मंजर दस्सन दे: मैं गोवा च एह् मनमोहक निक्का गेस्टहाउस लभने दे मिशन पर हा। स्वर्ग जियां लग्गदा हा, है ना? बुकिंग पुष्टीकरण खुश होईये ऐ ऐलान कित्ता: \"आनंद विला, एच. नं. 147/ए, सेंट एलेक्स चर्च दे नेड़े, कलंगुट, बारदेज़, गोवा 403516।\" मै सोचिया बड़ा आसान ऐ। आखरी शब्द मशहूर।"}
{"unnormalised": "", "normalised": "पहल्ला, \"एच. न. 147/ए.\" मैन समझया ऐ घर दा नम्बर होणा, दुह। पर ओहो नेईं, गोवा च, एह् लगदा ऐ कि इक ठोस निशानदेई दे मुकाबले इक सुझाव ऐ। मैन पक्का इक घंटा ओह्दे च घुम्मदे होई बिताया जेह्ड़ा मैन यकीन ऐ कि नरियल दा बाग होणा, ओथों दे लोकें तों पुच्छदे होई कि उन्हां \"एच. न. 147/ए, कोई स्लैश कुछ वी\" दिक्खेआ ऐ। जवाब खाली होई वेखने थमां लेई मददगार (पर आखिरकार गलत) दिशान तक फैले होए थे।", "text": "पहले, \"एच. नंबर 147/ए.\" मैं समझया कि एह घर दा नंबर ऐ, धुह। पर ओह नईं, गोआ च, एह इक पक्की निशानी तों ज़्यादा इक सलाह लगदी ऐ। मैं इक घंटा मता उसी जगह गै घूम्दा रेहा जिसदा मैं पक्का हा कि एह इक नारियल दा बाग ऐ, लोकें तों पुछदा रेहा जे उन्होंने \"एच. नंबर 147/ए, कोई स्लेश कुछ वी\" दिक्खेआ ऐ। जवाब खाली नज़रें तों लेइयै मददगार (पर आख़िर च ग़लत) दिशाएं तक बदले।"}
{"unnormalised": "", "normalised": "फिर इत्थे हा \"नियर सेंट एलेक्स चर्च।\" हुन, सेंट एलेक्स चर्च तां इक बड़ा मशहूर निशान है। तुसां सोचे दे होगे जे \"नियर\" दा मतलब होग, जियां, सामने आले थाह्रो थमां दिस्सना। ना। गोवा च, “नियर” दा मतलब है “आम तौर पर आसपास कुतै, शायद इक रिक्शा सवारी ते इक गौएं कन्नै गल्लबात बी शामल।” आखिर च मैं लब्बी ही लेआ... 3 अलग-अलग ऑटो-रिक्शा वालें गी पुच्छने दे बाद जिन्ने हर इक ने मेरे तों 500 रुपए मांगे इक सवारी लेई जिह्दे 100 रुपए लगदे हे।", "text": "फिर इक होया \"नियर सेंट एलेक्स चर्च।\" हुण, सेंट एलेक्स चर्च तां इक मता बड्डा लैंडमार्क ऐ। तुसां सोचदे होगे जे \"नियर\" दा मतलब होग, जियां, अग्गे आले डंडयां थमां दिखदा होग। ना। गोवा च, \"नियर\" दा मतलब ऐ \"जनरल विसिनिटी च कुतै बी, शायद इक्का रिक्शा दी सवारी ते इक गऊएं कन्नै गल्लबात बी शामिल होग।\" आखिर च मिगी ऐ मिल गया... 3 बक्ख-बक्ख ऑटो-रिक्शा वालेयां थमां पुच्छने दे बाद जिन्नां च हर इक ने मिगी 500 रुपये चार्ज करने दी कोशश कीती जिदी सवारी दा 100 रुपये होणा चाहिदा हा।"}
{"unnormalised": "", "normalised": "अते मेनू तां \"Bardez\" पर शुरू वी ना करो। क्या ए इक शहर ऐ? इक जिला? इक एहसास? मेनू अजें बी पूरी तरह यकीन नी ऐ। पोस्टकोड, \"403516,\" इक इक चीज़ ही हा जिन्ने कोई मतलब बनाऐया, ते उंदी वी गल्ल ऐ, गूगल मैप्स तां बस मेरे पर हस्सी पैया।", "text": "ते मेनू तां \"Bardez\" पर शुरू वी नी करो। के ऐ इक कस्बा ऐ? इक जिला? इक एहसास? मेनू अजें वी पूरी तरह यकीन नी ऐ। पिन कोड, \"403516,\" इकल्ल ही चीज ही जेह्दे च कुझ समझ आंदी ही, ते उस वेले वी, गूगल मैप्स मेरे पर हंसी करदा रिया।"}
{"unnormalised": "", "normalised": "आखरी, जो मिंजो इक छोटी तीर्थयात्रा लग्गी (ते किंगफिशर दी कइयां बोतलें पीईने दे बाद), मिंजो आनंद विला मिल्या। ऐ बड़ा प्यारा हा, सचमुच। पर यात्रा? चलो बस ऐही गल करां जे हून मैं \"गुम्मा ते परेशान\" दी गोआ बोली च माहिर होई गेआं।", "text": "आखिरकार, इक छोटी तीर्थ यात्रा (ते किंगफिशर दीयां केई बोतलें पीने दे बाद) जेह्‌ने बाद, मैं आनंद विला पर पुज्जा। एह् बड़ा प्यारा हा, सचमुच। पर यात्रा? आओ बस आह्‌निए जेह्‌ड़ी मैं हुण \"गुम ते परेशान\" दी गोआ बोली विच माहिर होई गेआं।"}
{"unnormalised": "", "normalised": "कहानी दा सबक? हमेशा, *हमेशा* जीपीएस कोआर्डिनेट होंदे चाहिदे न। ते शायद इक लोकल सिम कार्ड बी। ते पक्का तौर पर हास्य दी समझ होनी चाहिदी ऐ। कींकि भारत च पता लबना अपने आप च इक साहसिक कम्म होई सकदा ऐ, ते कदे-कदे, बेहतरीन कहानियां ओह् होंदियां न जिंदे च तुस्सी निराश हो जांदे ओ, हंसी-मजाक च खो जांदे ओ। अगली बारी, मैं अपनी बुकिंग नोट्स च बस \"अक्षांश: [इत्थे अक्षांश डालो], देशांतर: [इत्थे देशांतर डालो]\" लिखदां। आओ, देखो ओह केह् करने दी कोशश करदे न *ओह्* भ्रमित हो जांदे न!", "text": "कहानी दा मतलब ऐ? हमेषां, *हमेषां* GPS कोआर्डिनेट ज़रूर रक्खो। ते हो सकदा ऐ इक लोकल सिम कार्ड बी। ते पक्का ही हास्से दी भावना बी। क्योंकि भारत च पता ढूँढना अपने आप च इक साहसिक कम्म होई सकदा ऐ, ते कदे कदे, बेहतरीन कहानियां उही होंदियां न जिंदे च तुसीं मायूसी कन्नै, हास्यास्पद ढंग कन्नै गुम होई जांदे ओ। अगली बारी, मैं अपनी बुकिंग नोट्स च सिर्फ \"अक्षांश: [अक्षांश ऐत्थे डालो], देशांतर: [देशांतर ऐत्थे डालो]\" लिखदां। दिखदे आं कि ओह् ऐह्दे च कन्फ्यूज होन दी कोशिश करदे न!"}
{"unnormalised": "", "normalised": "माफ़ करना, मैं एह् करने च असमर्थ हां। मैं अभी तक डोगरी च अनुवाद करने लेई प्रशिक्षित नीं हां।", "text": "ठीक ऐ। मेईं दस्सो पाठ की ऐ जिह्नु तुस अनुवाद करना चांह्दे ओ।\n\"\"\""}
{"unnormalised": "", "normalised": "# फाइल च डमी ब्लॉग पोस्ट सामग्री लिखो", "text": "# फाइल विच नकली ब्लॉग पोस्ट सामग्री लिखो"}
{"unnormalised": "", "normalised": "ओपन (dummy_txt_filepath, 'w', encoding='utf-8') कन्नै f दे तौर पर:", "text": "dummy translation"}
{"unnormalised": "", "normalised": "f.write(blog_post_content)", "text": "ऍफ़.राइट(ब्लॉग_पोस्ट_कंटेंट)"}
{"unnormalised": "", "normalised": "# इक डमी इमेज फाइल बनाओ", "text": "# इक नकली इमेज फाइल बनाओ"}
{"unnormalised": "", "normalised": "ओपन (डमी_इमेज_फाइलपाथ, 'wb') एज़ f:", "text": "ओपन (dummy_image_filepath, 'wb') ऐज एफ:"}
{"unnormalised": "", "normalised": "f.write(b'dummy_image_content')", "text": "f.write(b'\\u0921\\u094d\\u0930\\u0947\\u0938\\u094d\\u0938_\\u0907\\u092e\\u0947\\u091c_\\u0915\\u093e_\\u0938\\u093e\\u0930\\u093e \\u0938\\u093e\\u092e\\u0917\\u094d\\u0930\\u0940')"}
{"unnormalised": "", "normalised": "print(f\"नकली डेटा '{dummy_source_folder}' च प्रदर्शन आस्तै बनाया गेआ।\")", "text": "प्रिंट (f\"नमूना डेटा '{dummy_source_folder}' च प्रदर्शन आस्तै बनाया गेआ।\")"}
{"unnormalised": "", "normalised": "# मुख प्रोसेसिंग फंक्शन गी कॉल करो", "text": "मुख्य प्रोसेसिंग फंक्शन गी बुलाओ"}
{"unnormalised": "", "normalised": "process_folder(dummy_source_folder, dummy_destination_folder)", "text": "process_folder(डमी_सोर्स_फोल्डर, डमी_डेस्टिनेशन_फोल्डर)"}
{"unnormalised": "", "normalised": "प्रिंट(\"\\n--- उदाहरण सामान्यीकृत सामग्री (गोवा_एड्रेसेस.txt थमां) ---\")", "text": "प्रिंट(\"\\n--- उदाहरण सामान्यीकृत सामग्री (गोवा_एड्रेसें.txt चों) ---\")"}
{"unnormalised": "", "normalised": "normalized_file_path = os.path.join(dummy_destination_folder, 'blog_posts', 'goa_addresses.txt')", "text": "normalized_file_path = os.path.join(dummy_destination_folder, 'blog_posts', 'goa_addresses.txt')"}
{"unnormalised": "", "normalised": "अगर os.path.exists(normalized_file_path):", "text": "अगर os.path.exists(normalized_file_path):"}
{"unnormalised": "", "normalised": "खोली करी normalized_file_path, 'r', encoding='utf-8' दे तौर पर f:", "text": "ओपन ( normalized_file_path, 'r', encoding='utf-8' ) अस f:"}
{"unnormalised": "", "normalised": "print(f.read())", "text": "प्रिंट (f.read())"}
{"unnormalised": "", "normalised": "नहीं ते:", "text": "नैं तां:"}
{"unnormalised": "", "normalised": "प्रिंट (f\"मानक बनाई दी फाइल एत्थे नईं मिली: {normalized_file_path}\")", "text": "प्रिंट(f\"नॉर्मलाइज़्ड फाइल इथे नीं मिली: {normalized_file_path}\")"}
{"unnormalised": "", "normalised": "# तुसां डमी_सोर्स_फोल्डर गी साफ करना चाही सकदे ओ जेकर ऐ सिर्फ डेमो आस्तै ऐ", "text": "अगर तुस्सै चाहो तां dummy_source_folder गी साफ करी सकदे ओ जेकर ऐ सिर्फ डेमो आस्ते ऐ"}
{"unnormalised": "", "normalised": "# shutil.rmtree(dummy_source_folder)", "text": "# shutil.rmtree(डमी_सोर्स_फोल्डर)"}
{"unnormalised": "", "normalised": "# print(f\"साफ़ कीता होआ डमी सोर्स फोल्डर: {डमी_सोर्स_फोल्डर}\")", "text": "# print(f\"साफ करी दित्ता ऐ नकली सोर्स फोल्डर: {dummy_source_folder}\")"}
{"unnormalised": "", "normalised": "मैं ठीक हूँ, धन्यवाद।\nतुसां कियां हो?\n```", "text": "मैं ठीक हूँ, धन्यवाद।\nतुसां कियां हो?\n```"}
{"unnormalised": "", "normalised": "मैं ठीक हूँ, धन्यवाद।\nतुसां क्या करदे ओ?", "text": "मैं ठीक हूँ, धन्यवाद।\nतुसां क्या करदे ओ?"}
{"unnormalised": "", "normalised": "**स्क्रिप्टें दा इस्तेमाल कीयां करा: **", "text": "**स्क्रिप्टें दा इस्तेमाल कीयां करा: **"}
{"unnormalised": "", "normalised": "1. **कोड बचाओ:** उप्पर दित्ते गेदे पाइथन कोड गी इक `.py` फाइल (जियां कि `normalize_data.py`) दे तौर पर बचाओ।", "text": "1. **कोड बचाओ:** उपरे दित्ते गेदे पाइथन कोड गी इक `.py` फाइल (मिसाल के तौर पर, `normalize_data.py`) दे तौर पर बचाओ।"}
{"unnormalised": "", "normalised": "2.  **`inflect` इंस्टॉल करो:** जेकर तुसां'दे कोल ऐह् न्हेई ऐ, तां' `inflect` लाइब्रेरी इंस्टॉल करो (नंबरें गी शब्दें च बदलने लेई इस्तेमाल होंदी ऐ):", "text": "2. **`inflect` इंस्टॉल करो:** अगर तुसांऽ कोल एह् नेईं ऐ, तां `inflect` लाइब्रेरी इंस्टॉल करो (जेह्ड़ी नंबरें गी शब्दें च बदलने लेई इस्तेमाल होंदी ऐ):"}
{"unnormalised": "", "normalised": "````bash\n    ```", "text": "मैं ठीक हूँ, धन्यवाद।\n```\n\nमैं ठीक हां, शुक्रिया।"}
{"unnormalised": "", "normalised": "pip install inflect", "text": "pip install inflect"}
{"unnormalised": "", "normalised": "की हाल ऐ?\n```", "text": "मैं ठीक हूँ, धन्यवाद।\nतुसां कियां हो?\n```"}
{"unnormalised": "", "normalised": "3.  **अपनी जानकारी तैयार करो:**", "text": "3. **अपनी डेटा तैयार करो:**"}
{"unnormalised": "", "normalised": "*   सारे तुसाड़े `.txt` फाइलें (और कोई होर फाइलें जेह्ड़ियां तुसां कॉपी करना चांदे ओ) इक टॉप-लेवल फोल्डर च रक्खो। उदाहरण के तौर पर, मन लओ कि तुसाड्डा मुख संग्रह इक फोल्डर च ऐ जिद्दां दा नाम `my_data_raw` ऐ।", "text": "* अपनी सारी `.txt` फाइलें (ते होर कोई भी फाइलें जिह्ड़ियां तुसां कापी करना चांह्दे ओ) इक टॉप-लेवल फोल्डर च रक्खो। उदाहरण लेई, मन्नी लैओ जे तुह्‌डा मुख्य संग्रह `my_data_raw` नाम दे इक फोल्डर च ऐ।"}
{"unnormalised": "", "normalised": "*   प्रदर्शन लेई, स्क्रिप्ट इक `dataset_raw` फोल्डर *बनाओगी* जिंदे च तुहाडी दित्ती गेई ब्लॉग पोस्ट ते इक डमी इमेज होवेगी।", "text": "* प्रदर्शन आहस्तेई, एह् स्क्रिप्ट तुंदे दित्ते दे ब्लॉग पोस्ट ते इक डमी इमेज कन्नै इक `dataset_raw` फोल्डर *बणाऊ*।"}
{"unnormalised": "", "normalised": "4.  **`source_folder`  ते  `destination_folder`  च बदलो करो:**", "text": "4. **`source_folder` ते `destination_folder` च बदलाव करो:**"}
{"unnormalised": "", "normalised": "*   `if __name__ == \"__main__\":` ब्लॉक च, `dummy_source_folder` गी अपने असली टॉप-लेवल डेटा फोल्डर दे रास्ते च बदलो।", "text": "* `अगर __name__ == \"__main__\":` ब्लॉक च, `dummy_source_folder` गी अपने असल टॉप-लेवल डेटा फोल्डर दे रास्ते च बदलो।"}
{"unnormalised": "", "normalised": "*   `dummy_destination_folder` गी बदली करी ओह् थाह्'र रख जिह्'दे विच तुसां सामान्य की'ते गे' आउटपुट गी भेजना चांह्'दे ओ (जियां' के `my_data_normalized`)।", "text": "* `dummy_source_folder` should point to the root directory of your data.\n* Remember to have all source files follow the naming convention `ID_TEXT.txt`.\n* The `ID` part will be removed from the final files.\n \n\n* `dummy_destination_folder` गी बदलो जित्थे तुसां Normalized आउटपुट लेई जाना चांह्दे ओ (मसाल दे तौर पर, `my_data_normalized`)।\n* `dummy_source_folder` गी अपने डेटा दी रूट डायरेक्टरी वल इशारा करना चाहिदा।\n* याद रक्खो कि सारे सोर्स फाइलें गी नेमिंग कन्वेंशन `ID_TEXT.txt` दा पालन करना चाहिदा।\n* `ID` हिस्सा आखिरी फाइलें चों हटाई दिता जाग।"}
{"unnormalised": "", "normalised": "ऐह् इक पाइथन प्रोग्राम ऐ।\n```", "text": "ह्न तोड़ी करीं।\n```"}
{"unnormalised": "", "normalised": "# उदाहरण: अगर तुह्‌आड़ी डेटा 'C:/Users/YourName/Documents/MyTextCollection' च ऐ।", "text": "जेकर तुसां'दा डेटा 'C:/Users/YourName/Documents/MyTextCollection' च ऐ।"}
{"unnormalised": "", "normalised": "# source_folder = 'C:/Users/YourName/Documents/MyTextCollection'", "text": "# source_folder = 'C:/Users/YourName/Documents/MyTextCollection'"}
{"unnormalised": "", "normalised": "# destination_folder = 'C:/Users/YourName/Documents/MyTextCollection_Normalized'", "text": "# destination_folder = 'C:/Users/YourName/Documents/MyTextCollection_Normalized'"}
{"unnormalised": "", "normalised": "# इस स्क्रिप्ट दे डेमो लेई, एह् इस्तेमाल करदा ऐ:", "text": "# एह् स्क्रिप्ट दे डेमो लेई, इह् इस्तेमाल करदा ऐ:"}
{"unnormalised": "", "normalised": "source_folder = 'dataset_raw' # ऐह् स्क्रिप्ट आसेआं बनाया जाग, जेकर ऐह् मौजूद नेईं ऐ", "text": "source_folder = 'dataset_raw' # एह स्क्रिप्ट थमां बनाई जाग अगर एह मौजूद नीं ऐ"}
{"unnormalised": "", "normalised": "destination_folder = 'dataset_normalized' # एह स्क्रिप्ट कोला बनाई जाग", "text": "destination_folder = 'dataset_normalized' # एह स्क्रिप्ट बनाई दिता जा'ग"}
{"unnormalised": "", "normalised": "की हाल ऐ?\n```", "text": "मैं ठीक हूँ, धन्यवाद।\nतुसां कियां हो?\n```"}
{"unnormalised": "", "normalised": "5.  **स्क्रिप्ट चलाओ:** अपणा टर्मिनल या कमांड प्रॉम्प्ट खोलो, उस डायरेक्टरी विच जाओ जिथे तुसे `normalize_data.py` सेव कीती ऐ, ते चलाओ:", "text": "5. **स्क्रिप्ट चलाओ: अपना टर्मिनल या कमांड प्रॉम्प्ट खोलो, उस डायरेक्ट्री पर जाओ जिथे तुसां `normalize_data.py` सेव कीती ऐ, ते चलाओ:"}
{"unnormalised": "", "normalised": "````bash\n    ```", "text": "मैं ठीक हूँ, धन्यवाद।\n```\n\nमैं ठीक हां, शुक्रिया।"}
{"unnormalised": "", "normalised": "python normalize_data.py", "text": "python normalize_data.py"}
{"unnormalised": "", "normalised": "की हाल ऐ?\n```", "text": "मैं ठीक हूँ, धन्यवाद।\nतुसां कियां हो?\n```"}
{"unnormalised": "", "normalised": "माफ़ करना, मंझे एह्थू कुछ् खास जानकारी दे बगैर अनुवाद नहीं करी सकदा। किरपा करियै पाठ देओ ते मैं अनुवाद करी सकूँ।", "text": "माफ़ करना, मंझे एह्थू कुछ् खास जानकारी दे बगैर अनुवाद नहीं करी सकदा। किरपा करियै पाठ देओ ते मैं अनुवाद करी सकूँ।"}
{"unnormalised": "", "normalised": "अगर तुस्से डमी डेटा सेटअप कन्नै स्क्रिप्ट चलांदे हो, तां `dataset_normalized/blog_posts/goa_addresses.txt` फाइल च होग:", "text": "अगर तुस्से डमी डेटा सेटअप कन्नै स्क्रिप्ट चलांदे हो, तां `dataset_normalized/blog_posts/goa_addresses.txt` फाइल च होग:"}
{"unnormalised": "", "normalised": "मैं ठीक हूँ, धन्यवाद।\nतुसां कियां हो?\n```", "text": "मैं ठीक हूँ, धन्यवाद।\nतुसां कियां हो?\n```"}
{"unnormalised": "", "normalised": "तरजुमा च खोहना: इंडिया दे पत्तया कन्नै मेरी कहानियाँ (ते तुसां गी जी-पी-एस दी लोड़ क्यों ऐ) तां, मैं सोचदा हा कि मैं बड़ा माहिर ऐं, तुसां जांदे ओ? मैं दिल्ली मेट्रो च शिखर वेल्लें दौरान यात्रा कीती ऐ, चांदनी चौक च इक साड़ी पर सर्वोत्तम मूल्य पर सौदेबाजी कीती ऐ, ते इत्थों तक कि बिना दुद्ध दे चाय दा आर्डर देने च कामयाब होई गेआ हां (इक करतब, मेरा भरोसा करो)। पर फेर पत्ता आए। ओह, पत्ता! आओ मैं दृश्य स्थापित करां: मैं गोवा च इस प्यारे छोटे गेस्टहाउस गी खोजने दे मिशन पर हा। बड़ा मनोहर लगदा ऐ, है ना? बुकिंग दी पुष्टि ने खुशी-खुशी ऐलान कीता: \"आनंद विला, एच. नं. इक सौ सैंतालीस स्लैश ए, एस-टी दे नेड़े। एलेक्स चर्च, कलंगुट, बारदेज़, गोवा चार सौ ते त्रै हजार पंच सौ ते सोलह।\" बड़ा आसान, मैं सोचदा हा। आखरी शब्द मशहूर। पहलां तां \"एच. नं. इक सौ सैंतालीस स्लैश ए।\" मैं मन्या कि ए मकान नंबर ऐ, दुह। पर ओहो नेईं, गोवा च, ए इक ठोस मार्कर दे मुकाबले इक सुझाव जापै दे। मैं इक मजबूत घंटा घूम्मन च बिताया जेह्ड़ा मेनू पक्का ऐ कि नारियल दा बाग हा, जेह्ड़े स्थानीय लोकें तों पुछदे होई कि उन्होंने \"एच. नं. इक सौ सैंतालीस स्लैश ए, कोई स्लैश कुझ वी\" दिक्खेया ऐ। प्रतिक्रियाएं खाली घूरने तों लेइयै मददगार (पर आखिरकार गलत) दिशाएं तगर होईयां। फेर ओह् \"एस-टी दे नेड़े\" हा। एलेक्स चर्च।\" हुण, एस-टी. एलेक्स चर्च इक बड़ा मशहूर स्थल ऐ। तुसां सोचदे ओ कि \"नेड़े\" दा मतलब होग, जिਵੇਂ कि फ्रंट स्टेप तों दिक्खना ऐ। नह। गोवा च, \"नेड़े\" दा मतलब ऐ \"आम इलाके च कुतै, संभवतः इक रिक्शा सवारी ते इक गौ कन्नै बातचीत करना।\" आख़िरकार मैं ऐस गी खोज लेया... त्रै बक्ख-बक्ख ऑटो-रिक्शा वालियां तों पुछने दे बाद जेह्ड़ियां हर इक ने मेनू रुपाई इक सौ दी सवारी लेई रुपाई पंच सौ चार्ज करने दी कोशिश कीती। ते \"बारदेज़\" पर मेनू शुरू वी ना करो। की ऐ इक शहर ऐ? इक जिला ऐ? इक भावना ऐ? मेनू अज्ज वी पूरी तरह यकीन नेईं ऐ। पोस्टकोड, \"चार सौ ते त्रै हजार पंच सौ ते सोलह,\" इक होई चीज हा जेह्ड़ी समझ आई, ते ऐस वेल्लें वी, गूगल मैप्स सिर्फ मेनू हासीदा हा। आख़िरकार, जेह्ड़ा इक छोटी तीर्थ यात्रा जापै दे हा (ते किंगफिशर दियां केईं बोतलें), मैं आनंद विला पर आके थमक गेआ। ए बड़ा प्यारा हा, सच्चमुच। पर यात्रा? आओ सिर्फ एही कहिये कि हुण मैं \"खोहेया ते भ्रांता\" दी गोअन बोली च माहिर ऐं। कहानी दा नैतिक? हमेशा, तारांकन हमेशा तारांकन च जी-पी-एस दे कोआर्डिनेट होंदे न। ते शायद इक स्थानीय एस-आई-एम कार्ड। ते निश्चित तौर पर हास्य दी समझ ऐ। क्योंकि भारत च इक पत्ता खोजना अपने आप च इक साहसिक कार्य हो सकदा ऐ, ते कदे-कदे, बेहतरीन कहानियां ओह् होंदियां न जिंदे च तुसां निराशाजनक ढंग कन्नै, हास्यपूर्ण ढंग कन्नै खोई जांदे ओ। अगली बारी, मैं सिर्फ मेरी बुकिंग नोट्स च \"अक्षांश: [अक्षांश इत्थें दाखल करो], देशांतर: [देशांतर इत्थें दाखल करो]\" लिखाने जा रेहा ऐं। आओ उनेंगी दिक्खिये कि उनेंगी तारांकन गी भ्रांति च पावन दी कोशिश करो!", "text": "तरजुमा च खोहना: इंडिया दे पत्तया कन्नै मेरी कहानियाँ (ते तुसां गी जी-पी-एस दी लोड़ क्यों ऐ) तां, मैं सोचदा हा कि मैं बड़ा माहिर ऐं, तुसां जांदे ओ? मैं दिल्ली मेट्रो च शिखर वेल्लें दौरान यात्रा कीती ऐ, चांदनी चौक च इक साड़ी पर सर्वोत्तम मूल्य पर सौदेबाजी कीती ऐ, ते इत्थों तक कि बिना दुद्ध दे चाय दा आर्डर देने च कामयाब होई गेआ हां (इक करतब, मेरा भरोसा करो)। पर फेर पत्ता आए। ओह, पत्ता! आओ मैं दृश्य स्थापित करां: मैं गोवा च इस प्यारे छोटे गेस्टहाउस गी खोजने दे मिशन पर हा। बड़ा मनोहर लगदा ऐ, है ना? बुकिंग दी पुष्टि ने खुशी-खुशी ऐलान कीता: \"आनंद विला, एच. नं. इक सौ सैंतालीस स्लैश ए, एस-टी दे नेड़े। एलेक्स चर्च, कलंगुट, बारदेज़, गोवा चार सौ ते त्रै हजार पंच सौ ते सोलह।\" बड़ा आसान, मैं सोचदा हा। आखरी शब्द मशहूर। पहलां तां \"एच. नं. इक सौ सैंतालीस स्लैश ए।\" मैं मन्या कि ए मकान नंबर ऐ, दुह। पर ओहो नेईं, गोवा च, ए इक ठोस मार्कर दे मुकाबले इक सुझाव जापै दे। मैं इक मजबूत घंटा घूम्मन च बिताया जेह्ड़ा मेनू पक्का ऐ कि नारियल दा बाग हा, जेह्ड़े स्थानीय लोकें तों पुछदे होई कि उन्होंने \"एच. नं. इक सौ सैंतालीस स्लैश ए, कोई स्लैश कुझ वी\" दिक्खेया ऐ। प्रतिक्रियाएं खाली घूरने तों लेइयै मददगार (पर आखिरकार गलत) दिशाएं तगर होईयां। फेर ओह् \"एस-टी दे नेड़े\" हा। एलेक्स चर्च।\" हुण, एस-टी. एलेक्स चर्च इक बड़ा मशहूर स्थल ऐ। तुसां सोचदे ओ कि \"नेड़े\" दा मतलब होग, जिਵੇਂ कि फ्रंट स्टेप तों दिक्खना ऐ। नह। गोवा च, \"नेड़े\" दा मतलब ऐ \"आम इलाके च कुतै, संभवतः इक रिक्शा सवारी ते इक गौ कन्नै बातचीत करना।\" आख़िरकार मैं ऐस गी खोज लेया... त्रै बक्ख-बक्ख ऑटो-रिक्शा वालियां तों पुछने दे बाद जेह्ड़ियां हर इक ने मेनू रुपाई इक सौ दी सवारी लेई रुपाई पंच सौ चार्ज करने दी कोशिश कीती। ते \"बारदेज़\" पर मेनू शुरू वी ना करो। की ऐ इक शहर ऐ? इक जिला ऐ? इक भावना ऐ? मेनू अज्ज वी पूरी तरह यकीन नेईं ऐ। पोस्टकोड, \"चार सौ ते त्रै हजार पंच सौ ते सोलह,\" इक होई चीज हा जेह्ड़ी समझ आई, ते ऐस वेल्लें वी, गूगल मैप्स सिर्फ मेनू हासीदा हा। आख़िरकार, जेह्ड़ा इक छोटी तीर्थ यात्रा जापै दे हा (ते किंगफिशर दियां केईं बोतलें), मैं आनंद विला पर आके थमक गेआ। ए बड़ा प्यारा हा, सच्चमुच। पर यात्रा? आओ सिर्फ एही कहिये कि हुण मैं \"खोहेया ते भ्रांता\" दी गोअन बोली च माहिर ऐं। कहानी दा नैतिक? हमेशा, तारांकन हमेशा तारांकन च जी-पी-एस दे कोआर्डिनेट होंदे न। ते शायद इक स्थानीय एस-आई-एम कार्ड। ते निश्चित तौर पर हास्य दी समझ ऐ। क्योंकि भारत च इक पत्ता खोजना अपने आप च इक साहसिक कार्य हो सकदा ऐ, ते कदे-कदे, बेहतरीन कहानियां ओह् होंदियां न जिंदे च तुसां निराशाजनक ढंग कन्नै, हास्यपूर्ण ढंग कन्नै खोई जांदे ओ। अगली बारी, मैं सिर्फ मेरी बुकिंग नोट्स च \"अक्षांश: [अक्षांश इत्थें दाखल करो], देशांतर: [देशांतर इत्थें दाखल करो]\" लिखाने जा रेहा ऐं। आओ उनेंगी दिक्खिये कि उनेंगी तारांकन गी भ्रांति च पावन दी कोशिश करो!"}
{"unnormalised": "", "normalised": "मैं ठीक हूँ, धन्यवाद।\nतुसां कियां हो?\n```", "text": "मैं ठीक हूँ, धन्यवाद।\nतुसां कियां हो?\n```"}
