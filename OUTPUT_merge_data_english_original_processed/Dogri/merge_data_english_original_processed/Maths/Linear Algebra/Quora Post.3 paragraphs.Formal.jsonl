{"unnormalised": "कसै मथी मशीन लर्निंग च लीनियर अलजेब्रा दे इस्तेमाल बारै च पुच्छया। खैर, इह् बड़ा बुनियादी ऐ। इक बुनियादी न्यूरल नेटवर्क परत गी गै ध्यान च रक्खो; इह् असल च इक मैट्रिक्स गुणा ऐ। हर न्यूरॉन दा आउटपुट अपने इनपुट दा वज़नी योग ऐ, ते इनें भारें गी मैट्रिक्स च व्यवस्थित कीता जंदा ऐ। उदाहरण दे तौर पर, इक परत च (100 x 50) आयाम दे भार W होई सकदे न, जिसदा मतलब ऐ जे इह् 50-आयामी इनपुट गी 100-आयामी आउटपुट च बदलदा ऐ। फॉरवर्ड पास च Wx + b दी गणना करना शामल ऐ, जित्थे x इनपुट वेक्टर ऐ ते b इक पक्षपाती वेक्टर ऐ। इह् 'Wx' बिलकुल ओह् ऐ जित्थे लीनियर अलजेब्रा चमकी दा ऐ।", "normalised": "मत्थों कुसै पुच्छया मशीन लर्निंग च लीनियर अलजेब्रा दी की एप्लिकेशन ऐ। खैर, ऐ तां मता बुनियादी ऐ। इक बुनियादी न्यूरल नेटवर्क लेयर गी ध्यान च रक्खो; ऐ असल च इक मैट्रिक्स मल्टीप्लिकेशन ऐ। हर न्यूरॉन दा आउटपुट अपने इनपुट दा भारित योग ऐ, ते ऐ भार मैट्रिक्स च व्यवस्थित कीते जंदे न। उदाहरण दे तौर पर, इक लेयर च डब्ल्यू भार हो सकदे न जिंदी डाइमेंशन सौ बाई पचास ऐ, जिदा मतलब ऐ जे ऐ पचास-आयामी इनपुट गी इक सौ-आयामी आउटपुट च बदलदा ऐ। फॉरवर्ड पास च डब्ल्यू एक्स प्लस बी दी गणना करना शामल ऐ, जित्थे एक्स इनपुट वेक्टर ऐ ते बी इक बायस वेक्टर ऐ। एह् 'डब्ल्यू एक्स' बिल्कुल उही ऐ जित्थे लीनियर अलजेब्रा चमकीदा ऐ।", "text": "कसै मथी मशीन लर्निंग च लीनियर अलजेब्रा दे इस्तेमाल बारै च पुच्छया। खैर, इह् बड़ा बुनियादी ऐ। इक बुनियादी न्यूरल नेटवर्क परत गी गै ध्यान च रक्खो; इह् असल च इक मैट्रिक्स गुणा ऐ। हर न्यूरॉन दा आउटपुट अपने इनपुट दा वज़नी योग ऐ, ते इनें भारें गी मैट्रिक्स च व्यवस्थित कीता जंदा ऐ। उदाहरण दे तौर पर, इक परत च (100 x 50) आयाम दे भार W होई सकदे न, जिसदा मतलब ऐ जे इह् 50-आयामी इनपुट गी 100-आयामी आउटपुट च बदलदा ऐ। फॉरवर्ड पास च Wx + b दी गणना करना शामल ऐ, जित्थे x इनपुट वेक्टर ऐ ते b इक पक्षपाती वेक्टर ऐ। इह् 'Wx' बिलकुल ओह् ऐ जित्थे लीनियर अलजेब्रा चमकी दा ऐ।"}
{"unnormalised": "फेर तुसांऽ कोल इमेज प्रोसेसिंग ऐ। इक इमेज गी इक मैट्रिक्स (जां रंगीन इमेजां आस्तै मैट्रिसेस दा इक सेट) दे तौर पर पेश कीता जाई सकदा ऐ। धुंधला करना, किनारे दा पता लाना, ते रोटेशन जियां सारियां कारवाइयां लीनियर अलजेब्रा अवधारणाएं पर निर्भर करदियां न। उदाहरण आस्तै, 3x3 कंवोल्यूशन कर्नेल लगाने च तत्व-वार गुणा ते जोड़ शामल ऐ जित्थे मैट्रिक्स संचालन दा उपयोग करदे होई पेश कीता जाई सकदा ऐ। इमेज गी रिसाइज करने जां इसगी काटने जियां सरल कम्मेंगी बी लीनियर ट्रांसफॉर्मेशन दे तौर पर दिक्खेआ जाई सकदा ऐ। पीसीए जियां इमेज कंप्रेशन तकनीक बी लीनियर अलजेब्रा दा भारी इस्तेमाल करदियां न।", "normalised": "फेर तुसां इमेज प्रोसेसिंग करो। इक इमेज गी मैट्रिक्स जां रंगीन इमेजें आस्तै मैट्रिक्स दे इक सेट दे रूप च दर्शायेआ जाई सकदा ऐ। धुंधली करने, किनारे दा पता लगाने, ते घुमावने जेहे सारे संचालन लीनियर अलजेब्रा अवधारणाएं उप्पर निर्भर करदे न। उदाहरण दे तौर उप्पर, त्रै गुणा त्रै कंवल्शन कर्नेल लगाने च तत्व-वार गुणा ते जोड शामल ऐ जिस गी मैट्रिक्स संचालन दा उपयोग करदे होई दर्शाया जाई सकदा ऐ। इमेज दा आकार बदलने जां इस गी काटने जेहे सरल कम्म भी लीनियर ट्रांसफॉर्मेशन दे रूप च दिक्खे जाई सकदे न। पी-सी-ए जेही इमेज कंप्रेशन तकनीकें भी लीनियर अलजेब्रा दा भारी इस्तेमाल करदियां न।", "text": "फेर तुसांऽ कोल इमेज प्रोसेसिंग ऐ। इक इमेज गी इक मैट्रिक्स (जां रंगीन इमेजां आस्तै मैट्रिसेस दा इक सेट) दे तौर पर पेश कीता जाई सकदा ऐ। धुंधला करना, किनारे दा पता लाना, ते रोटेशन जियां सारियां कारवाइयां लीनियर अलजेब्रा अवधारणाएं पर निर्भर करदियां न। उदाहरण आस्तै, 3x3 कंवोल्यूशन कर्नेल लगाने च तत्व-वार गुणा ते जोड़ शामल ऐ जित्थे मैट्रिक्स संचालन दा उपयोग करदे होई पेश कीता जाई सकदा ऐ। इमेज गी रिसाइज करने जां इसगी काटने जियां सरल कम्मेंगी बी लीनियर ट्रांसफॉर्मेशन दे तौर पर दिक्खेआ जाई सकदा ऐ। पीसीए जियां इमेज कंप्रेशन तकनीक बी लीनियर अलजेब्रा दा भारी इस्तेमाल करदियां न।"}
{"unnormalised": "अगें, लीनियर अलजेब्रा कई ऑप्टिमाइजेशन एल्गोरिदम गी सपोर्ट करदा ऐ जेह्ड़े मशीन लर्निंग च इस्तेमाल होंदे न जिਵੇਂ ग्रेडिएंट डिसेंट। ऐ एल्गोरिदम मॉडलें गी कुशलता कन्नै ट्रेन करने लेई मता जरूरी न। इस करी, भले गै तुस हर वेले मैट्रिक्स लिखदे न होओ, पर लीनियर अलजेब्रा दी मता समझ गै तुंदी मदद करी सकदी ऐ के तुस कई एमएल मॉडलें दे अंदरूनी कम गी समझो, ते कन्नै गै अपने कोड गी डीबग करने च भी मदद करी सकदी ऐ। तुहां गी हर वेले आइगेन वैल्यूज, आइगेनवेक्टर, मैट्रिक्स डीकंपोजिशन, ते वेक्टर स्पेस जैसी चीजें दा सामना करना पऊ।", "normalised": "अगें, लीनियर अलजेब्रा ग्रेडिएंट डिसेंट जेहेई मशीन लर्निंग च इस्तेमाल होने वाले मता सारे ऑप्टिमाइजेशन एल्गोरिदम दा आधार ऐ। ऐ एल्गोरिदम कुशल तरीके कन्नै मॉडल गी प्रशिक्षित करने लेई मता जरूरी न। तां, भलेई तुस हर बखत स्पष्ट रूप कन्नै मैट्रिक्स नेईं लिखदे हो, पर लीनियर अलजेब्रा दी मजबूत समझ निश्चित रूप कन्नै तुहाडी मता सारे एम-एल मॉडल दी अंदरूनी कामकाज गी समझने च मदद करदी ऐ, ते तुहाडी कोड गी डिबग करने च बी मदद करदी ऐ। तुस हर बखत आइगनवैल्यू, आइगनवेक्टर, मैट्रिक्स डीकंपोजिशन, ते वेक्टर स्पेस जेहियां चीजें दा सामना करोओ।", "text": "अगें, लीनियर अलजेब्रा कई ऑप्टिमाइजेशन एल्गोरिदम गी सपोर्ट करदा ऐ जेह्ड़े मशीन लर्निंग च इस्तेमाल होंदे न जिਵੇਂ ग्रेडिएंट डिसेंट। ऐ एल्गोरिदम मॉडलें गी कुशलता कन्नै ट्रेन करने लेई मता जरूरी न। इस करी, भले गै तुस हर वेले मैट्रिक्स लिखदे न होओ, पर लीनियर अलजेब्रा दी मता समझ गै तुंदी मदद करी सकदी ऐ के तुस कई एमएल मॉडलें दे अंदरूनी कम गी समझो, ते कन्नै गै अपने कोड गी डीबग करने च भी मदद करी सकदी ऐ। तुहां गी हर वेले आइगेन वैल्यूज, आइगेनवेक्टर, मैट्रिक्स डीकंपोजिशन, ते वेक्टर स्पेस जैसी चीजें दा सामना करना पऊ।"}
