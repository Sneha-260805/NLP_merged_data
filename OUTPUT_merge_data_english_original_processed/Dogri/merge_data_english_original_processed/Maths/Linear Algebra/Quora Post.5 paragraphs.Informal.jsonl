{"unnormalised": "हेलो दोस्तो, इक झटपट सवाल लीनियर अलजेब्रा बारे। मैं इक एग्जाम दी तैयारी करदां प्या, ते इक चीज़ विच अटक गया। मैं असल विच आइगेनवैल्यूज़ ते आइगेनवेक्टर्स गी असली दुनिया दी चीज़ें च किवें अप्लाई करी सकदां, सिर्फ मैट्रिक्स ट्रांसफॉर्मेशन तो अलावा? मेरी किताब च सिर्फ सैद्धांतिक उदाहरण ऐ, पर मैं जानना चांह्दां कि ऐ चीज़ कितनी उपयोगी ऐ, समझदे ओ ना? सोची रिया, जिवें, की ऐ सिग्नल प्रोसेसिंग च इस्तेमाल होंदी ऐ या शायद एआई दी चीज़ें च वी? कोई वी सरल व्याख्या या उदाहरण बहुत मददगार होगन!", "normalised": "हेलो दोस्तों, लीनियर अलजेब्रा दे बारे च इक झट सवाल ऐ। मैं इक एग्जाम दी तैयारी करदा पेआं ते किस चीज़ च अटक गेआ ऐ। मैं असल च असल दुनिया दी चीज़ें च आइगन वैल्यूज ते आइगनवेक्टर्स गी केह्से लागू करदा ऐं, सिर्फ मैट्रिक्स ट्रांसफॉर्मेशन दे अलावा? मेरी टेक्स्टबुक च सिर्फ सैद्धांतिक उदाहरण न, पर मैं जानना चांह्दा ऐं के एह चीज़ कितनी उपयोगी ऐ, तुसां जानदे ओ? सोचो के, केह् एह सिग्नल प्रोसेसिंग च जां शायद ए-आई दी चीज़ें च वी इस्तेमाल होंदी ऐ? कोई वी सरल व्याख्या जां उदाहरण मता मददगार होगन!", "text": "हेलो दोस्तो, इक झटपट सवाल लीनियर अलजेब्रा बारे। मैं इक एग्जाम दी तैयारी करदां प्या, ते इक चीज़ विच अटक गया। मैं असल विच आइगेनवैल्यूज़ ते आइगेनवेक्टर्स गी असली दुनिया दी चीज़ें च किवें अप्लाई करी सकदां, सिर्फ मैट्रिक्स ट्रांसफॉर्मेशन तो अलावा? मेरी किताब च सिर्फ सैद्धांतिक उदाहरण ऐ, पर मैं जानना चांह्दां कि ऐ चीज़ कितनी उपयोगी ऐ, समझदे ओ ना? सोची रिया, जिवें, की ऐ सिग्नल प्रोसेसिंग च इस्तेमाल होंदी ऐ या शायद एआई दी चीज़ें च वी? कोई वी सरल व्याख्या या उदाहरण बहुत मददगार होगन!"}
{"unnormalised": "ते, मिंजो याद ऐ साडे प्रोफेसर, डॉ. वर्मा, कुसै उंदा इस्तेमाल पेजRank एल्गोरिथम च करने दा जिक्र करदे हे, गूगल दे असली एल्गोरिथम च। मिंजो लगदा ऐ के उह् वेब दे लिंक स्ट्रक्चर नु दर्शाने आले इक्क बड्डे मैट्रिक्स दे eigenvectors पर आधारित हा। सबसे बड्डे eigenvalue आह्ले eigenvector ने हर पेज दे महत्व दा स्कोर दित्ता हा। बड़ा सोहना ऐ, सही ऐ ना? लग्गदा ऐ जियां जादू होऐ। सोचणे पर मजबूर करदा ऐ के होर केह् शानदार युक्तियां लीनियर अलजेब्रा च लुक्कियां न।", "normalised": "तोह्, मिंजो याद ऐ साड़े प्रोफेसर, डॉक्टर वर्मा, कुसैह् गलैह् च इनेंगी इस्तेमाल करने बारैह् दस्सेआ हा पेज रैंक एल्गोरिदम च, गूगल देह् ओरिजिनल च। मिंजो लगदा ऐ केह् वेब देह् लिंक स्ट्रक्चर दी नुमाइंदगी करने आह्ले इक बड्डे मैट्रिक्स देह् आइगेनवेक्टर उप्पर आधारत हा। सबनें शां बड्डे आइगेनमूल आह्ले आइगेनवेक्टर ने तोह्रैह् इक-इक पेज आस्तै महत्त्ता स्कोर दित्ता हा। काफी चंगा ऐ, हैना? तकरीबन जादू लग्गदा ऐ, हा हा। तुसां सोचदे हो केह् होर कीह् बढ़िया चालाकियां लीनियर अलजेब्रा च लुकीयां न।", "text": "ते, मिंजो याद ऐ साडे प्रोफेसर, डॉ. वर्मा, कुसै उंदा इस्तेमाल पेजRank एल्गोरिथम च करने दा जिक्र करदे हे, गूगल दे असली एल्गोरिथम च। मिंजो लगदा ऐ के उह् वेब दे लिंक स्ट्रक्चर नु दर्शाने आले इक्क बड्डे मैट्रिक्स दे eigenvectors पर आधारित हा। सबसे बड्डे eigenvalue आह्ले eigenvector ने हर पेज दे महत्व दा स्कोर दित्ता हा। बड़ा सोहना ऐ, सही ऐ ना? लग्गदा ऐ जियां जादू होऐ। सोचणे पर मजबूर करदा ऐ के होर केह् शानदार युक्तियां लीनियर अलजेब्रा च लुक्कियां न।"}
{"unnormalised": "इक होर एप्लीकेशन जो मैं किथैं देखी ही, ओ इंजीनियरिंग सिस्टमें च स्टेबिलिटी एनालिसिस कन्नै जुड़ी ही। जियां, जे तुंदे कोल डिफरेंशियल इक्वेशनें कन्नै दस्सया गेदा कोई सिस्टम ऐ, तां तुस सिस्टम दे मैट्रिक्स दे आइगनवैल्यूज़ दा इस्तेमाल एह् जानने आस्तै करी सकदे ओ जे सिस्टम स्थिर ऐ या नैं। जे सारे आइगनवैल्यूज़ दे नेगेटिव रियल पार्ट होंदे न, तां सिस्टम स्थिर ऐ। जे तुस कैपेसिटर (C= 10μF), इंडक्टर (L = 5mH), ते रेजिस्टर्स (R=10 ओहम) कन्नै इलेक्ट्रिकल सर्किट मॉडल करना चांदे ओ, तां आइगनवैल्यूज़ पता करना तुसेंगी एह् समझने च मदद करदा ऐ जे सर्किट ऑसिलेट करदा ऐ या सड़दा ऐ।", "normalised": "इक होर एप्लीकेशन जेह्ड़ी मैं कुत्थें दिक्खी ही, ओ इंजीनियरिंग सिस्टम च स्थिरता दा विश्लेषण करने कन्नै जुड़ी होई ही। जियां, जे तुंदे कोल डिफ़रेंशियल इक्वेशंस कन्नै दस्सेया गेदा कोई सिस्टम ऐ, तां तुस सिस्टम दे मैट्रिक्स दे आइगनवैल्यूज़ दा इस्तेमाल एह् पता लाने लेई करी सकदे ओ की सिस्टम स्थिर ऐ या नि। जे सारे आइगनवैल्यूज़ दे नेगेटिव रियल पार्ट होंदे न, तां सिस्टम स्थिर होंदा ऐ। जे तुस कैपेसिटर्स (सी दस माइक्रोफैरड दे बराबर), इंडक्टर्स (एल पांच मिलीहेनरी दे बराबर), ते रेजिस्टर्स (आर दस ओम दे बराबर) कन्नै इलेक्ट्रिक सर्किट्स दा मॉडल बनाना चांदे ओ, तां आइगनवैल्यूज़ लभने कन्नै तुहानूं एह् समझने च मदद मिलदी ऐ की सर्किट ऑसिलेट करदा ऐ या डेके हो जांदा ऐ।", "text": "इक होर एप्लीकेशन जो मैं किथैं देखी ही, ओ इंजीनियरिंग सिस्टमें च स्टेबिलिटी एनालिसिस कन्नै जुड़ी ही। जियां, जे तुंदे कोल डिफरेंशियल इक्वेशनें कन्नै दस्सया गेदा कोई सिस्टम ऐ, तां तुस सिस्टम दे मैट्रिक्स दे आइगनवैल्यूज़ दा इस्तेमाल एह् जानने आस्तै करी सकदे ओ जे सिस्टम स्थिर ऐ या नैं। जे सारे आइगनवैल्यूज़ दे नेगेटिव रियल पार्ट होंदे न, तां सिस्टम स्थिर ऐ। जे तुस कैपेसिटर (C= 10μF), इंडक्टर (L = 5mH), ते रेजिस्टर्स (R=10 ओहम) कन्नै इलेक्ट्रिकल सर्किट मॉडल करना चांदे ओ, तां आइगनवैल्यूज़ पता करना तुसेंगी एह् समझने च मदद करदा ऐ जे सर्किट ऑसिलेट करदा ऐ या सड़दा ऐ।"}
{"unnormalised": "हां, बिल्कुल एआई। आइगनमूल ते आइगन वेक्टर आयाम घटाने दी तकनीकें च बड्डा रोल निभांदे न, जिਵੇਂ के प्रिंसिपल कंपोनेंट एनालिसिस (PCA)। सोचो तुस्सां ढेर सारी विशेषताएं आले डेटासेट नाल कम्म करी करदे ओ, जिਵੇਂ के चेहरें दी तस्वीरें दा डेटासेट। हर तस्वीर च 1000 विशेषताएं (1000 पिक्सेल) न, तुस्सां PCA दा इस्तेमाल \"प्रिंसिपल कंपोनेंट\" पता करने लेई करी सकदे ओ, जेह्ड़े बुनियादी तौर उप्पर तुंदे डेटा दे कोवेरियंस मैट्रिक्स दे सब्भनें शा बड्डे आइगनमूलें दे अनुरूप आइगन वेक्टर न। तुस्सां थोड़े जिहे कंपोनेंट दा इस्तेमाल अपने डेटा नु दर्शाने ते आयाम नु ½ च घटाने लेई करी सकदे ओ। फेर मॉडल बनाना आसान होई जंदा ऐ (उदाहरण लेई, इमेज रिकॉग्निशन च)।", "normalised": "हां, बिल्कुल ए-आई। आइगेनवैल्यूज़ ते आइगेनवेक्टर डायमेंशनलिटी रिडक्शन तकनीकें च बड़िया रोल अदा करदे न, जि'यां प्रिंसिपल कंपोनेंट एनालिसिस (पी-सी-ए)। सोचो तुसें इक डेटासेट पर कम्म करदे हो जिस च ढेर सारी विशेषताएं न, जि'यां चेहरे दी तस्वीरें दा इक डेटासेट। हर तस्वीर च इक हजार विशेषताएं (इक हजार पिक्सेल) न, तुस अपने डेटा दे कोवेरिएंस मैट्रिक्स दे सब्भनें शा बड्डे आइगेनवैल्यूज़ दे अनुरूप \"प्रिंसिपल कंपोनेंट\" लभने आस्तै पी-सी-ए दा इस्तेमाल करी सकदे ओ, जेह्ड़े बुनियादी तौर पर आइगेनवेक्टर न। तुस अपने डेटा गी दर्शाने ते डाइमेंशन गी इक च दो कन्नै बंडने आस्तै उंदे कुसै कंपोनेंट दा इस्तेमाल करी सकदे ओ। फिर मॉडल बनाना आसान ऐ (उदाहरण आस्तै, इमेज रिकग्निशन च)।", "text": "हां, बिल्कुल एआई। आइगनमूल ते आइगन वेक्टर आयाम घटाने दी तकनीकें च बड्डा रोल निभांदे न, जिਵੇਂ के प्रिंसिपल कंपोनेंट एनालिसिस (PCA)। सोचो तुस्सां ढेर सारी विशेषताएं आले डेटासेट नाल कम्म करी करदे ओ, जिਵੇਂ के चेहरें दी तस्वीरें दा डेटासेट। हर तस्वीर च 1000 विशेषताएं (1000 पिक्सेल) न, तुस्सां PCA दा इस्तेमाल \"प्रिंसिपल कंपोनेंट\" पता करने लेई करी सकदे ओ, जेह्ड़े बुनियादी तौर उप्पर तुंदे डेटा दे कोवेरियंस मैट्रिक्स दे सब्भनें शा बड्डे आइगनमूलें दे अनुरूप आइगन वेक्टर न। तुस्सां थोड़े जिहे कंपोनेंट दा इस्तेमाल अपने डेटा नु दर्शाने ते आयाम नु ½ च घटाने लेई करी सकदे ओ। फेर मॉडल बनाना आसान होई जंदा ऐ (उदाहरण लेई, इमेज रिकॉग्निशन च)।"}
{"unnormalised": "आशा ऐ के इस कन्नै थोड़ी मदद होग! लीनियर अलजेब्रा कदे-कदे अमूर्त लग्गी सकदा ऐ, पर eigenvalues ​​ते eigenvectors दे टनें अनुप्रयोग बाहर नेईं, जेकर तुस सिर्फ उन्हें ढूँढो। ते भूलो नेईं, अभ्यास ही कुंजी ऐ! तेरे इम्तिहान वास्ते शुभकामनाएं भाई!", "normalised": "उम्मीद ऐ कि इस कन्नै थोड़ी मदद होग! लीनियर अलजेब्रा कदे-कदे अमूर्त दिक्ख दा ऐ, पर eigenvalues ​​ते eigenvectors दे होई सारे अनुप्रयोग न, जे तुस सिर्फ उन्हां दी तलाश करो। ते एह् ना भुल्लना, अभ्यास कुंजी ऐ! तुंदे इम्तिहान लेई शुभकामनाएं ब्रो!", "text": "आशा ऐ के इस कन्नै थोड़ी मदद होग! लीनियर अलजेब्रा कदे-कदे अमूर्त लग्गी सकदा ऐ, पर eigenvalues ​​ते eigenvectors दे टनें अनुप्रयोग बाहर नेईं, जेकर तुस सिर्फ उन्हें ढूँढो। ते भूलो नेईं, अभ्यास ही कुंजी ऐ! तेरे इम्तिहान वास्ते शुभकामनाएं भाई!"}
