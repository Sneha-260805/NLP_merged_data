{"unnormalised": "मैं गी लीनियर अलजेब्रा समझन च दिक्क्त आई रही ऐ। की कोई आसान शब्दें च आइगनवेक्टर्स ते आइगनवेल्यूज समझाया सकदा ऐ, खास करियै इस गल्ल कन्नै जे ओह् असली दुनियां दी एप्लीकेशन च किस चाल्लीं इस्तेमाल होई सकदे न? मेरी टेक्स्टबुक एह् बिल्कुल साफ नीं करदी।", "normalised": "मियां लीनियर अलजेब्रा समझने च दिक्क्त आई रही है। केई मताईदा वेक्टर ते आइगनवैल्यू सरल शब्द्दे च समझा सकदा है, खास करी के ओ असली दुनिया दे इस्तेमालें च केह्जे बरते जाई सकदे न? मेरी किताब ऐनू साफ नी बना रही है।", "text": "मैं गी लीनियर अलजेब्रा समझन च दिक्क्त आई रही ऐ। की कोई आसान शब्दें च आइगनवेक्टर्स ते आइगनवेल्यूज समझाया सकदा ऐ, खास करियै इस गल्ल कन्नै जे ओह् असली दुनियां दी एप्लीकेशन च किस चाल्लीं इस्तेमाल होई सकदे न? मेरी टेक्स्टबुक एह् बिल्कुल साफ नीं करदी।"}
{"unnormalised": "अच्छा, इयां सोची लैओ जे तुंदे कोल इक मैट्रिक्स ऐ, आओ इसगी 'A' बुलाईये। हुन, जे तुस 'A' गी इक वेक्टर, 'v', कन्नै गुणा करदे ओ, तां तुसेंगी इक होर वेक्टर मिलदा ऐ। इक eigenvector इक खास वेक्टर 'v' ऐ जेह्ड़ा, जिसलै 'A' कन्नै गुणा कीता जंदा ऐ, तां सिर्फ स्केल च बदली करदा ऐ, दिशा च नेईं। जिस राशी कन्नै ऐ स्केल करदा ऐ उसगी eigenvalue आखदे न, जिसगी 'λ' कन्नै दर्शाया जंदा ऐ। तां, समीकरण ऐ A * v = λ * v. इसगी इयां सोची लैओ: जे 'A' इक रूपांतरण दा प्रतिनिधित्व करदा ऐ, तां eigenvector 'v' इक वेक्टर ऐ जेह्ड़ा रूपांतरण दे बाद बी संरेखित रौंह्दा ऐ, बस λ दे फैक्टर कन्नै खींचेआ जां दबाया जंदा ऐ। eigenvalues ​​ते eigenvectors गी गिनने च अक्सर बहुपद समीकरणें गी हल करना शामल होंदा ऐ; विशेषता बहुपद det(A - λI) = 0 दे मूलां गी खोजने कन्नै तुसेंगी eigenvalues ​​मिलदे न, जित्थै 'I' पहचान मैट्रिक्स ऐ। 3x3 मैट्रिक्स च, इस च थोड़ी होर मेहनत लगदी ऐ, खास कर के जिसलै eigenvalues ​​जटिल होंदे न। तुसेंगी शायद अपनी 11 वीं क्लास दी गणित चों अपनी जटिल संख्या जोड़-तोड़ गी याद रखने दी लोड़ होग!", "normalised": "ठीक है, तो सोचो तुसां लग्गे इक मैट्रिक्स ऐ, चलो असां इसयो 'A' बुलाईए। हुन, जे तुसां 'A' गी इक वेक्टर, 'v', कन्नै गुना करदे ओ, तां तुसां गी इक होर वेक्टर मिलदा ऐ। इक आइगनवेक्टर इक खास वेक्टर 'v' ऐ जेह्ड़ा, जदों 'A' कन्नै गुना कीता जंदा ऐ, तां सिर्फ स्केले च बदल्दी ऐ, दिशा च नेईं। ओह् मात्रा जेह्दे कन्नै ऐ स्केले करदी ऐ गी आइगनवैल्यू आखदे न, जिसगी 'लैम्डा' कन्नै दर्शायी जंदी ऐ। तां, समीकरण ऐ A गुणे v बराबर ऐ लैम्डा गुणे v दे। इसगी इस चाल्ली सोचो: जे 'A' इक परिवर्तन गी दर्शांदा ऐ, तां आइगनवेक्टर 'v' इक वेक्टर ऐ जेह्ड़ा परिवर्तन दे बाद बी अलाइन रेह्न्दा ऐ, बस लैम्डा दे फैक्टर कन्नै खिच्ची जां संकुचित कीता जंदा ऐ। आइगनवैल्यू ते आइगनवेक्टर दी गणना च अकसर बहुपद समीकरणें गी हल करना शामल ऐ; A माइनस लैम्डा I दे विशेषता वाले बहुपद निर्धारक दे मू्लें गी ढूंढना बराबर ऐ शून्य दे जेह्ड़ा तुसां गी आइगनवैल्यू दिंदा ऐ, जित्थै 'I' पहचान मैट्रिक्स ऐ। त्रै बाई त्रै मैट्रिक्स च, इस च थोड़ी होर मेहनत दी लोड़ होंदी ऐ, खास करी के जदों आइगनवैल्यू जटिल होंदे न। तुसां गी ग्यारह्वीं क्लास दे गणित चों अपने जटिल संख्या हेरफेर याद रखने दी लोड़ होई सकदी ऐ!", "text": "अच्छा, इयां सोची लैओ जे तुंदे कोल इक मैट्रिक्स ऐ, आओ इसगी 'A' बुलाईये। हुन, जे तुस 'A' गी इक वेक्टर, 'v', कन्नै गुणा करदे ओ, तां तुसेंगी इक होर वेक्टर मिलदा ऐ। इक eigenvector इक खास वेक्टर 'v' ऐ जेह्ड़ा, जिसलै 'A' कन्नै गुणा कीता जंदा ऐ, तां सिर्फ स्केल च बदली करदा ऐ, दिशा च नेईं। जिस राशी कन्नै ऐ स्केल करदा ऐ उसगी eigenvalue आखदे न, जिसगी 'λ' कन्नै दर्शाया जंदा ऐ। तां, समीकरण ऐ A * v = λ * v. इसगी इयां सोची लैओ: जे 'A' इक रूपांतरण दा प्रतिनिधित्व करदा ऐ, तां eigenvector 'v' इक वेक्टर ऐ जेह्ड़ा रूपांतरण दे बाद बी संरेखित रौंह्दा ऐ, बस λ दे फैक्टर कन्नै खींचेआ जां दबाया जंदा ऐ। eigenvalues ​​ते eigenvectors गी गिनने च अक्सर बहुपद समीकरणें गी हल करना शामल होंदा ऐ; विशेषता बहुपद det(A - λI) = 0 दे मूलां गी खोजने कन्नै तुसेंगी eigenvalues ​​मिलदे न, जित्थै 'I' पहचान मैट्रिक्स ऐ। 3x3 मैट्रिक्स च, इस च थोड़ी होर मेहनत लगदी ऐ, खास कर के जिसलै eigenvalues ​​जटिल होंदे न। तुसेंगी शायद अपनी 11 वीं क्लास दी गणित चों अपनी जटिल संख्या जोड़-तोड़ गी याद रखने दी लोड़ होग!"}
{"unnormalised": "तो, ऐ कुत्थें बरतेंदे न? इक मता ज़रूरी इस्तेमाल ऐ गूगल दे पेज रैंक एल्गोरिदम च। इंटरनेट गी इक मता बड्डा नेटवर्क दस्सेआ जाई सकदा ऐ, जिस च वेब पेज नोड दे तौर पर ते लिंक किनारे दे तौर पर होंदे न। पेज रैंक लिंक मैट्रिक्स दे सब्भै शा बड्डे आइगेनवैल्यू दे अनुरूप आइगेनवेक्टर दा इस्तेमाल हर पेज दी सापेक्षिक महत्वता दा पता लग्गान लेई करदा ऐ। इक होर इस्तेमाल इमेज कंप्रेसन तकनीक च ऐ, जिਵੇਂ प्रिंसिपल कंपोनेंट एनालिसिस (PCA)। PCA इक इमेज दे प्रिंसिपल कंपोनेंट गी पहचानने लेई आइगेनवेक्टर्स दा इस्तेमाल करदा ऐ, जिस कन्नै तुस्सी मता जानकारी खोए बिना डेटा साइज गी घट्ट करी सकदे ओ। मनो तुआडे कोल 1024x768 पिक्सेल दी इमेज ऐ, तुस्सी PCA दा इस्तेमाल करी सकदे ओ ते इमेज दी मता जानकारी नु दस्सन आह्ले सिर्फ टॉप 100 आइगेनवेक्टर्स गी ही रख सकदे ओ। भौतिकी च, ऐह्नां दा इस्तेमाल किसी सिस्टम दे वाइब्रेशन दे नॉर्मल मोड गी ढूंढने लेई कीता जंदा ऐ, चाहे ओह् अणु हों या पुल!", "normalised": "ते, इह् कुत्थें बरतने दे न? इक खास बरतून गूगल दे पेज रैंक एल्गोरिदम च ऐ। इंटरनेट गी इक बड्डे नेटवर्क दे तौर पर दर्शाया जाई सकदा ऐ, जिस च वेब पेज नोड दे तौर पर ते लिंक किनारी दे तौर पर होंदे न। पेज रैंक लिंक मैट्रिक्स दे सब तों बड्डे आइगन वैल्यू कन्नै मेल खाने आह्ले आइगनवेक्टर दा इस्तेमाल करदा ऐ तां जे हर पेज दी नैटवर्क च की अहमियत ऐ, ऐ पता लग्गेआ जाई सकै। इक होर बरतून इमेज कंप्रेशन तकनीक च ऐ जिਵੇਂ पी-सी-ए। पी-सी-ए इक इमेज दे मुख घटकें गी पहचानने लेई आइगनवेक्टर दा इस्तेमाल करदा ऐ, जिस कन्नै तुस जानकारी गी जादा खोए बिना डाटा दा आकार घट्ट करी सकदे ओ। मनो कि तुहाडे कोल हजार चोबी ते सात सौ अडसठ पिक्सेल दी इक तस्वीर ऐ, तुस पी-सी-ए दा इस्तेमाल करी सकदे ओ ते सिर्फ सौ सब तों उच्च आइगनवेक्टर ही रख सकदे ओ जेह्डे इमेज दी मता जानकारी गी दर्शांदे न। फिजिक्स च, इह् कुसै सिस्टम दे कंपन दे समान मोडें गी पता लाने लेई बरतने दे न, चाहे इह् अणु होन या पुल!", "text": "तोह्, इह् कुत्थें बरतने आह्ले न? इक मत्वपूर्ण इस्तेमाल ऐ गूगल दे पेज रैंक एल्गोरिथ्म च। इंटरनेट गी इक बड्डे नेटवर्क दे रूप च दर्शाया जाई सकदा ऐ, जिस च वेब पेज नोड दे रूप च ते लिंक किनारे दे रूप च होंदे न। पेज रैंक लिंक मैट्रिक्स दे सब्भै शा बड्डे आइगेनवैल्यू आह्ले आइगेनवेक्टर दा इस्तेमाल हर पेज दे सापेक्ष महत्व गी निर्धारत करने लेई करदा ऐ। इक होर एप्लीकेशन ऐ इमेज कम्प्रेशन तकनीकें जिਵੇਂ के (PCA)। पीसीए इक इमेज दे प्रिंसिपल कंपोनेंट्स गी पहचानने लेई आइगेनवेक्टर्स दा इस्तेमाल करदा ऐ, जिस कन्नै तुस बत्ती जानकारी खोए बिना डेटा साइज गी घट्ट करी सकदे ओ। मान लो तुंदे कोल 1024x768 पिक्सेल दी इक इमेज ऐ, तुस पीसीए दा इस्तेमाल करी सकदे ओ ते सिर्फ टॉप 100 आइगेनवेक्टर्स गी रक्खी सकदे ओ जेह्ड़े ज्यादातर इमेज जानकारी गी दर्शांदे न। भौतिक विज्ञान च, इनह्ना दा इस्तेमाल किसी सिस्टम दे कंपन दे सामान्य मोड ढूंढने लेई कीता जंदा ऐ, चाहे उह् अणु हों या पुल!"}
{"unnormalised": "असल विच, आइगनवैल्यूज़ ते आइगनवेक्टर जटिल प्रणालियें गी सरल बनाने च मदद करदे न। इन \"अपरिवर्तनीय\" दिशाएं ते स्केलिंग फेक्टरों गी पहचाणने दे नाल, अस समझ सकदे आं जे इक रेखीय परिवर्तन इक स्पेस पर केंईं कम्म करदा ऐ ते इस ज्ञान दा इस्तेमाल करी के कईं क्षेत्रें च समस्याएं हल करी सकदे आं। इथे तां तक कि रैखिक अवकल समीकरणें दी प्रणाली (उदाहरण खातर dx/dt = Ax) गी हल करने च बी, मैट्रिक्स 'A' दे आइगनवैल्यूज़ λ1 ते λ2 पता करना इक ज़रूरी पहला कदम ऐ। कुच्छ उदाहरण देखो ते उन्हां गी हल करने दी कोशिश करो; अभ्यास नाल बहुत मदद मिलदी ऐ!", "normalised": "असल विच, आइगनमूल ते आइगनवेक्टर जटिल सिस्टमें गी आसान बनाने च मदद करदे न। इनें \"अपरिवर्तनीय\" दिशाएं ते स्केलिंग फैक्टरें गी पहचानेआ करी, अस समझ सकदे आं कि इक रैखिक परिवर्तन इक स्थान उप्पर किस चाल्लीं कम्म करदा ऐ ते इस ज्ञान दा इस्तेमाल करी के बक्ख-बक्ख क्षेत्रें च समस्याएं हल करी सकदे आं। इथे तक कि किसें रैखिक अवकल समीकरणें दे सिस्टम गी हल करने च (उदाहरण लेई d x गी d t कन्नै भाग दिता गेआ ऐ A x दे बराबर ऐ), मैट्रिक्स 'A' दे आइगनमूल लैम्ब्डा इक ते लैम्ब्डा दो गी लभना इक महत्वपूर्ण पहला कदम ऐ। कुसै उदाहरन गी तलाशो ते उन्हां गी हल करने दी कोशिश करो; अभ्यास कन्नै बड़ी मदद मिलदी ऐ!", "text": "असल विच, आइगनवैल्यूज़ ते आइगनवेक्टर जटिल प्रणालियें गी सरल बनाने च मदद करदे न। इन \"अपरिवर्तनीय\" दिशाएं ते स्केलिंग फेक्टरों गी पहचाणने दे नाल, अस समझ सकदे आं जे इक रेखीय परिवर्तन इक स्पेस पर केंईं कम्म करदा ऐ ते इस ज्ञान दा इस्तेमाल करी के कईं क्षेत्रें च समस्याएं हल करी सकदे आं। इथे तां तक कि रैखिक अवकल समीकरणें दी प्रणाली (उदाहरण खातर dx/dt = Ax) गी हल करने च बी, मैट्रिक्स 'A' दे आइगनवैल्यूज़ λ1 ते λ2 पता करना इक ज़रूरी पहला कदम ऐ। कुच्छ उदाहरण देखो ते उन्हां गी हल करने दी कोशिश करो; अभ्यास नाल बहुत मदद मिलदी ऐ!"}
