{"unnormalised": "केनचित् पृष्टोऽहं यन्त्रशिक्षणे रैखिकबीजगणितस्य उपयोगविषये। अहो, तत् तु अतीव मूलभूतम्। मन्यतां कश्चन प्राथमिकः कृत्रिम-तन्त्रिका-जालस्तरः; सः अनिवार्यरूपेण आव्यूहगुणनम्। प्रत्येकस्य तन्त्रिकाकोशस्य निर्गमः तस्य निविष्टानां भारितं योगफलम्, एते च भाराः आव्यूहेषु संगठिताः। उदाहरणार्थम्, कस्यचित् स्तरस्य भाराः W (100 x 50) मित्याकाराः भवेयुः, अर्थात् सः 50-आयामिकं निविष्टं 100-आयामिके निर्गमे परिवर्तयति। अग्रिमगमने Wx + b इत्यस्य गणना अन्तर्भवति, यत्र x निविष्टसदिशः, b च अभिनतिसदिशः। इदं 'Wx' इत्यत्रैव रैखिकबीजगणितस्य प्रकाशः।", "normalised": "कश्चित् माम् अपृच्छत् यन्त्रशिक्षणे रेखीयबीजगणितस्य उपयोगान् विषये।\nअस्तु, तत् तु आधारभूतम् अस्ति।\nकस्मिंश्चित् आधारभूते स्नायुजालस्तरे विचार्यताम्; तत् मूलतः आव्यूहगुणनम् एव।\nप्रत्येकस्य स्नायुकणस्य निर्गमः तस्य निवेशानां भारितं योगफलम् अस्ति, एते च भाराः आव्यूहेषु आयोजिताः सन्ति।\nउदाहरणार्थम्, कस्यचित् स्तरस्य भाराः W स्युः ये शतपञ्चाशत्परिमाणाः, अर्थात् तत् पञ्चाशत्-परिमाणकं निवेशं शत-परिमाणके निर्गमे परिवर्तयति।\nअग्रिम-गतिः W x अधिकं b इत्यस्य गणनां अन्तर्भावयति, यत्र x निवेश-सदिशः, b च अभिनति-सदिशः अस्ति।\nइदं 'W x' इति तत् स्थानम् अस्ति यत्र रेखीयबीजगणितं शोभते।", "text": "केनचित् पृष्टोऽहं यन्त्रशिक्षणे रैखिकबीजगणितस्य उपयोगविषये। अहो, तत् तु अतीव मूलभूतम्। मन्यतां कश्चन प्राथमिकः कृत्रिम-तन्त्रिका-जालस्तरः; सः अनिवार्यरूपेण आव्यूहगुणनम्। प्रत्येकस्य तन्त्रिकाकोशस्य निर्गमः तस्य निविष्टानां भारितं योगफलम्, एते च भाराः आव्यूहेषु संगठिताः। उदाहरणार्थम्, कस्यचित् स्तरस्य भाराः W (100 x 50) मित्याकाराः भवेयुः, अर्थात् सः 50-आयामिकं निविष्टं 100-आयामिके निर्गमे परिवर्तयति। अग्रिमगमने Wx + b इत्यस्य गणना अन्तर्भवति, यत्र x निविष्टसदिशः, b च अभिनतिसदिशः। इदं 'Wx' इत्यत्रैव रैखिकबीजगणितस्य प्रकाशः।"}
{"unnormalised": "अथ चित्रप्रक्रिया विद्यते । चित्रं आव्यूहेण निरूपयितुं शक्यते (अथवा वर्णचित्राणां कृते आव्यूहसमुच्चयेन) । धूमनं, कोरज्ञानं, भ्रमणादिक्रियाः सर्वाः रैखिकबीजगणितसंकल्पनासु आश्रिताः । उदाहरणार्थं, 3x3 संवलनकेन्द्रकस्य अनुप्रयोगे घटकवारगुणनं योगश्च अन्तर्भवति, यत् आव्यूहक्रियाभिः निरूपयितुं शक्यते । सरलकार्याणि अपि, यथा चित्रस्य आकारपरिवर्तनं वा कर्तनं, रैखिकपरिवर्तनरूपेण द्रष्टुं शक्यते । चित्रसंपीडनप्रणाल्यः, यथा पी.सी.ए., अपि रैखिकबीजगणितस्य प्रचुरं उपयोगं कुर्वन्ति ।", "normalised": "अथ चित्रप्रक्रिया विद्यते। चित्रं आव्यूहेन वा वर्णचित्राणां कृते आव्यूहसमुच्चयेन वा निरूपयितुं शक्यते। धूमनं, सीमाज्ञानं, भ्रमणानि इत्यादीनि कार्याणि सर्वाणि रैखिकबीजगणितसंकल्पनाधारितानि। उदाहरणार्थं, त्रिगुणत्रिगुणसंवलनकन्दस्य प्रयोगे अवयववारगुणनं योगश्च अन्तर्भवति यत् आव्यूहकार्यैः निरूपयितुं शक्यते। चित्रस्य आकारपरिवर्तनं वा कर्तनं वा इव सरलकार्याणि अपि रैखिकपरिवर्तनरूपेण द्रष्टुं शक्यन्ते। पी-सी-ए सदृश्यः चित्रसंपीडनप्रयुक्तिः अपि रैखिकबीजगणितं बहुधा उपयुज्यते।", "text": "अथ चित्रप्रक्रिया विद्यते । चित्रं आव्यूहेण निरूपयितुं शक्यते (अथवा वर्णचित्राणां कृते आव्यूहसमुच्चयेन) । धूमनं, कोरज्ञानं, भ्रमणादिक्रियाः सर्वाः रैखिकबीजगणितसंकल्पनासु आश्रिताः । उदाहरणार्थं, 3x3 संवलनकेन्द्रकस्य अनुप्रयोगे घटकवारगुणनं योगश्च अन्तर्भवति, यत् आव्यूहक्रियाभिः निरूपयितुं शक्यते । सरलकार्याणि अपि, यथा चित्रस्य आकारपरिवर्तनं वा कर्तनं, रैखिकपरिवर्तनरूपेण द्रष्टुं शक्यते । चित्रसंपीडनप्रणाल्यः, यथा पी.सी.ए., अपि रैखिकबीजगणितस्य प्रचुरं उपयोगं कुर्वन्ति ।"}
{"unnormalised": "अग्रे, रैखिकबीजगणितं Gradient Descent-इत्यादिवत् यन्त्रशिक्षणे उपयुज्यमानानाम् अनुकूलनाविधिनाम् आधारः अस्ति।\nएते विधयः कार्यक्षमरीत्या प्रतिरूपाणां প্রশিক্ষণে महत्त्वपूर्णाः सन्ति।\nअतः, भवान् सर्वदा स्पष्टरूपेण आव्यूहान् न लिखति चेदपि, रैखिकबीजगणितस्य दृढं ज्ञानं निश्चितरूपेण भवते अनेकेषां ML-प्रतिरूपाणां आन्तरिककार्यं ज्ञातुं साहाय्यं करिष्यति, तथा च स्वस्य कूटस्य दोषमार्जनं कर्तुम् अपि साहाय्यं करिष्यति।\nभवन्तं सर्वदा eigenvalues, eigenvectors, matrix decomposition, vector spaces इत्यादीनां विषयाणां सामना भविष्यति।", "normalised": "अपि च, रैखिकबीजगणितं Gradient Descent इत्येवं Machine Learning इत्यत्र प्रयुज्यमानानाम् Optimization algorithm-इत्याख्यानां बह्वीनां आधारः। एते algorithms कार्यक्षमत्वेन प्रतिमानानां प्रशिक्षणायातीव महत्वपूर्णाः। अतः, यद्यपि भवन्तः सर्वदा स्पष्टरूपेण आव्यूहान् न लिखन्ति, तथापि रैखिकबीजगणितस्य दृढं ज्ञानं निश्चितरूपेण भवतां बह्वीनां M-L प्रतिमानानाम् आन्तरिककार्यप्रणालीं ज्ञातुं, भवतां कूटस्य Debugging-करणे च साहाय्यं करिष्यति। भवन्तः eigenvalues, eigenvectors, matrix decomposition, vector spaces इत्यादीनि सर्वदा अनुभविष्यन्ति।", "text": "अग्रे, रैखिकबीजगणितं Gradient Descent-इत्यादिवत् यन्त्रशिक्षणे उपयुज्यमानानाम् अनुकूलनाविधिनाम् आधारः अस्ति।\nएते विधयः कार्यक्षमरीत्या प्रतिरूपाणां প্রশিক্ষণে महत्त्वपूर्णाः सन्ति।\nअतः, भवान् सर्वदा स्पष्टरूपेण आव्यूहान् न लिखति चेदपि, रैखिकबीजगणितस्य दृढं ज्ञानं निश्चितरूपेण भवते अनेकेषां ML-प्रतिरूपाणां आन्तरिककार्यं ज्ञातुं साहाय्यं करिष्यति, तथा च स्वस्य कूटस्य दोषमार्जनं कर्तुम् अपि साहाय्यं करिष्यति।\nभवन्तं सर्वदा eigenvalues, eigenvectors, matrix decomposition, vector spaces इत्यादीनां विषयाणां सामना भविष्यति।"}
