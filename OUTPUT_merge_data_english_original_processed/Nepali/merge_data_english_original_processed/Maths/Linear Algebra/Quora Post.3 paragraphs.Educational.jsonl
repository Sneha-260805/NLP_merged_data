{"unnormalised": "मलाई लिनियर बीजगणित बुझ्न गाह्रो भइरहेको छ। कसैले मलाई आइगेनभेक्टर र आइगेनभ्यालुहरू सरल शब्दमा बुझाउन सक्नुहुन्छ, विशेष गरी तिनीहरूलाई वास्तविक-संसारका अनुप्रयोगहरूमा कसरी प्रयोग गर्न सकिन्छ? मेरो पाठ्यपुस्तकले यसलाई स्पष्ट गरिरहेको छैन।", "normalised": "मलाई रेखीय बीजगणित बुझ्न गाह्रो भइरहेको छ। कसैले आइगेनभेक्टर र आइगेनभ्यालुलाई सरल भाषामा व्याख्या गर्न सक्छ, विशेष गरी तिनीहरू वास्तविक संसारका अनुप्रयोगहरूमा कसरी प्रयोग हुन सक्छन्? मेरो पाठ्यपुस्तकले यसलाई स्पष्ट गरिरहेको छैन।", "text": "मलाई लिनियर बीजगणित बुझ्न गाह्रो भइरहेको छ। कसैले मलाई आइगेनभेक्टर र आइगेनभ्यालुहरू सरल शब्दमा बुझाउन सक्नुहुन्छ, विशेष गरी तिनीहरूलाई वास्तविक-संसारका अनुप्रयोगहरूमा कसरी प्रयोग गर्न सकिन्छ? मेरो पाठ्यपुस्तकले यसलाई स्पष्ट गरिरहेको छैन।"}
{"unnormalised": "ठीक छ, मान्नुहोस् तपाईंसँग एउटा म्याट्रिक्स छ, त्यसलाई 'A' भनौं। अब, यदि तपाईंले 'A' लाई भेक्टर, 'v' सँग गुणन गर्नुभयो भने, तपाईंले अर्को भेक्टर पाउनुहुन्छ। आइगेनभेक्टर एउटा विशेष भेक्टर 'v' हो, जसलाई 'A' ले गुणन गर्दा दिशा परिवर्तन नगरी स्केलमा मात्र परिवर्तन हुन्छ। यो स्केल हुने मात्रालाई आइगेनभ्यालु भनिन्छ, जसलाई 'λ' ले जनाइन्छ। त्यसैले, समीकरण A * v = λ * v हो। यसलाई यसरी सोच्नुहोस्: यदि 'A' ले रूपान्तरणलाई प्रतिनिधित्व गर्छ भने, आइगेनभेक्टर 'v' एउटा भेक्टर हो जुन रूपान्तरण पछि पनि पङ्क्तिबद्ध रहन्छ, केवल λ को कारकले तन्काइएको वा संकुचित हुन्छ। आइगेनभ्यालु र आइगेनभेक्टरहरू गणना गर्दा प्रायः polynomial समीकरणहरू समाधान गर्नुपर्ने हुन्छ; characteristic polynomial det(A - λI) = 0 को जरा पत्ता लगाउँदा आइगेनभ्यालुहरू प्राप्त हुन्छन्, जहाँ 'I' पहिचान म्याट्रिक्स हो। 3x3 म्याट्रिक्समा, यसका लागि अलिक बढी काम गर्नुपर्छ, विशेष गरी जब आइगेनभ्यालुहरू जटिल हुन्छन्। तपाईंले कक्षा ११ को गणितबाट जटिल संख्याको हेरफेर याद गर्नुपर्ने हुन सक्छ!", "normalised": "ठिक छ, मान्नुहोस् तपाईंसँग एउटा म्याट्रिक्स छ, त्यसलाई 'A' भनौं। अब, यदि तपाईंले 'A' लाई एउटा भेक्टर, 'v' सँग गुणन गर्नुभयो भने, तपाईंले अर्को भेक्टर पाउनुहुन्छ। आइगेनभेक्टर एउटा विशेष भेक्टर 'v' हो, जसलाई 'A' सँग गुणन गर्दा दिशा परिवर्तन नगरी केवल स्केल परिवर्तन हुन्छ। यो स्केल हुने मात्रालाई आइगेनभ्यालु भनिन्छ, जसलाई 'lambda' ले जनाइन्छ। त्यसैले, समीकरण A गुणा v बराबर lambda गुणा v हुन्छ। यसलाई यसरी सोच्नुहोस्: यदि 'A' ले रूपान्तरणलाई प्रतिनिधित्व गर्छ भने, आइगेनभेक्टर 'v' एउटा भेक्टर हो जुन रूपान्तरण पछि पनि पङ्क्तिबद्ध रहन्छ, केवल lambda को गुणनले तन्काइएको वा खुम्चाइएको हुन्छ। आइगेनभ्यालु र आइगेनभेक्टर गणना गर्न प्रायः polynomial समीकरणहरू समाधान गर्नुपर्ने हुन्छ; A माइनस lambda I को क्यारेक्टरिस्टिक polynomial determinant को मूलहरू पत्ता लगाउनुले तपाईंलाई आइगेनभ्यालुहरू दिन्छ, जहाँ 'I' आइडेन्टिटी म्याट्रिक्स हो। तीन गुणा तीन म्याट्रिक्समा, यसले अलिक बढी काम गर्नुपर्ने हुन्छ, विशेष गरी जब आइगेनभ्यालुहरू जटिल हुन्छन्। तपाईंले कक्षा ११ को गणितबाट आफ्नो जटिल संख्याको manipulation हरू सम्झन आवश्यक हुन सक्छ!", "text": "ठीक छ, मान्नुहोस् तपाईंसँग एउटा म्याट्रिक्स छ, त्यसलाई 'A' भनौं। अब, यदि तपाईंले 'A' लाई भेक्टर, 'v' सँग गुणन गर्नुभयो भने, तपाईंले अर्को भेक्टर पाउनुहुन्छ। आइगेनभेक्टर एउटा विशेष भेक्टर 'v' हो, जसलाई 'A' ले गुणन गर्दा दिशा परिवर्तन नगरी स्केलमा मात्र परिवर्तन हुन्छ। यो स्केल हुने मात्रालाई आइगेनभ्यालु भनिन्छ, जसलाई 'λ' ले जनाइन्छ। त्यसैले, समीकरण A * v = λ * v हो। यसलाई यसरी सोच्नुहोस्: यदि 'A' ले रूपान्तरणलाई प्रतिनिधित्व गर्छ भने, आइगेनभेक्टर 'v' एउटा भेक्टर हो जुन रूपान्तरण पछि पनि पङ्क्तिबद्ध रहन्छ, केवल λ को कारकले तन्काइएको वा संकुचित हुन्छ। आइगेनभ्यालु र आइगेनभेक्टरहरू गणना गर्दा प्रायः polynomial समीकरणहरू समाधान गर्नुपर्ने हुन्छ; characteristic polynomial det(A - λI) = 0 को जरा पत्ता लगाउँदा आइगेनभ्यालुहरू प्राप्त हुन्छन्, जहाँ 'I' पहिचान म्याट्रिक्स हो। 3x3 म्याट्रिक्समा, यसका लागि अलिक बढी काम गर्नुपर्छ, विशेष गरी जब आइगेनभ्यालुहरू जटिल हुन्छन्। तपाईंले कक्षा ११ को गणितबाट जटिल संख्याको हेरफेर याद गर्नुपर्ने हुन सक्छ!"}
{"unnormalised": "त्यसो भए, यिनीहरू कहाँ प्रयोग हुन्छन्? एउटा महत्त्वपूर्ण अनुप्रयोग गुगलको PageRank एल्गोरिदममा छ। इन्टरनेटलाई विशाल नेटवर्कको रूपमा प्रतिनिधित्व गर्न सकिन्छ, जहाँ वेब पृष्ठहरू नोड र लिङ्कहरू किनाराको रूपमा हुन्छन्। PageRank ले प्रत्येक पृष्ठको सापेक्षिक महत्त्व निर्धारण गर्न लिङ्क म्याट्रिक्सको सबैभन्दा ठूलो eigenvalue सँग मिल्दो eigenvector प्रयोग गर्दछ। अर्को अनुप्रयोग Principal Component Analysis (PCA) जस्ता छवि सङ्कुचन प्रविधिहरूमा छ। PCA ले छविको मुख्य कम्पोनेन्टहरू पहिचान गर्न eigenvectors प्रयोग गर्दछ, जसले गर्दा धेरै जानकारी नगुमाईकन डेटाको आकार घटाउन अनुमति दिन्छ। मान्नुहोस् तपाईंसँग 1024x768 पिक्सेलको छवि छ, तपाईं PCA प्रयोग गर्न सक्नुहुन्छ र छविको धेरैजसो जानकारी प्रतिनिधित्व गर्ने शीर्ष 100 eigenvectors मात्र राख्न सक्नुहुन्छ। भौतिकशास्त्रमा, तिनीहरूलाई प्रणालीको कम्पनको सामान्य मोडहरू पत्ता लगाउन प्रयोग गरिन्छ, चाहे त्यो अणु होस् वा पुल!", "normalised": "त्यसोभए, यिनीहरु कहाँ प्रयोग हुन्छन्? एउटा महत्त्वपूर्ण प्रयोग गुगलको पेज र्याङ्क एल्गोरिदममा छ। इन्टरनेटलाई एउटा विशाल नेटवर्कको रूपमा प्रतिनिधित्व गर्न सकिन्छ, जसमा वेब पृष्ठहरू नोडको रूपमा र लिङ्कहरू किनाराको रूपमा हुन्छन्। पेज र्याङ्कले प्रत्येक पृष्ठको सापेक्षिक महत्त्व निर्धारण गर्न लिङ्क म्याट्रिक्सको सबैभन्दा ठूलो आइगेनभ्यालुसँग सम्बन्धित आइगेनभेक्टर प्रयोग गर्दछ। अर्को प्रयोग छवि सङ्कुचन प्रविधिहरू जस्तै पी-सी-ए मा छ। पी-सी-एले छविको मुख्य कम्पोनेन्टहरू पहिचान गर्न आइगेनभेक्टरहरू प्रयोग गर्दछ, जसले धेरै जानकारी नगुमाई डेटा आकार घटाउन अनुमति दिन्छ। मानौं तपाईंसँग एक हजार चौबीस बाइ सात सय अड्चालीस पिक्सेलको छवि छ भने, तपाईं पी-सी-ए प्रयोग गर्न सक्नुहुन्छ र छविको धेरैजसो जानकारी प्रतिनिधित्व गर्ने शीर्ष एक सय आइगेनभेक्टरहरू मात्र राख्न सक्नुहुन्छ। भौतिक विज्ञानमा, यिनीहरूलाई प्रणालीको कम्पनको सामान्य मोडहरू पत्ता लगाउन प्रयोग गरिन्छ, चाहे अणु होस् वा पुल!", "text": "त्यसोभए, यी कहाँ प्रयोग हुन्छन्? एउटा महत्त्वपूर्ण प्रयोग गुगलको PageRank एल्गोरिदममा छ। इन्टरनेटलाई एउटा विशाल नेटवर्कको रूपमा प्रतिनिधित्व गर्न सकिन्छ, जसमा वेब पृष्ठहरू नोडको रूपमा र लिङ्कहरू किनाराको रूपमा हुन्छन्। PageRank ले प्रत्येक पृष्ठको सापेक्षिक महत्त्व निर्धारण गर्न लिङ्क म्याट्रिक्सको सबैभन्दा ठूलो eigenvalue सँग सम्बन्धित eigenvector प्रयोग गर्दछ। अर्को प्रयोग छवि कम्प्रेसन प्रविधिहरू जस्तै (PCA) मा छ। PCA ले छविको मुख्य कम्पोनेन्टहरू पहिचान गर्न eigenvectors प्रयोग गर्दछ, जसले धेरै जानकारी नगुमाई डेटा आकार घटाउन अनुमति दिन्छ। मान्नुहोस् तपाईंसँग 1024x768 पिक्सेलको छवि छ, तपाईंले PCA प्रयोग गर्न सक्नुहुन्छ र छविको धेरैजसो जानकारी प्रतिनिधित्व गर्ने शीर्ष 100 eigenvectors मात्र राख्न सक्नुहुन्छ। भौतिकशास्त्रमा, तिनीहरूलाई प्रणालीको कम्पनको सामान्य मोडहरू पत्ता लगाउन प्रयोग गरिन्छ, चाहे त्यो अणु होस् वा पुलहरू!"}
{"unnormalised": "वास्तवमा, आइगेनभ्यालु र आइगेनभेक्टरहरूले जटिल प्रणालीहरूलाई सरल बनाउन मद्दत गर्छन्। यी \"अपरिवर्तनीय\" दिशाहरू र स्केलिङ फ्याक्टरहरू पहिचान गरेर, हामी एक रेखीय रूपान्तरणले स्पेसमा कसरी कार्य गर्छ भनेर बुझ्न सक्छौं र यस ज्ञानको प्रयोग गरी विभिन्न क्षेत्रका समस्याहरू समाधान गर्न सक्छौं। रेखीय भिन्न समीकरणहरूको प्रणाली (उदाहरणका लागि dx/dt = Ax) समाधान गर्ने जस्ता कुरामा पनि, म्याट्रिक्स 'A' को आइगेनभ्यालुहरू λ1 र λ2 पत्ता लगाउनु एउटा महत्वपूर्ण पहिलो चरण हो। केही उदाहरणहरू खोज्नुहोस् र तिनीहरूलाई समाधान गर्ने प्रयास गर्नुहोस्; अभ्यासले धेरै मद्दत गर्छ!", "normalised": "मूलतः, आइगनमान र आइगनभेक्टरहरूले जटिल प्रणालीहरूलाई सरल बनाउन मद्दत गर्छन्। यी \"अपरिवर्तनीय\" दिशाहरू र स्केलिंग कारकहरू पहिचान गरेर, हामी रेखीय रूपान्तरणले स्पेसमा कसरी कार्य गर्छ भनेर बुझ्न सक्छौं र यो ज्ञानलाई विभिन्न क्षेत्रहरूमा समस्याहरू समाधान गर्न प्रयोग गर्न सक्छौं। रेखीय विभेदक समीकरणहरूको प्रणाली समाधान गर्ने जस्तो कुरामा पनि (उदाहरणका लागि d x भाग d t बराबर A x), म्याट्रिक्स 'A' को आइगनमान lambda एक र lambda दुई पत्ता लगाउनु महत्त्वपूर्ण पहिलो चरण हो। केही उदाहरणहरू खोज्नुहोस् र समाधान गर्ने प्रयास गर्नुहोस्; अभ्यासले धेरै मद्दत गर्छ!", "text": "वास्तवमा, आइगेनभ्यालु र आइगेनभेक्टरहरूले जटिल प्रणालीहरूलाई सरल बनाउन मद्दत गर्छन्। यी \"अपरिवर्तनीय\" दिशाहरू र स्केलिङ फ्याक्टरहरू पहिचान गरेर, हामी एक रेखीय रूपान्तरणले स्पेसमा कसरी कार्य गर्छ भनेर बुझ्न सक्छौं र यस ज्ञानको प्रयोग गरी विभिन्न क्षेत्रका समस्याहरू समाधान गर्न सक्छौं। रेखीय भिन्न समीकरणहरूको प्रणाली (उदाहरणका लागि dx/dt = Ax) समाधान गर्ने जस्ता कुरामा पनि, म्याट्रिक्स 'A' को आइगेनभ्यालुहरू λ1 र λ2 पत्ता लगाउनु एउटा महत्वपूर्ण पहिलो चरण हो। केही उदाहरणहरू खोज्नुहोस् र तिनीहरूलाई समाधान गर्ने प्रयास गर्नुहोस्; अभ्यासले धेरै मद्दत गर्छ!"}
