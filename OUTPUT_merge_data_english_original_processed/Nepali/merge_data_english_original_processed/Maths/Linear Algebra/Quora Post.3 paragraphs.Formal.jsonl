{"unnormalised": "कसैले मलाई मेसिन लर्निङमा लीनियर एल्जेब्राको प्रयोगबारे सोधे। खैर, यो एकदमै आधारभूत छ। एउटा साधारण न्यूरल नेटवर्क लेयरलाई विचार गर्नुहोस्; यो मूलतः म्याट्रिक्स गुणन हो। प्रत्येक न्यूरोनको आउटपुट यसको इनपुटहरूको भारित योग हो, र यी भारहरूलाई म्याट्रिक्समा व्यवस्थित गरिन्छ। उदाहरणका लागि, एउटा लेयरमा (१०० x ५०) आयामको W भार हुन सक्छ, जसको अर्थ यसले ५०-आयामिक इनपुटलाई १००-आयामिक आउटपुटमा रूपान्तरण गर्छ। फर्वार्ड पासमा Wx + b गणना गर्नु समावेश छ, जहाँ x इनपुट भेक्टर हो र b bias भेक्टर हो। यो 'Wx' ठीक त्यहीँ हो जहाँ लीनियर एल्जेब्रा चम्किन्छ।", "normalised": "कसैले मलाई मेसिन लर्निङमा लीनियर अलजेब्राको प्रयोगहरु बारे सोध्यो। खैर, यो एकदमै आधारभूत छ। एउटा साधारण न्यूरल नेटवर्क लेयरलाई विचार गर्नुहोस्; यो अनिवार्य रूपमा म्याट्रिक्स गुणन हो। प्रत्येक न्यूरोनको आउटपुट यसको इनपुटहरूको भारित योग हो, र यी भारहरूलाई म्याट्रिक्समा व्यवस्थित गरिन्छ। उदाहरणका लागि, एउटा लेयरमा एक सय गुणा पचास डाइमेन्सन भएको W वेट हुन सक्छ, जसको मतलब यसले पचास-डाइमेन्सनल इनपुटलाई एक सय-डाइमेन्सनल आउटपुटमा रूपान्तरण गर्छ। फरवार्ड पासले W x प्लस b गणना गर्दछ, जहाँ x इनपुट भेक्टर हो र b एक बायस भेक्टर हो। यो 'W x' ठ्याक्कै त्यहीँ हो जहाँ लीनियर अलजेब्रा चम्किन्छ।", "text": "कसैले मलाई मेसिन लर्निङमा लीनियर एल्जेब्राको प्रयोगबारे सोधे। खैर, यो एकदमै आधारभूत छ। एउटा साधारण न्यूरल नेटवर्क लेयरलाई विचार गर्नुहोस्; यो मूलतः म्याट्रिक्स गुणन हो। प्रत्येक न्यूरोनको आउटपुट यसको इनपुटहरूको भारित योग हो, र यी भारहरूलाई म्याट्रिक्समा व्यवस्थित गरिन्छ। उदाहरणका लागि, एउटा लेयरमा (१०० x ५०) आयामको W भार हुन सक्छ, जसको अर्थ यसले ५०-आयामिक इनपुटलाई १००-आयामिक आउटपुटमा रूपान्तरण गर्छ। फर्वार्ड पासमा Wx + b गणना गर्नु समावेश छ, जहाँ x इनपुट भेक्टर हो र b bias भेक्टर हो। यो 'Wx' ठीक त्यहीँ हो जहाँ लीनियर एल्जेब्रा चम्किन्छ।"}
{"unnormalised": "त्यसपछि तपाईंसँग छवि प्रशोधन छ। एउटा छविलाई म्याट्रिक्स (वा रङीन छविको लागि म्याट्रिक्सको सेट) को रूपमा प्रतिनिधित्व गर्न सकिन्छ। धमिलो पार्ने, किनारा पत्ता लगाउने र घुमाउने जस्ता कार्यहरू सबै रेखीय बीजगणित अवधारणाहरूमा निर्भर हुन्छन्। उदाहरणका लागि, 3x3 कन्भोलुसन कर्नेल प्रयोग गर्दा तत्व-वार गुणन र योग समावेश हुन्छ जुन म्याट्रिक्स अपरेशनहरू प्रयोग गरेर प्रतिनिधित्व गर्न सकिन्छ। छवि पुन:आकार गर्ने वा क्रप गर्ने जस्ता साधारण कार्यहरूलाई पनि रेखीय रूपान्तरणको रूपमा हेर्न सकिन्छ। PCA जस्ता छवि सङ्कुचन प्रविधिहरूले पनि रेखीय बीजगणितको धेरै प्रयोग गर्छन्।", "normalised": "त्यसपछि तपाईंसँग छवि प्रशोधन छ। छवि रङीन छविको लागि म्याट्रिक्स वा म्याट्रिक्सहरूको सेटको रूपमा प्रतिनिधित्व गर्न सकिन्छ। धमिलो पार्ने, किनारा पत्ता लगाउने, र घुमाउने जस्ता कार्यहरू सबै रेखीय बीजगणित अवधारणाहरूमा निर्भर हुन्छन्। उदाहरणका लागि, तीन गुणा तीन कनवल्सन कर्नेल लागू गर्दा तत्व-वार गुणन र जोड समावेश हुन्छ, जसलाई म्याट्रिक्स अपरेसनहरू प्रयोग गरेर प्रतिनिधित्व गर्न सकिन्छ। छवि रिसाइज गर्ने वा क्रप गर्ने जस्ता साधारण कार्यहरूलाई पनि रेखीय रूपान्तरणको रूपमा हेर्न सकिन्छ। पी-सी-ए जस्ता छवि सङ्कुचन प्रविधिहरूले पनि रेखीय बीजगणितको धेरै प्रयोग गर्दछ।", "text": "त्यसपछि तपाईंसँग छवि प्रशोधन छ। एउटा छविलाई म्याट्रिक्स (वा रङीन छविको लागि म्याट्रिक्सको सेट) को रूपमा प्रतिनिधित्व गर्न सकिन्छ। धमिलो पार्ने, किनारा पत्ता लगाउने र घुमाउने जस्ता कार्यहरू सबै रेखीय बीजगणित अवधारणाहरूमा निर्भर हुन्छन्। उदाहरणका लागि, 3x3 कन्भोलुसन कर्नेल प्रयोग गर्दा तत्व-वार गुणन र योग समावेश हुन्छ जुन म्याट्रिक्स अपरेशनहरू प्रयोग गरेर प्रतिनिधित्व गर्न सकिन्छ। छवि पुन:आकार गर्ने वा क्रप गर्ने जस्ता साधारण कार्यहरूलाई पनि रेखीय रूपान्तरणको रूपमा हेर्न सकिन्छ। PCA जस्ता छवि सङ्कुचन प्रविधिहरूले पनि रेखीय बीजगणितको धेरै प्रयोग गर्छन्।"}
{"unnormalised": "यसबाहेक, रेखीय बीजगणितले ग्रेडियन्ट डिसेन्ट जस्ता धेरै मेसिन लर्निङमा प्रयोग हुने अप्टिमाइजेसन एल्गोरिदमहरूलाई समर्थन गर्दछ। यी एल्गोरिदमहरू मोडेलहरूलाई प्रभावकारी रूपमा तालिम दिनको लागि महत्त्वपूर्ण छन्। त्यसैले, तपाईंले जहिले पनि स्पष्ट रूपमा म्याट्रिक्सहरू लेख्नु नपर्ने भएता पनि, रेखीय बीजगणितको बलियो बुझाइले धेरै एमएल मोडेलहरूको भित्री कार्यहरू बुझ्न र तपाईंको कोड डिबग गर्न पनि मद्दत गर्नेछ। तपाईंले आइगेनभ्यालुहरू, आइगेनभेक्टरहरू, म्याट्रिक्स डिकम्पोजिसन, र भेक्टर स्पेसहरू जस्ता चीजहरू जहिले पनि भेट्नुहुनेछ।", "normalised": "यसबाहेक, लीनियर बीजगणितले ग्रेडियन्ट डिसेन्ट जस्ता धेरै अप्टिमाइजेसन एल्गोरिदमहरूलाई समर्थन गर्दछ जुन मेसिन लर्निङमा प्रयोग गरिन्छ। यी एल्गोरिदमहरू कुशलतापूर्वक मोडेलहरूलाई तालिम दिनका लागि महत्वपूर्ण छन्। त्यसैले, तपाईंले जहिले पनि स्पष्ट रूपमा म्याट्रिक्सहरू लेखिरहनु नपर्ला, तर लीनियर बीजगणितको बलियो ज्ञानले धेरै एम-एल मोडेलहरूको भित्री कार्यहरू बुझ्न र तपाईंको कोड डिबग गर्न मद्दत गर्नेछ। तपाईंले आइगेनभ्यालु, आइगेनभेक्टर, म्याट्रिक्स डिकम्पोजिसन, र भेक्टर स्पेसहरू जस्ता कुराहरू सधैं सामना गर्नुहुनेछ।", "text": "यसबाहेक, रेखीय बीजगणितले ग्रेडियन्ट डिसेन्ट जस्ता धेरै मेसिन लर्निङमा प्रयोग हुने अप्टिमाइजेसन एल्गोरिदमहरूलाई समर्थन गर्दछ। यी एल्गोरिदमहरू मोडेलहरूलाई प्रभावकारी रूपमा तालिम दिनको लागि महत्त्वपूर्ण छन्। त्यसैले, तपाईंले जहिले पनि स्पष्ट रूपमा म्याट्रिक्सहरू लेख्नु नपर्ने भएता पनि, रेखीय बीजगणितको बलियो बुझाइले धेरै एमएल मोडेलहरूको भित्री कार्यहरू बुझ्न र तपाईंको कोड डिबग गर्न पनि मद्दत गर्नेछ। तपाईंले आइगेनभ्यालुहरू, आइगेनभेक्टरहरू, म्याट्रिक्स डिकम्पोजिसन, र भेक्टर स्पेसहरू जस्ता चीजहरू जहिले पनि भेट्नुहुनेछ।"}
