{"unnormalised": "हे साथीहरू, लिनियर अलजेब्रा बारे एउटा छिटो प्रश्न छ। म एउटा परीक्षाको तयारी गर्दैछु र एउटा कुरामा अड्किएको छु। म्याट्रिक्स ट्रान्सफॉर्मेशन जस्ता कुराहरू बाहेक, वास्तविक संसारमा आइगेनभ्यालु र आइगेनभेक्टरहरू कसरी प्रयोग गर्ने? मेरो पाठ्यपुस्तकमा सैद्धान्तिक उदाहरणहरू मात्र छन्, तर मलाई जान्न मन छ कि यो कुरा कहाँ उपयोगी छ, थाहा छ नि? सोच्दै छु कि, के यो सिग्नल प्रोसेसिंगमा वा सायद AI stuff मा पनि प्रयोग हुन्छ? कुनै सरल व्याख्या वा उदाहरणहरू धेरै सहयोगी हुनेछन्!", "normalised": "हे साथीहरु, लिनियर बीजगणित बारे एउटा छिटो प्रश्न छ। म परीक्षाको तयारी गर्दैछु र एउटा कुरामा अड्किएँ। म्याट्रिक्स रूपान्तरण जस्ता कुराहरु बाहेक, वास्तविक संसारमा आइगनभ्यालु र आइगनभेक्टरहरू कसरी प्रयोग गर्ने? मेरो पाठ्यपुस्तकमा सैद्धान्तिक उदाहरणहरू मात्र छन्, तर म जान्न चाहन्छु कि यो कुरा कहाँ उपयोगी छ, थाहा छ नि? जस्तै, के यो सिग्नल प्रोसेसिङ वा ए-आई जस्ता कुराहरुमा प्रयोग हुन्छ? कुनै सरल व्याख्या वा उदाहरणहरु भए धेरै सहयोगी हुने थियो!", "text": "हे साथीहरू, लिनियर अलजेब्रा बारे एउटा छिटो प्रश्न छ। म एउटा परीक्षाको तयारी गर्दैछु र एउटा कुरामा अड्किएको छु। म्याट्रिक्स ट्रान्सफॉर्मेशन जस्ता कुराहरू बाहेक, वास्तविक संसारमा आइगेनभ्यालु र आइगेनभेक्टरहरू कसरी प्रयोग गर्ने? मेरो पाठ्यपुस्तकमा सैद्धान्तिक उदाहरणहरू मात्र छन्, तर मलाई जान्न मन छ कि यो कुरा कहाँ उपयोगी छ, थाहा छ नि? सोच्दै छु कि, के यो सिग्नल प्रोसेसिंगमा वा सायद AI stuff मा पनि प्रयोग हुन्छ? कुनै सरल व्याख्या वा उदाहरणहरू धेरै सहयोगी हुनेछन्!"}
{"unnormalised": "त्यसोभए, मलाई याद छ हाम्रा प्राध्यापक डा. वर्माले पेजर्याङ्क एल्गोरिदम, गुगलको मौलिक एल्गोरिदममा तिनीहरूको प्रयोगको बारेमा केही उल्लेख गर्नुभएको थियो। मलाई लाग्छ यो वेबको लिङ्क संरचनालाई प्रतिनिधित्व गर्ने एउटा विशाल म्याट्रिक्सको आइगनभेक्टरहरूमा आधारित थियो। सबैभन्दा ठूलो आइगनभ्यालु भएको आइगनभेक्टरले प्रत्येक पृष्ठको लागि महत्त्व स्कोर दिन्छ। एकदम राम्रो, हैन? लगभग जादु जस्तो लाग्छ, हाहा। रैखिक बीजगणितमा अरू कस्ता उपयोगी तरिकाहरू लुकेका होलान् जस्तो लाग्छ।", "normalised": "त्यसोभए, मलाई याद छ हाम्रा प्राध्यापक, डाक्टर वर्माले पेज र्‍याङ्क एल्गोरिदम, गुगलको पहिलो एल्गोरिदममा यसको प्रयोगबारे केही कुरा उल्लेख गर्नुभएको थियो। मलाई लाग्छ यो वेबको लिङ्क संरचनालाई प्रतिनिधित्व गर्ने एउटा विशाल म्याट्रिक्सको आइगेनभेक्टरमा आधारित थियो। सबैभन्दा ठूलो आइगेनभ्यालु भएको आइगेनभेक्टरले प्रत्येक पृष्ठको महत्त्व स्कोर दिन्छ। एकदमै राम्रो, होइन र? लगभग जादु जस्तो लाग्छ, हा हा। यसले तपाईंलाई रेखीय बीजगणितमा अरू कस्ता उपयोगी तरिकाहरू लुकेका होलान् भन्ने सोच्न बाध्य बनाउँछ।", "text": "त्यसोभए, मलाई याद छ हाम्रा प्राध्यापक डा. वर्माले पेजर्याङ्क एल्गोरिदम, गुगलको मौलिक एल्गोरिदममा तिनीहरूको प्रयोगको बारेमा केही उल्लेख गर्नुभएको थियो। मलाई लाग्छ यो वेबको लिङ्क संरचनालाई प्रतिनिधित्व गर्ने एउटा विशाल म्याट्रिक्सको आइगनभेक्टरहरूमा आधारित थियो। सबैभन्दा ठूलो आइगनभ्यालु भएको आइगनभेक्टरले प्रत्येक पृष्ठको लागि महत्त्व स्कोर दिन्छ। एकदम राम्रो, हैन? लगभग जादु जस्तो लाग्छ, हाहा। रैखिक बीजगणितमा अरू कस्ता उपयोगी तरिकाहरू लुकेका होलान् जस्तो लाग्छ।"}
{"unnormalised": "मैले कतै देखेको अर्को एउटा अनुप्रयोग इन्जिनियरिङ प्रणालीहरूमा स्थिरता विश्लेषणसँग सम्बन्धित थियो। जस्तै, यदि तपाईंसँग भिन्न समीकरणहरूद्वारा वर्णन गरिएको प्रणाली छ भने, तपाईंले प्रणालीको म्याट्रिक्सको आइगेनभ्यालुहरू प्रयोग गरेर प्रणाली स्थिर छ कि छैन भनेर निर्धारण गर्न सक्नुहुन्छ। यदि सबै आइगेनभ्यालुहरूको नकारात्मक वास्तविक भागहरू छन् भने, प्रणाली स्थिर हुन्छ। यदि तपाईं क्यापेसिटरहरू (C= 10μF), इन्डक्टरहरू (L = 5mH), र प्रतिरोधकहरू (R=10 Ohms) भएका विद्युतीय सर्किटहरू मोडेल गर्न चाहनुहुन्छ भने, आइगेनभ्यालुहरू पत्ता लगाउनाले सर्किटले दोलन गर्छ कि क्षय हुन्छ भनेर बुझ्न मद्दत गर्दछ।", "normalised": "मैले कतै देखेको अर्को एउटा अनुप्रयोग ईन्जिनियरिङ प्रणालीहरूमा स्थिरता विश्लेषणसँग सम्बन्धित थियो। जस्तै, यदि तपाईंसँग डिफरेन्सियल समीकरणहरूद्वारा वर्णन गरिएको प्रणाली छ भने, तपाईं प्रणालीको म्याट्रिक्सको आइगेनभ्यालुहरू प्रयोग गरेर प्रणाली स्थिर छ कि छैन भनेर निर्धारण गर्न सक्नुहुन्छ। यदि सबै आइगेनभ्यालुहरूको नकारात्मक वास्तविक भागहरू छन् भने, तब प्रणाली स्थिर हुन्छ। यदि तपाईं क्यापेसिटरहरू (C बराबर दस माइक्रोफराड), इन्डक्टरहरू (L बराबर पाँच मिलीहेनरी), र प्रतिरोधकहरू (R बराबर दस ओम) भएको विद्युतीय सर्किटहरूको मोडेल बनाउन चाहनुहुन्छ भने, आइगेनभ्यालुहरू पत्ता लगाउनाले सर्किट दोलन हुन्छ कि क्षय हुन्छ भनेर बुझ्न मद्दत गर्दछ।", "text": "मैले कतै देखेको अर्को एउटा अनुप्रयोग इन्जिनियरिङ प्रणालीहरूमा स्थिरता विश्लेषणसँग सम्बन्धित थियो। जस्तै, यदि तपाईंसँग भिन्न समीकरणहरूद्वारा वर्णन गरिएको प्रणाली छ भने, तपाईंले प्रणालीको म्याट्रिक्सको आइगेनभ्यालुहरू प्रयोग गरेर प्रणाली स्थिर छ कि छैन भनेर निर्धारण गर्न सक्नुहुन्छ। यदि सबै आइगेनभ्यालुहरूको नकारात्मक वास्तविक भागहरू छन् भने, प्रणाली स्थिर हुन्छ। यदि तपाईं क्यापेसिटरहरू (C= 10μF), इन्डक्टरहरू (L = 5mH), र प्रतिरोधकहरू (R=10 Ohms) भएका विद्युतीय सर्किटहरू मोडेल गर्न चाहनुहुन्छ भने, आइगेनभ्यालुहरू पत्ता लगाउनाले सर्किटले दोलन गर्छ कि क्षय हुन्छ भनेर बुझ्न मद्दत गर्दछ।"}
{"unnormalised": "र हो, बिल्कुल AI। Eigenvalues र eigenvectors ले Principal Component Analysis (PCA) जस्ता आयामिकता घटाउने प्रविधिहरूमा ठूलो भूमिका खेल्छन्। कल्पना गर्नुहोस् तपाईं धेरै विशेषताहरू भएको डेटासेटसँग काम गर्दै हुनुहुन्छ, जस्तै अनुहारहरूको छविहरूको डेटासेट। प्रत्येक छविमा 1000 विशेषताहरू (1000 पिक्सेलहरू) छन्, तपाईंले PCA प्रयोग गरेर \"मुख्य कम्पोनेन्टहरू\" फेला पार्न सक्नुहुन्छ, जुन मूलतः तपाईंको डेटाको covariance matrix को सबैभन्दा ठूलो eigenvalues सँग सम्बन्धित eigenvectors हुन्। तपाईं ती थोरै कम्पोनेन्टहरू प्रयोग गरेर आफ्नो डेटालाई प्रतिनिधित्व गर्न र आयामहरूलाई ½ मा घटाउन सक्नुहुन्छ। त्यसपछि मोडेलहरू निर्माण गर्न सजिलो हुन्छ (उदाहरणका लागि, छवि पहिचानमा)।", "normalised": "र हो, बिल्कुल ए-आई। आइगेनभ्यालु र आइगेनभेक्टरले प्रिन्सिपल कम्पोनेन्ट एनालिसिस (पी-सी-ए) जस्ता डाइमेन्सनालिटी रिडक्शन प्रविधिहरूमा ठूलो भूमिका खेल्छन्। कल्पना गर्नुहोस् कि तपाईं धेरै विशेषताहरू भएको डेटासेटसँग काम गर्दै हुनुहुन्छ, जस्तै अनुहारहरूको छविहरूको डेटासेट। प्रत्येक छविमा एक हजार विशेषताहरू (एक हजार पिक्सेलहरू) छन्, तपाईंले \"प्रिन्सिपल कम्पोनेन्टहरू\" पत्ता लगाउन पी-सी-ए प्रयोग गर्न सक्नुहुन्छ, जुन मूलतः तपाईंको डेटाको कोभेरियन्स म्याट्रिक्सको सबैभन्दा ठूलो आइगेनभ्यालुसँग सम्बन्धित आइगेनभेक्टरहरू हुन्। तपाईं ती केही कम्पोनेन्टहरू प्रयोग गरेर आफ्नो डेटा प्रतिनिधित्व गर्न र आयामहरूलाई आधाले घटाउन सक्नुहुन्छ। त्यसपछि मोडेलहरू बनाउन सजिलो हुन्छ (उदाहरणका लागि, छवि पहिचानमा)।", "text": "र हो, बिल्कुल AI। Eigenvalues र eigenvectors ले Principal Component Analysis (PCA) जस्ता आयामिकता घटाउने प्रविधिहरूमा ठूलो भूमिका खेल्छन्। कल्पना गर्नुहोस् तपाईं धेरै विशेषताहरू भएको डेटासेटसँग काम गर्दै हुनुहुन्छ, जस्तै अनुहारहरूको छविहरूको डेटासेट। प्रत्येक छविमा 1000 विशेषताहरू (1000 पिक्सेलहरू) छन्, तपाईंले PCA प्रयोग गरेर \"मुख्य कम्पोनेन्टहरू\" फेला पार्न सक्नुहुन्छ, जुन मूलतः तपाईंको डेटाको covariance matrix को सबैभन्दा ठूलो eigenvalues सँग सम्बन्धित eigenvectors हुन्। तपाईं ती थोरै कम्पोनेन्टहरू प्रयोग गरेर आफ्नो डेटालाई प्रतिनिधित्व गर्न र आयामहरूलाई ½ मा घटाउन सक्नुहुन्छ। त्यसपछि मोडेलहरू निर्माण गर्न सजिलो हुन्छ (उदाहरणका लागि, छवि पहिचानमा)।"}
{"unnormalised": "आशा छ यसले केही मद्दत गर्नेछ! रेखीय बीजगणित कहिलेकाहीँ अमूर्त लाग्न सक्छ, तर eigenvalues ​​र eigenvectors को धेरै अनुप्रयोगहरू छन्, यदि तपाईंले खोज्नुभयो भने। र नबिर्सनुहोस्, अभ्यास महत्वपूर्ण छ! परीक्षाको लागि शुभकामना भाइ!", "normalised": "आशा छ यसले केही मद्दत गर्छ! रेखीय बीजगणित कहिलेकाहीँ अमूर्त लाग्न सक्छ, तर eigenvalues र eigenvectors को धेरै अनुप्रयोगहरू छन्, यदि तपाईंले खोज्नुभयो भने। र नबिर्सनुहोस्, अभ्यास नै प्रमुख हो! तपाईँको परीक्षाको लागि शुभकामना ब्रो!", "text": "आशा छ यसले केही मद्दत गर्नेछ! रेखीय बीजगणित कहिलेकाहीँ अमूर्त लाग्न सक्छ, तर eigenvalues ​​र eigenvectors को धेरै अनुप्रयोगहरू छन्, यदि तपाईंले खोज्नुभयो भने। र नबिर्सनुहोस्, अभ्यास महत्वपूर्ण छ! परीक्षाको लागि शुभकामना भाइ!"}
