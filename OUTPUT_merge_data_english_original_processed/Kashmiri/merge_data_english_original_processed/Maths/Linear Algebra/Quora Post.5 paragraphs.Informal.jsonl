{"unnormalised": "ہے گیو، لِنیٖر الجبرا بارَس منٛز اَکھ ژٔٹ سوال چھُ۔ میٖہ چھُ اَکھ امتحان خاطَر تیارِی گَژھان تہٕ اَکھ چیزَس منٛز چھُ بَرنَس پھَساو۔ کیٛاز چھُ اہَموِیَت دار قدٕر تہٕ اہَموِیَت دار ویکٹر حَقیٖقی دُنیاہَس منٛز اِستِمال گَژھان، مَیٹرِکس ٹرانسفارمیشنَس نِش پورہٕ؟ میٖچِھ کتابَس منٛز چھِ صِرِف نظریاتی مِثالے، مگر میٖہ چھُ وُنُن کیاہ چھُ یہِ چیز کارآمد، زانُن؟ سوٗچنَس چھُ، کیاہ یہِ سگنل پراسیسِنگ یا شایَد اے آی چیزَن منٛز اِستِمال گَژھان؟ کُنہٕ سادٕ وضاحت یا مثالے سُہَل حَوالَس سان آسیٚن!", "normalised": "ہے گئزو، لینیئر الجبرا بارہَس منٛز اَکھ جَلد سوال۔ \nمیں ایک امتحان خٲطرٕ تیاری کران چھُس تہٕ اَکھ چیزَس منٛز پھَسِتھ۔ \nمیں کِتھ طور چھُس اصل دنیاہَس منٛز eigenvalies تہٕ eigenvectors لاگو کران، اسہِ، matrix transformations پتہٕ؟ \nمیرے textbook منٛز چھِ صرف theoretical examples، مگر میں چھُس جانن خوائش مند کہ یہ چیز کُتھ فٲئدِ مند چھُ، ژے چھُو زانان؟ \nسوچان چھُس مثال طور، کیا یہ signal processing منٛز یا شٲیَد اے-آئی چیزَس منٛز استعمال گژھان چھُ؟ \nکوٚنہ تہِ آسان تشریح یا مثال تہ مُدتگار ثابت گژھَن!", "text": "ہے گیو، لِنیٖر الجبرا بارَس منٛز اَکھ ژٔٹ سوال چھُ۔ میٖہ چھُ اَکھ امتحان خاطَر تیارِی گَژھان تہٕ اَکھ چیزَس منٛز چھُ بَرنَس پھَساو۔ کیٛاز چھُ اہَموِیَت دار قدٕر تہٕ اہَموِیَت دار ویکٹر حَقیٖقی دُنیاہَس منٛز اِستِمال گَژھان، مَیٹرِکس ٹرانسفارمیشنَس نِش پورہٕ؟ میٖچِھ کتابَس منٛز چھِ صِرِف نظریاتی مِثالے، مگر میٖہ چھُ وُنُن کیاہ چھُ یہِ چیز کارآمد، زانُن؟ سوٗچنَس چھُ، کیاہ یہِ سگنل پراسیسِنگ یا شایَد اے آی چیزَن منٛز اِستِمال گَژھان؟ کُنہٕ سادٕ وضاحت یا مثالے سُہَل حَوالَس سان آسیٚن!"}
{"unnormalised": "تَے، مےٚ چھُ یاد ساٚن پرۄفیسَر، ڈاکٹر وَرما، یِم سٲری تِمَن پؠٹھ پیج رینک الگورِتھمَس مَنٛز اِستِمال کَرنہٕ خٲطرٕ، گوگل سُنٛد اصل واتہٕ تہٕ. میہٕ چھُ لَگان زِ یِہ اوس اَکھ بَڈِس میٛٹرِکِس (matrix) کِس ایگَن ویکٹرَس (eigenvectors) پؠٹھ مبنی یُس ویبُکِس لِنک سٹرکچرُک (link structure) نمائندگی کَران اوس۔ یُس ایگَن ویکٹر سَب کھۄتہٕ بَڈِس ایگَن ویلیو (eigenvalue) سٟتؠ چھُ، یُس تِمَن ہَر صَفہٕ خٲطرٕ اَہمیَتھ سکور دِوان. واریاہ خۄش نَٲل، نَہٕ؟ زَن چھُ جادو وُن موجوٗد، ہَہَہَ. چھُ پَیدا کَران حیرٲن زِ کیٛا باقٕی خۄش تَرکیٖب چھِ لِنیَر الجبراہَس مَنٛز لُکہٕ یِوان.", "normalised": "تہ، مے٘ چھُ یاد ساٚن پروفیسر، ڈاکٹر ورما، کُنہِ کِھژتھ کران اَمہِ بارَس مَنٛز زِ تِم کَران استِمال پیج رینک ایلگورِتھمَس مَنٛز، گوگل سٕنٛز اصل واجی وُن۔ مے٘ چھُ لگان زِ یہِ اوس بُنیادٕت ایگن ویکٹرس پؠٹھ اَکھ بوٚڈ میٹریٚکس پؠٹھ یُس ظٲہِر کرَن آسہٕ ویبٕچ لِنٛک سٹرکچَر۔ یُس ایگن ویکٹر آسہٕ سارِوٕے کھۄتہٕ زیٛادٕ ایگن ویلیو، سوٗ دیُن آسہٕ تُم اَہَمِیَتھ سُکور ہر اَکھ پیج خٲطِر۔ چُھ آسانۍ، ہِیےٚ؟ تہٕ لگَن آسہٕ زَن کِھہِ کَرَماتھ چھُ، ہا ہا۔ چھُ کَران تَجَسُس زِ کیاہ باقِیِیَن کوٗل ٹرِکس چھَن رُوپٲی لِیٖنِیَر اَلجبرا مَنٛز۔", "text": "تَے، مےٚ چھُ یاد ساٚن پرۄفیسَر، ڈاکٹر وَرما، یِم سٲری تِمَن پؠٹھ پیج رینک الگورِتھمَس مَنٛز اِستِمال کَرنہٕ خٲطرٕ، گوگل سُنٛد اصل واتہٕ تہٕ. میہٕ چھُ لَگان زِ یِہ اوس اَکھ بَڈِس میٛٹرِکِس (matrix) کِس ایگَن ویکٹرَس (eigenvectors) پؠٹھ مبنی یُس ویبُکِس لِنک سٹرکچرُک (link structure) نمائندگی کَران اوس۔ یُس ایگَن ویکٹر سَب کھۄتہٕ بَڈِس ایگَن ویلیو (eigenvalue) سٟتؠ چھُ، یُس تِمَن ہَر صَفہٕ خٲطرٕ اَہمیَتھ سکور دِوان. واریاہ خۄش نَٲل، نَہٕ؟ زَن چھُ جادو وُن موجوٗد، ہَہَہَ. چھُ پَیدا کَران حیرٲن زِ کیٛا باقٕی خۄش تَرکیٖب چھِ لِنیَر الجبراہَس مَنٛز لُکہٕ یِوان."}
{"unnormalised": "بییہ اکھ اِستِمال مؠں وُچھ کُنہ جایہِ پؠٹھ، یُس چھُ انجینئرنگ نظامن منٛز اِستھکَام مُتعلِق۔ یِمہٕ، اگر چھُک یُس نِظام بَیٲن کَرنہٕ ڈِفَرنشیَل مُساواتَن سٟتؠ، تِمہٕ تُلِتھ ٲسِن وُچھِتھ نِظامُک میٹِرکسُک ذاتِی قِیمَتھ اَتھ زانُن خاطِر زِ کیا نِظام چھُ مُستحکِم یا نا۔ اگر چھِ سٲریَن ذاتِی قِیمَتھَن ہُنٛد مَنفی حَقِیقِی حِصّہ، تِمہٕ چھُ نِظام مُستحکِم۔ اگر چھُک چھِتھ چاہان اِلیکٹْرِکل سَرکِٹ موڈَل کرُن کیپیسِیٹَرَن سٟتؠ (C= 10μF)، اِنڈَکٹرَن سٟتؠ (L = 5mH)، تہٕ ریزِسٹرَن سٟتؠ (R=10 اوہمز)، ذاتِی قِیمَتھ دِریافتھ کَرنہٕ چھُک مَدَتھ کَرنہٕ اَتھ سَمَجھُن منٛز زِ کیا سَرکِٹ دۄلِتھ چھُ یا ضائِع گَژھِتھ چھُ۔", "normalised": "بییہِ اَکھ اِستِعمال یُس مےٚے کُۅنہِ جایہِ دٕچھ، اۄس اِنٛجِنییَرِنٛگ نِظامَن مٕنٛز اِستِقرَار ہُنٛد تجزیہٕ سٕتۍ مُتعلِق۔ مثال کہِ، اگر چھُکُھ یُس نِظام تفاضُلی مُساواتَن سٕتۍ تَشریح کَرنہٕ آمُت، توٚہِ نِظامٕچ میٛٹرِکسٕچ آپنٕن قیٖمَتھ اِستِمال کٔرِتھ حٲصِل کٔرتھ چھُکُھ یِہِ معلوٗم کٔرِتھ کِیٚا نِظام مُستَحکَم چھُ یٔا نٔہ۔ اگر تَمامَن آپنٕن قیٖمَتھَن ہِنٛدَن چھِ مَنفِی حَقِیٖقی حِصہٕ، توٚ نِظام چھُ مُستَحکَم۔ اگر چھُکُھ اِلیکٹرآنِک سَرکِٹَن ہٕنٛدَن ماڈَل تیار کَرنُک خواہِش کَرَن یِمَن مٕنٛز کَپیسِٹَر (C بَرابَر دَس مایکروفیراڈ) اینٛڈَکٹَر (L بَرابَر پَنٛژ میلیہِنری) تہٕ ریٖزِسٛٹَر (R بَرابَر دَس اوٗم) آسَن، توٚ آپنٕن قیٖمَتھ دَریافَتھ کَرنہٕ چھِ توٚہِ مدد کَران یِہِ سمَجھنہٕ خٲطرٕ کِیٚا سَرکِٹ دۄلِت چھُ یٔا زَوال پَذیر۔", "text": "بییہ اکھ اِستِمال مؠں وُچھ کُنہ جایہِ پؠٹھ، یُس چھُ انجینئرنگ نظامن منٛز اِستھکَام مُتعلِق۔ یِمہٕ، اگر چھُک یُس نِظام بَیٲن کَرنہٕ ڈِفَرنشیَل مُساواتَن سٟتؠ، تِمہٕ تُلِتھ ٲسِن وُچھِتھ نِظامُک میٹِرکسُک ذاتِی قِیمَتھ اَتھ زانُن خاطِر زِ کیا نِظام چھُ مُستحکِم یا نا۔ اگر چھِ سٲریَن ذاتِی قِیمَتھَن ہُنٛد مَنفی حَقِیقِی حِصّہ، تِمہٕ چھُ نِظام مُستحکِم۔ اگر چھُک چھِتھ چاہان اِلیکٹْرِکل سَرکِٹ موڈَل کرُن کیپیسِیٹَرَن سٟتؠ (C= 10μF)، اِنڈَکٹرَن سٟتؠ (L = 5mH)، تہٕ ریزِسٹرَن سٟتؠ (R=10 اوہمز)، ذاتِی قِیمَتھ دِریافتھ کَرنہٕ چھُک مَدَتھ کَرنہٕ اَتھ سَمَجھُن منٛز زِ کیا سَرکِٹ دۄلِتھ چھُ یا ضائِع گَژھِتھ چھُ۔"}
{"unnormalised": "ہاں، بالکل اے آئی۔ Eigenvalues تہٕ eigenvectors dimensionality reduction techniques منز بھاری کردار ادا کران چھِ، یِمہِ زیٛادٕ تر principal component analysis (PCA)۔ تصور کرو تم ایک ایسے ڈیٹا سیٹ پؠٹھ کٲم کران چھو یَتھ مَنٛز بھارو فیچرز چھِ، میٲنہٕ مثال خٲطرٕ چہرن ہُنٛد ڈیٹا سیٹ۔ ہر امیج مَنٛز چھُ 1000 فیچرز (1000 پکسلز)، تم PCA اِستعمال کٔرِتھ \"پرنسپل کمپوننٹ\" لَبِتھ ہَکین چھو، یِم چھِ بنیادی طور پٲنٹھ covariance matrix ہَس مَنٛز موجوٗد eigenvectors یِمَن متعلقہٕ سب کھۄتہٕ بٔڑؠ eigenvalues چھِ۔ تم یہِ چند کمپوننٹس اِستعمال کٔرِتھ پنُن ڈیٹا پیش کٔرتھ dimensions آدھ کرِتھ ہَکین چھو۔ پتہٕ چُھ ماڈل (مثال طور ایمیج شناخت مَنٛز) بناون آسان۔", "normalised": "ہَو ، یِی چھُ بالکل A-I ۔ ایگَن ویلیو تہٕ ایگَن وییکٹَرَن ہُنٛد اَہَم کردار چھُ ڈایمِنشَنیٲلیٹی رِیڈَکشن ٹیکنیٖکس مَنٛز یِتھ کیٚن زِ پِرِنسِیپَل کامپوننٹ اَنالِسِس (P-C-A) ۔ تَصَوُر کَرِو زِ تُہیہَے چھُ اَکھ ڈیٹا سیٹَس سٟتؠ کٲم کَرَن یِمَن مَنٛز چھِ بَہُت زیٛادٕ فیچَر، یِتھ کیٚن زِ چَہروَن ہٕنٛزَن تَصویٖرَن ہُنٛد ڈیٹا سیٹ ۔ ہَر تَصویٖرَس مَنٛز چھِ اَکھ ہَزار فیچَر (اَکھ ہَزار پِکسَل) ، تُہیہَے چھُو P-C-A اِستِمال کَرِتھ \"پِرِنسِیپَل کامپوننٹ\" لَبَن، یِمَن چھِ بَنیٲدی طور پٲنٛٹھ ایگَن وییکٹَر یِمَوَن چھِ تَمہِ ڈیٹا ہُنٛد کوویٖرِیئَنس میٹرِکسَس مَنٛز سَب کھۄتہٕ بوٚڈ ایگَن ویلیو ۔ تُہیہَے چھُو تِم تھۄڈ کامپوننٹ اِستِمال کَرِتھ پننہٕ ڈیٹا نُمٲیِش کَرَن تہٕ ڈایمِنشَن وُن دۄہِن تَقسیٖم کَرَن ۔ تَمہِ پتہٕ چھُ ماڈَل بَنٲوُن آسان (مثٲل طور ، اِمَیج ریکَگنیشنَس مَنٛز) ۔", "text": "ہاں، بالکل اے آئی۔ Eigenvalues تہٕ eigenvectors dimensionality reduction techniques منز بھاری کردار ادا کران چھِ، یِمہِ زیٛادٕ تر principal component analysis (PCA)۔ تصور کرو تم ایک ایسے ڈیٹا سیٹ پؠٹھ کٲم کران چھو یَتھ مَنٛز بھارو فیچرز چھِ، میٲنہٕ مثال خٲطرٕ چہرن ہُنٛد ڈیٹا سیٹ۔ ہر امیج مَنٛز چھُ 1000 فیچرز (1000 پکسلز)، تم PCA اِستعمال کٔرِتھ \"پرنسپل کمپوننٹ\" لَبِتھ ہَکین چھو، یِم چھِ بنیادی طور پٲنٹھ covariance matrix ہَس مَنٛز موجوٗد eigenvectors یِمَن متعلقہٕ سب کھۄتہٕ بٔڑؠ eigenvalues چھِ۔ تم یہِ چند کمپوننٹس اِستعمال کٔرِتھ پنُن ڈیٹا پیش کٔرتھ dimensions آدھ کرِتھ ہَکین چھو۔ پتہٕ چُھ ماڈل (مثال طور ایمیج شناخت مَنٛز) بناون آسان۔"}
{"unnormalised": "امید چھُ یُہ مدد گار ثابت گژھہ! لِنیَر الجبرا کڈھن چھُ کبھی کبھی تجریدی نظر، مگر وِزَن اینجینوَلیوَن تہٕ اینجینوَکٹرز ہنزِ اِتھاہَن ایپلی کیشنز چھِ اتھاء، اگر تُم بَس تِمَو دِکھوو۔ تہٕ یَتھ دِکھو مت، مشق چھُ ضَروری! تُمَو امِتحانَس منز مبارک باد بروو!", "normalised": "امید چھُ یُہ مدد گار ثابت گژھِ! لِنیئر الجبرا کُنہِ کُنہِ تجریدی لَگِتھ ہَے، مگر eigenvalues تہٕ eigenvectors ین ہنزِ بے تحاشہ اطلاقات چھِ یتھِی، اگر توہی یِمِس دِیو نظرِ، تہٕ نہٕ کرو فراموش، مشق چھُ ضروری! تہندِ امتحانُک خیرہوے bro!", "text": "امید چھُ یُہ مدد گار ثابت گژھہ! لِنیَر الجبرا کڈھن چھُ کبھی کبھی تجریدی نظر، مگر وِزَن اینجینوَلیوَن تہٕ اینجینوَکٹرز ہنزِ اِتھاہَن ایپلی کیشنز چھِ اتھاء، اگر تُم بَس تِمَو دِکھوو۔ تہٕ یَتھ دِکھو مت، مشق چھُ ضَروری! تُمَو امِتحانَس منز مبارک باد بروو!"}
