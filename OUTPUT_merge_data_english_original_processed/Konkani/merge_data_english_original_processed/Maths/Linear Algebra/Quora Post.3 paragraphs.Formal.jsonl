{"unnormalised": "Konkani:\n\nKonkani:\nKonkai mhaka machine learning-ant linear algebra-che upyog vixim vicharlem. Taka zai zalear, tem khub molachem. Eka buniyadi neural network layer-achech vichar kor; tem mukhya rupan matrix gunakar astam. Dor eka neuron-cho output tachi input-chi bhar-dileli zomn astam, ani hi bhar matrixant sanghatit kel'li astam. Udahornnak, eka layer-che bhark W asa zav, (100 x 50) dimaensaunche, mhunnje tem eka 50-dimensional input-ak eka 100-dimensional output-ant badalta. Pudde vochpache prokiyent Wx + b-che gannttacho aspav asta, zatant x input vector astam ani b bias vector astam. Hea 'Wx'-acher linear algebra uzvadd asta.", "normalised": "कोणें तरी म्हाका मशीन लर्निंगांत लीनियर अल्जेब्राचें उपेग कितें आसा म्हण विचारलें. बरें, तें खूब म्हत्वाचें. एक सादें न्यूरल नेटवर्क लेयर विचारा; तें म्हळ्यार मुळावें मॅट्रिक्स मल्टिप्लिकेशन. दरेक न्यूरॉनाचें आउटपुट म्हळ्यार ताच्या इनपुटांचें भारित बेरीज, आनी हें भार मॅट्रिसांनी संघटित केलां. देखीक, एका लेयराक W भार आसूं येता जाचें परिमाण शेंकडों पन्नास आसूं येता, म्हळ्यार तें पन्नास-डायमेंशनल इनपुटाक शेंकडों-डायमेंशनल आउटपुटांत बदलता. फॉरवर्ड पासांत W x अधिक b ची गणना करपाचो आस्पाव आसा, जंय x म्हळ्यार इनपुट व्हेक्टर आनी b म्हळ्यार बायस व्हेक्टर. हें 'W x' अचूकपणान जंय लीनियर अल्जेब्रा चमकता.", "text": "Konkani:\n\nKonkani:\nKonkai mhaka machine learning-ant linear algebra-che upyog vixim vicharlem. Taka zai zalear, tem khub molachem. Eka buniyadi neural network layer-achech vichar kor; tem mukhya rupan matrix gunakar astam. Dor eka neuron-cho output tachi input-chi bhar-dileli zomn astam, ani hi bhar matrixant sanghatit kel'li astam. Udahornnak, eka layer-che bhark W asa zav, (100 x 50) dimaensaunche, mhunnje tem eka 50-dimensional input-ak eka 100-dimensional output-ant badalta. Pudde vochpache prokiyent Wx + b-che gannttacho aspav asta, zatant x input vector astam ani b bias vector astam. Hea 'Wx'-acher linear algebra uzvadd asta."}
{"unnormalised": "Ani magir asa image processing. Ek image-ak matrix mhunn dakhouunk yeta (vo rangit images khatir matrices-cho ek set). Blur korop, edge detect korop, ani rotations sarkhea operations-ak linear algebra concepts-acho aadhar asta. Udharonnak, ek 3x3 convolution kernel vaprun element-wise multiplication ani summation korop, jem matrix operations vaprun dakhouunk yeta. Eka image-achem size bodolop vo te katrun kaddop sarke sadhe kamui linear transformations mhunn polleunk zata. Image compression techniques zoxe ki PCA linear algebra-cho bhari vapor kortat.", "normalised": "Ani magir tumkam chitrachi prakriya (image processing) asa. Eka chitrak rangit chitranchi matrika (matrix) vo matrikacho ek zomo mhunn dakoieeta. Dhondoll korop, kadd'ddi sodhun kaddop ani bhonvddi korop hea sogleank rekhik bijgonitachem vichar lagtat. Udharonnak, tin gunnile tin konvolyushanacho (convolution) kernel vaprun tatunt dor ek ghottkachi gunnkar ani sumaricho somavesh asta, jem matrika (matrix) karyam vaprun dakoieeta. Chitrachi size bodlop vo tem katorop hea sarkea sadhea kamankui rekhik bodlop mhunn polleunko zata. P-C-A sarkhea chitrachi dhobachi kshomota (compression techniques) chodd rekhik bijgonitacho vapor kortat.", "text": "Ani magir asa image processing. Ek image-ak matrix mhunn dakhouunk yeta (vo rangit images khatir matrices-cho ek set). Blur korop, edge detect korop, ani rotations sarkhea operations-ak linear algebra concepts-acho aadhar asta. Udharonnak, ek 3x3 convolution kernel vaprun element-wise multiplication ani summation korop, jem matrix operations vaprun dakhouunk yeta. Eka image-achem size bodolop vo te katrun kaddop sarke sadhe kamui linear transformations mhunn polleunk zata. Image compression techniques zoxe ki PCA linear algebra-cho bhari vapor kortat."}
{"unnormalised": "Ani, Linear Algebra Machine Learning-ant vaportat Gradient Descent sarkhea optimization algorithms-ank adhar dita. He algorithms models-ank porinnamkarak ritin training diunk mhotvache asat. Mhunn, tumhi sogllea vellar spãsht ritin matrices boroinastana, linear algebra-chi ek ghott samaz tumkam zaitench choddxe ML models-anchi bhitlli kria somzunk modot korteli, ani tumchea code-antli chuk sodun kaddunk-ui modot korteli. Tumkam eigenvalues, eigenvectors, matrix decomposition, ani vector spaces sarkhea vostuncho anubhav soglleach vellar ietolo.", "normalised": "पुनरुक्तीक, लीनियर अल्जेब्रा Gradient Descent भशेन मशीन लर्निंगांत वापरतात अशा खूब ऑप्टिमायझेशन अल्गोरिदम्सक आदार दिता. हे अल्गोरिदम्स मॉडेल कार्यक्षमपणान प्रशिक्षण दिवपाक म्हत्वाचे आसात. देखून, तुमी दरवेळेक स्पश्टपणान मॅट्रिक्स बरोवन काडनासतना, लीनियर अल्जेब्राचें घटमूट गिन्यान तुमकां खूब एम-एल मॉडेलच्या भितरल्या कामाकाजां समजून घेवपाक निश्चितपणान मदत करतले, आनी तुमच्या कोडिंगांतली चूक काडपाक मदत करतले. तुमकां eigenvalues, eigenvectors, matrix decomposition, आनी vector spaces सारक्यो वस्तू दरवेळेक भेटतल्यो.", "text": "Ani, Linear Algebra Machine Learning-ant vaportat Gradient Descent sarkhea optimization algorithms-ank adhar dita. He algorithms models-ank porinnamkarak ritin training diunk mhotvache asat. Mhunn, tumhi sogllea vellar spãsht ritin matrices boroinastana, linear algebra-chi ek ghott samaz tumkam zaitench choddxe ML models-anchi bhitlli kria somzunk modot korteli, ani tumchea code-antli chuk sodun kaddunk-ui modot korteli. Tumkam eigenvalues, eigenvectors, matrix decomposition, ani vector spaces sarkhea vostuncho anubhav soglleach vellar ietolo."}
