{"unnormalised": "मला रेषीय बीजगणित समजायला त्रास होत आहे. कोणीतरी मला eigenvector आणि eigenvalue सोप्या भाषेत समजावून सांगू शकेल का, विशेषत: ते वास्तविक जगात कसे वापरले जाऊ शकतात याबद्दल? माझे पाठ्यपुस्तक ते स्पष्ट करत नाही आहे.", "normalised": "मला रेषीय बीजगणित समजायला त्रास होत आहे. कोणीतरी आइगनवेक्टर आणि आइगनव्हॅल्यू साध्या भाषेत समजावू शकेल का, विशेषत: ते वास्तविक जगात कसे वापरले जाऊ शकतात याबद्दल? माझे पाठ्यपुस्तक ते स्पष्ट करत नाहीये.", "text": "मला रेषीय बीजगणित समजायला त्रास होत आहे. कोणीतरी मला eigenvector आणि eigenvalue सोप्या भाषेत समजावून सांगू शकेल का, विशेषत: ते वास्तविक जगात कसे वापरले जाऊ शकतात याबद्दल? माझे पाठ्यपुस्तक ते स्पष्ट करत नाही आहे."}
{"unnormalised": "ठीक आहे, तर कल्पना करा तुमच्याकडे एक मॅट्रिक्स आहे, त्याला 'A' म्हणूया. आता, जर तुम्ही 'A' ला एका वेक्टर 'v' ने गुणले, तर तुम्हाला दुसरा वेक्टर मिळतो. आयगेनवेक्टर हा एक विशेष वेक्टर 'v' आहे की, ज्याला 'A' ने गुणल्यावर, त्याची फक्त स्केल बदलते, दिशा नाही. ज्या प्रमाणात ते स्केल होते त्याला आयगेनव्हॅल्यू म्हणतात, ज्याला 'λ' असे दर्शवतात. म्हणून, समीकरण आहे A * v = λ * v. याचा अर्थ असा आहे: जर 'A' रूपांतरण दर्शवत असेल, तर आयगेनवेक्टर 'v' हा एक वेक्टर आहे जो रूपांतरणानंतर सरळ रेषेत राहतो, फक्त λ च्या घटकाने ताणला किंवा दाबला जातो. आयगेनव्हॅल्यू आणि आयगेनवेक्टरची गणना करण्यासाठी बहुपदी समीकरणे सोडवणे आवश्यक आहे; कॅरेक्टरिस्टिक बहुपदी det(A - λI) = 0 ची मूळे शोधल्यास तुम्हाला आयगेनव्हॅल्यू मिळतात, जिथे 'I' म्हणजे आयडेंटिटी मॅट्रिक्स. 3x3 मॅट्रिक्समध्ये, यासाठी थोडे अधिक काम करावे लागते, विशेषत: जेव्हा आयगेनव्हॅल्यू कॉम्प्लेक्स (जटिल) असतात. तुम्हाला इयत्ता 11 वीच्या गणितातील कॉम्प्लेक्स नंबरचे (जटिल संख्यांचे) नियम आठवावे लागू शकतात!", "normalised": "ठीक आहे, तर कल्पना करा तुमच्याकडे एक मॅट्रिक्स आहे, त्याला आपण 'A' म्हणूया. आता, जर तुम्ही 'A' ला एका वेक्टर 'v' ने गुणले, तर तुम्हाला दुसरा वेक्टर मिळतो. आयगेनवेक्टर हा एक खास वेक्टर 'v' असतो, ज्याला 'A' ने गुणल्यावर तो फक्त आकार बदलतो, दिशा नाही. ज्या प्रमाणात तो आकार बदलतो त्याला आयगेनव्हॅल्यू म्हणतात, ज्याला 'लॅम्डा' असे दर्शवतात. तर, समीकरण आहे A गुणिले v बरोबर लॅम्डा गुणिले v. याचा अर्थ असा आहे: जर 'A' परिवर्तनाचे प्रतिनिधित्व करत असेल, तर आयगेनवेक्टर 'v' हा एक वेक्टर आहे जो परिवर्तनानंतरही सरळ रेषेत राहतो, तो फक्त लॅम्डाच्या घटकाने ताणला किंवा दाबला जातो. आयगेनव्हॅल्यू आणि आयगेनवेक्टरची गणना करण्यासाठी बहुपदी समीकरणे सोडवणे आवश्यक आहे; A वजा लॅम्डा I च्या निर्धारकाचे वैशिष्ट्यपूर्ण बहुपदीचे मूळ शून्य काढल्यास तुम्हाला आयगेनव्हॅल्यू मिळतात, जिथे 'I' हा ओळख मॅट्रिक्स आहे. तीन बाय तीन मॅट्रिक्समध्ये, हे थोडे अधिक काम आहे, विशेषत: जेव्हा आयगेनव्हॅल्यू कॉम्प्लेक्स (गुंतागुंतीचे) असतात. तुम्हाला अकरावीच्या गणितातील कॉम्प्लेक्स नंबरचे (गुंतागुंतीच्या संख्यांचे) नियम आठवावे लागतील!", "text": "ठीक आहे, तर कल्पना करा तुमच्याकडे एक मॅट्रिक्स आहे, त्याला 'A' म्हणूया. आता, जर तुम्ही 'A' ला एका वेक्टर 'v' ने गुणले, तर तुम्हाला दुसरा वेक्टर मिळतो. आयगेनवेक्टर हा एक विशेष वेक्टर 'v' आहे की, ज्याला 'A' ने गुणल्यावर, त्याची फक्त स्केल बदलते, दिशा नाही. ज्या प्रमाणात ते स्केल होते त्याला आयगेनव्हॅल्यू म्हणतात, ज्याला 'λ' असे दर्शवतात. म्हणून, समीकरण आहे A * v = λ * v. याचा अर्थ असा आहे: जर 'A' रूपांतरण दर्शवत असेल, तर आयगेनवेक्टर 'v' हा एक वेक्टर आहे जो रूपांतरणानंतर सरळ रेषेत राहतो, फक्त λ च्या घटकाने ताणला किंवा दाबला जातो. आयगेनव्हॅल्यू आणि आयगेनवेक्टरची गणना करण्यासाठी बहुपदी समीकरणे सोडवणे आवश्यक आहे; कॅरेक्टरिस्टिक बहुपदी det(A - λI) = 0 ची मूळे शोधल्यास तुम्हाला आयगेनव्हॅल्यू मिळतात, जिथे 'I' म्हणजे आयडेंटिटी मॅट्रिक्स. 3x3 मॅट्रिक्समध्ये, यासाठी थोडे अधिक काम करावे लागते, विशेषत: जेव्हा आयगेनव्हॅल्यू कॉम्प्लेक्स (जटिल) असतात. तुम्हाला इयत्ता 11 वीच्या गणितातील कॉम्प्लेक्स नंबरचे (जटिल संख्यांचे) नियम आठवावे लागू शकतात!"}
{"unnormalised": "तर, हे कुठे वापरले जातात? याचा एक महत्त्वाचा उपयोग Google च्या PageRank अल्गोरिदममध्ये आहे. इंटरनेटला एक प्रचंड मोठे नेटवर्क म्हणून दर्शवता येते, ज्यामध्ये वेब पेजेस नोड्स (nodes) म्हणून आणि लिंक्स (links) एजेस (edges) म्हणून असतात. PageRank लिंक मॅट्रिक्सच्या (link matrix) सर्वात मोठ्या आइगेनव्हॅल्यूशी (eigenvalue) संबंधित आइगेनव्हेक्टरचा (eigenvector) वापर करून प्रत्येक पेजचे सापेक्ष महत्त्व ठरवते. आणखी एक उपयोग इमेज कॉम्प्रेशन तंत्रात (image compression techniques) आहे, जसे की प्रिंसिपल कंपोनंट एनालिसिस (PCA). PCA इमेजचे मुख्य घटक ओळखण्यासाठी आइगेनव्हेक्टर्सचा वापर करते, ज्यामुळे फारशी माहिती न गमावता डेटा आकार कमी करता येतो. उदाहरणार्थ, तुमच्याकडे 1024x768 पिक्सेलची इमेज आहे, तुम्ही PCA वापरू शकता आणि इमेजची बहुतेक माहिती दर्शवणारे फक्त पहिले 100 आइगेनव्हेक्टर ठेवू शकता. भौतिकशास्त्रात, ते एखाद्या प्रणालीच्या (system) कंपनाच्या सामान्य पद्धती शोधण्यासाठी वापरले जातात, मग ते रेणू असोत किंवा पूल!", "normalised": "तर, यांचा वापर कुठे होतो? याचे एक महत्त्वाचे उपयोजन गुगलच्या पेज रँक अल्गोरिदममध्ये आहे. इंटरनेटला एक प्रचंड मोठे नेटवर्क म्हणून दर्शवता येते, ज्यात वेब पेजेस नोड्स (nodes) आणि लिंक्स (links) एज (edges) म्हणून असतात. पेज रँक, लिंक मॅट्रिक्सच्या (link matrix) सर्वात मोठ्या आयगेनव्हॅल्यूशी (eigenvalue) संबंधित आयगेनव्हेक्टरचा (eigenvector) वापर करून प्रत्येक पेजचे सापेक्ष महत्त्व निर्धारित करते. आणखी एक उपयोजन पी. सी. ए. (P-C-A) सारख्या इमेज कॉम्प्रेशन (image compression) तंत्रात आहे. पी. सी. ए. इमेजमधील (image) मुख्य घटक ओळखण्यासाठी आयगेनव्हेक्टर्सचा वापर करते, ज्यामुळे फार माहिती न गमावता डेटा आकार कमी करता येतो. समजा तुमच्याकडे एक हजार चोवीस बाय सातशे अडुसष्ट पिक्सेलची इमेज (image) आहे, तर तुम्ही पी. सी. ए. वापरू शकता आणि बहुतेक इमेज माहिती दर्शवणारे फक्त शंभर सर्वोत्तम आयगेनव्हेक्टर्स (eigenvectors) ठेवू शकता. भौतिकशास्त्रात, त्यांचा उपयोग प्रणालीच्या कंपनाच्या सामान्य पद्धती शोधण्यासाठी केला जातो, मग ते रेणू असोत किंवा पूल!", "text": "तर, हे कुठे वापरले जातात? याचे एक महत्त्वाचे उदाहरण म्हणजे गुगलच्या PageRank अल्गोरिदममध्ये. इंटरनेटला एक मोठे नेटवर्क म्हणून दर्शवता येते, ज्यामध्ये वेब पेजेस नोड्स (nodes) आणि लिंक्स (links) हे edges (एजेस) आहेत. PageRank लिंक मॅट्रिक्सच्या (link matrix) सर्वात मोठ्या eigenvalue शी संबंधित eigenvector चा वापर करून प्रत्येक पेजचे सापेक्ष महत्त्व निर्धारित करते. दुसरे उदाहरण म्हणजे इमेज कॉम्प्रेशन (image compression) तंत्र जसे की (PCA). PCA इमेजचे मुख्य घटक ओळखण्यासाठी eigenvectors चा वापर करते, ज्यामुळे माहिती फारशी न गमावता डेटाचा आकार कमी करता येतो. उदाहरणार्थ, तुमच्याकडे 1024x768 पिक्सेलची इमेज आहे, तुम्ही PCA वापरू शकता आणि इमेजची बहुतेक माहिती दर्शवणारे फक्त टॉप 100 eigenvectors ठेवू शकता. भौतिकशास्त्रात, त्यांचा उपयोग एखाद्या प्रणालीच्या व्हायब्रेशनचे (vibration) सामान्य मोड शोधण्यासाठी केला जातो, मग ते रेणू असोत किंवा पूल!"}
{"unnormalised": "Eigenvalues आणि eigenvectors मोठ्या गुंतागुंतीच्या प्रणाली सोप्या बनवण्यासाठी मदत करतात. हे \"अचल\" दिशा आणि स्केलिंग घटक शोधून, आपण हे समजू शकतो की रेषीय परिवर्तन (linear transformation) एखाद्या जागेवर (space) कसे कार्य करते आणि या ज्ञानाचा उपयोग विविध क्षेत्रांमधील समस्या सोडवण्यासाठी करू शकतो. अगदी रेषीय अवकल समीकरण प्रणाली (system of linear differential equations) सोडवताना देखील (उदाहरणार्थ, dx/dt = Ax), मॅट्रिक्स 'A' चे eigenvalues λ1 आणि λ2 शोधणे हे एक महत्त्वाचे पहिले पाऊल आहे. काही उदाहरणे शोधा आणि ती सोडवण्याचा प्रयत्न करा; सरावाने खूप मदत होते!", "normalised": "मुळात, आयगेनव्हॅल्यूज (eigenvalues) आणि आयगेनव्हेक्टर्स (eigenvectors) जटिल प्रणाली सोप्या बनविण्यात मदत करतात. हे \"अचल\" दिशा आणि स्केलिंग घटक ओळखून, आपण एक रेखीय परिवर्तन (linear transformation) एखाद्या जागेवर (space) कसे कार्य करते हे समजू शकतो आणि या ज्ञानाचा उपयोग विविध क्षेत्रांतील समस्या सोडवण्यासाठी करू शकतो. अगदी रेषीय अवकल समीकरणांची प्रणाली (system of linear differential equations) सोडवताना (उदा. d x भागिले d t बरोबर A x), मॅट्रिक्स 'A' चे आयगेनव्हॅल्यूज लॅम्डा वन (lambda one) आणि लॅम्डा टू (lambda two) शोधणे हे एक महत्त्वाचे पहिले पाऊल आहे. काही उदाहरणे शोधा आणि ती सोडवण्याचा प्रयत्न करा; सरावाने खूप मदत होते!", "text": "Eigenvalues आणि eigenvectors मोठ्या गुंतागुंतीच्या प्रणाली सोप्या बनवण्यासाठी मदत करतात. हे \"अचल\" दिशा आणि स्केलिंग घटक शोधून, आपण हे समजू शकतो की रेषीय परिवर्तन (linear transformation) एखाद्या जागेवर (space) कसे कार्य करते आणि या ज्ञानाचा उपयोग विविध क्षेत्रांमधील समस्या सोडवण्यासाठी करू शकतो. अगदी रेषीय अवकल समीकरण प्रणाली (system of linear differential equations) सोडवताना देखील (उदाहरणार्थ, dx/dt = Ax), मॅट्रिक्स 'A' चे eigenvalues λ1 आणि λ2 शोधणे हे एक महत्त्वाचे पहिले पाऊल आहे. काही उदाहरणे शोधा आणि ती सोडवण्याचा प्रयत्न करा; सरावाने खूप मदत होते!"}
