{"unnormalised": "ᱢᱟᱲᱟᱝ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱠᱟᱹᱢᱤ ᱮᱦᱚᱵ ᱢᱟᱲᱟᱝ ᱱᱚᱣᱟ ᱵᱟᱰᱟᱭ ᱫᱚᱨᱠᱟᱨ ᱠᱟᱱᱟ ᱡᱮ ᱤᱧ ᱫᱚ ᱢᱤᱫᱴᱟᱝ ᱢᱟᱨᱟᱝ ᱯᱟᱹᱨᱥᱤ ᱢᱳᱰᱮᱞ ᱠᱟᱹᱱᱟᱹᱧ, ᱥᱟᱱᱛᱟᱲᱤ ᱯᱟᱹᱨᱥᱤ ᱨᱮ ᱯᱩᱨᱟᱹᱣ ᱟᱹᱭᱫᱟᱹᱨᱤ ᱵᱟᱹᱱᱩᱜ ᱛᱤᱧᱟ᱾ ᱤᱧ ᱫᱚ ᱤᱝᱞᱤᱥ ᱟᱹᱲᱟᱹ ᱨᱮᱭᱟᱜ ᱢᱮᱱᱮᱫᱽ ᱵᱩᱡᱷᱟᱹᱣ ᱠᱟᱛᱮ ᱥᱩᱨᱼᱥᱩᱯᱩᱨ ᱛᱚᱨᱡᱚᱢᱟ ᱮᱢ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ, ᱢᱮᱱᱠᱷᱟᱱ ᱱᱚᱣᱟ ᱑᱐᱐% ᱥᱟᱹᱦᱤ ᱜᱮᱭᱟ ᱚᱱᱟ ᱫᱚ ᱵᱟᱹᱧ ᱞᱟᱹᱭ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ᱾\n\nᱤᱧ ᱱᱤᱛᱚᱜ ᱛᱚᱨᱡᱚᱢᱟ ᱮᱛᱚᱦᱚᱵ ᱮᱫᱟ᱾", "normalised": "ᱚᱱᱟ ᱥᱟᱶᱛᱮ, ᱵᱟᱰᱟᱭ ᱧᱟᱢ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱪᱮᱫ ᱞᱮᱠᱟᱛᱮ ᱟᱢᱟᱜ ᱯᱟᱱᱛᱮ ᱠᱟᱹᱢᱤᱦᱚᱨᱟ ᱵᱮᱥ ᱛᱮ ᱦᱩᱭᱩᱜᱼᱟ ᱾\n```", "text": "ᱢᱟᱲᱟᱝ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱠᱟᱹᱢᱤ ᱮᱦᱚᱵ ᱢᱟᱲᱟᱝ ᱱᱚᱣᱟ ᱵᱟᱰᱟᱭ ᱫᱚᱨᱠᱟᱨ ᱠᱟᱱᱟ ᱡᱮ ᱤᱧ ᱫᱚ ᱢᱤᱫᱴᱟᱝ ᱢᱟᱨᱟᱝ ᱯᱟᱹᱨᱥᱤ ᱢᱳᱰᱮᱞ ᱠᱟᱹᱱᱟᱹᱧ, ᱥᱟᱱᱛᱟᱲᱤ ᱯᱟᱹᱨᱥᱤ ᱨᱮ ᱯᱩᱨᱟᱹᱣ ᱟᱹᱭᱫᱟᱹᱨᱤ ᱵᱟᱹᱱᱩᱜ ᱛᱤᱧᱟ᱾ ᱤᱧ ᱫᱚ ᱤᱝᱞᱤᱥ ᱟᱹᱲᱟᱹ ᱨᱮᱭᱟᱜ ᱢᱮᱱᱮᱫᱽ ᱵᱩᱡᱷᱟᱹᱣ ᱠᱟᱛᱮ ᱥᱩᱨᱼᱥᱩᱯᱩᱨ ᱛᱚᱨᱡᱚᱢᱟ ᱮᱢ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ, ᱢᱮᱱᱠᱷᱟᱱ ᱱᱚᱣᱟ ᱑᱐᱐% ᱥᱟᱹᱦᱤ ᱜᱮᱭᱟ ᱚᱱᱟ ᱫᱚ ᱵᱟᱹᱧ ᱞᱟᱹᱭ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ᱾\n\nᱤᱧ ᱱᱤᱛᱚᱜ ᱛᱚᱨᱡᱚᱢᱟ ᱮᱛᱚᱦᱚᱵ ᱮᱫᱟ᱾"}
{"unnormalised": "", "normalised": "os ᱵᱷᱤᱛᱨᱤ ᱥᱮᱞᱮᱫ ᱢᱮ", "text": "os ᱵᱷᱤᱛᱨᱤ ᱥᱮᱞᱮᱫ ᱢᱮ"}
{"unnormalised": "", "normalised": "ᱨᱮ ᱯᱟᱱᱛᱮ ᱧᱟᱢ ᱢᱮ᱾", "text": "ᱨᱮ ᱯᱟᱱᱛᱮ ᱧᱟᱢ ᱢᱮ᱾"}
{"unnormalised": "", "normalised": "num2words ᱠᱷᱚᱱ ᱾", "text": "num2words ᱠᱷᱚᱱ ᱾"}
{"unnormalised": "", "normalised": "ᱰᱤᱯᱷᱟᱹᱭᱤᱱ ᱠᱚᱱᱵᱷᱚᱨᱴ_ᱱᱚᱢᱵᱚᱨ_ᱴᱩ_ᱣᱟᱨᱰᱥ(ᱱᱚᱢᱵᱚᱨ_ᱮᱥᱴᱤᱟᱨ):", "text": "ᱰᱤᱯᱷᱟᱹᱭᱤᱱ ᱠᱚᱱᱵᱷᱚᱨᱴ_ᱱᱚᱢᱵᱚᱨ_ᱴᱩ_ᱣᱟᱨᱰᱥ(ᱱᱚᱢᱵᱚᱨ_ᱮᱥᱴᱤᱟᱨ):"}
{"unnormalised": "", "normalised": "ᱠᱩᱨᱩᱢᱩᱴᱩ ᱢᱮ:", "text": "ᱠᱩᱨᱩᱢᱩᱴᱩ ᱢᱮ:"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ 'ᱹ' ᱫᱚ ᱱᱚᱢᱵᱚᱨ_ᱥᱴᱨᱤᱝ ᱨᱮ ᱢᱮᱱᱟᱜᱼᱟ:", "text": "ᱡᱩᱫᱤ '.' ᱫᱚ ᱱᱚᱢᱵᱚᱨ_ᱮᱥᱴᱨᱮᱝ ᱵᱷᱤᱛᱨᱤ ᱨᱮ ᱢᱮᱱᱟᱜᱼᱟ ᱾"}
{"unnormalised": "", "normalised": "integer_part, decimal_part = number_str.split('.')", "text": "integer_part, decimal_part = number_str.split('.')"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱯᱩᱨᱟᱹ ᱦᱟᱹᱴᱤᱧ ᱛᱟᱦᱮᱸᱱᱟ:", "text": "ᱡᱩᱫᱤ ᱯᱩᱨᱱᱚ ᱦᱟᱹᱴᱤᱧ ᱛᱟᱦᱮᱱᱟ ᱵᱟᱝᱠᱷᱟᱱ:"}
{"unnormalised": "", "normalised": "integer_words = num2words(int(integer_part))", "text": "integer_words = num2words(int(integer_part))"}
{"unnormalised": "", "normalised": "ᱵᱟᱝᱠᱷᱟᱱ:", "text": "ᱵᱟᱝᱠᱷᱟᱱ:"}
{"unnormalised": "", "normalised": "integer_words = ''", "text": "ᱮᱞ ᱟᱹᱲᱟᱹ ᱠᱚ = ''"}
{"unnormalised": "", "normalised": "decimal_words = 'ᱯᱚᱭᱮᱱᱴ ' + ' '.join(num2words(int(d)) ᱞᱟᱹᱜᱤᱫ ᱛᱮ ᱡᱚᱛᱚ ᱰᱮᱥᱤᱢᱟᱞ ᱯᱟᱴ ᱨᱮᱱᱟᱜ)", "text": "decimal_words = 'ᱯᱚᱭᱮᱱᱴ ' + ' '.join(num2words(int(d)) ᱫᱷᱟᱹᱵᱤᱡ ᱫᱚ ᱰᱮᱥᱤᱢᱟᱞ ᱯᱟᱴ ᱠᱟᱱᱟ)"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱮᱞ ᱟᱹᱲᱟᱹ ᱠᱚ ᱛᱟᱦᱮᱸ ᱠᱚᱜᱼᱟ ᱾", "text": "ᱡᱩᱫᱤ ᱤᱱᱴᱤᱡᱟᱨ ᱟᱹᱲᱟᱹ ᱠᱚ ᱛᱟᱦᱮᱸᱱᱟ ᱾"}
{"unnormalised": "", "normalised": "ᱨᱩᱣᱟᱹᱲ ᱢᱮ {ᱞᱮᱠᱷᱟᱱᱟᱜ ᱟᱹᱲᱟᱹ ᱠᱚ} {ᱫᱟᱥᱟᱢᱤᱠ ᱟᱹᱲᱟᱹ ᱠᱚ}", "text": "ᱨᱩᱣᱟᱹᱲ ᱢᱮ `{integer_words} {decimal_words}`"}
{"unnormalised": "", "normalised": "ᱵᱟᱝᱠᱷᱟᱱ:", "text": "ᱵᱟᱝᱠᱷᱟᱱ:"}
{"unnormalised": "", "normalised": "ᱨᱩᱣᱟᱹᱲ ᱢᱮ ᱫᱚᱥᱚᱢᱤᱠ ᱟᱹᱲᱟᱹᱠᱚ", "text": "ᱮᱢ ᱨᱩᱣᱟᱹᱲ ᱢᱮ ᱫᱚᱥᱚᱢᱤᱠ ᱟᱹᱲᱟᱹ ᱠᱚ"}
{"unnormalised": "", "normalised": "ᱵᱟᱝᱠᱷᱟᱱ ᱫᱚᱺ", "text": "ᱵᱟᱝᱠᱷᱟᱱ:"}
{"unnormalised": "", "normalised": "ᱨᱩᱣᱟᱹᱲ ᱢᱮ ᱱᱚᱢᱵᱚᱨᱥ ᱴᱩ ᱣᱚᱨᱰᱥ (ᱤᱱᱴ (ᱱᱚᱢᱵᱚᱨ_ᱮᱥᱴᱨᱤᱝ))", "text": "ᱮᱞᱮᱠᱟᱱ ᱞᱮᱠᱷᱟ (number_str) ᱨᱮᱭᱟᱜ ᱯᱩᱨᱟᱹ ᱮᱞᱮᱠᱟ ᱵᱮᱱᱟᱣ ᱠᱟᱛᱮ ᱚᱱᱟ ᱫᱚ ᱟᱹᱲᱟᱹ ᱛᱮ ᱚᱞ ᱢᱮ ᱾"}
{"unnormalised": "", "normalised": "ᱵᱷᱮᱜᱟᱨ ᱜᱮ ᱢᱮᱱ ᱠᱷᱟᱹᱛᱤᱨ:", "text": "ᱢᱟᱱᱟ ᱵᱟᱛᱤᱞ ᱞᱮᱠᱟᱛᱮ ValueError:"}
{"unnormalised": "", "normalised": "ᱨᱩᱣᱟᱹᱲ ᱢᱮ ᱞᱮᱠᱷᱟ_ᱚᱞ(# ᱨᱩᱣᱟᱹᱲ ᱢᱮ ᱮᱛᱚᱦᱚᱵ ᱡᱩᱫᱤ ᱵᱚᱫᱚᱞ ᱵᱟᱝ ᱥᱟᱹᱛ ᱞᱮᱱᱠᱷᱟᱱ)", "text": "ᱞᱮᱠᱷᱟ ᱚᱞ ᱨᱩᱣᱟᱹᱲ ᱢᱮ  # ᱮᱦᱚᱵ ᱞᱮᱠᱟᱱ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ ᱡᱩᱫᱤ ᱵᱚᱫᱚᱞ ᱵᱟᱝ ᱥᱟᱹᱛᱚᱜᱼᱟ"}
{"unnormalised": "", "normalised": "ᱛᱚ ᱚᱞ ᱥᱟᱢᱴᱟᱣ (normalize) ᱢᱮᱱᱛᱮᱫ:", "text": "ᱛᱚ ᱚᱞ ᱥᱟᱢᱴᱟᱣ (normalize) ᱢᱮᱱᱛᱮᱫ:"}
{"unnormalised": "", "normalised": "# ᱨᱩᱞ ᱑: ᱪᱤᱱᱦᱟᱹᱠᱩ → ᱨᱚᱲ ᱨᱩᱯ", "text": "# ᱱᱤᱭᱚᱢ ᱑: ᱪᱤᱱᱦᱟᱹ ᱠᱚ → ᱨᱚᱲ ᱨᱩᱯ"}
{"unnormalised": "", "normalised": "# ᱴᱤᱠᱟᱹ: ᱪᱤᱱᱦᱟᱹᱣ ᱵᱚᱫᱚᱞ ᱞᱟᱹᱜᱤᱫ ᱛᱮ ᱫᱟᱲᱮ ᱢᱮᱱᱟᱜᱼᱟ ᱪᱮᱫᱟᱜ ᱡᱮ ᱠᱚᱱᱚ ᱥᱚᱢᱚᱥᱭᱟ ᱵᱟᱧᱪᱟᱣ ᱞᱟᱹᱜᱤᱫ '$' ᱫᱚ '$20B' ᱠᱷᱚᱱ ᱢᱟᱲᱟᱝ ᱵᱚᱫᱚᱞ ᱛᱟᱦᱮᱱᱟ᱾", "text": "ᱱᱚᱴ: ᱪᱤᱱᱦᱟᱹ ᱵᱚᱫᱚᱞ ᱞᱟᱹᱜᱤᱫ ᱛᱮ ᱚᱨᱰᱟᱨ ᱢᱟᱱᱟᱣ ᱫᱚᱨᱠᱟᱨ, ᱡᱮᱢᱚᱱ '$' ᱫᱚ '$20B' ᱵᱚᱫᱚᱞ ᱞᱟᱦᱟ ᱨᱮ ᱦᱟᱛᱟᱣ ᱠᱟᱛᱮ ᱵᱟᱹᱲᱤᱡ ᱵᱩᱡᱷᱟᱹᱣ ᱵᱟᱝ ᱦᱩᱭᱩᱜ ᱢᱟ᱾"}
{"unnormalised": "", "normalised": "# ᱢᱤᱫ ᱠᱷᱚᱱ ᱵᱟᱹᱲᱛᱤ ᱟᱠᱷᱚᱨ ᱪᱤᱱᱦᱟᱹ ᱟᱨ ᱚᱱᱟ ᱠᱚ ᱡᱟᱦᱟᱸ ᱮᱞᱠᱷᱟ ᱥᱟᱶ ᱠᱟᱹᱢᱤ ᱨᱮ ᱞᱟᱜᱟᱜᱼᱟ, ᱚᱱᱟ ᱠᱚ ᱢᱟᱲᱟᱝ ᱫᱚᱦᱚᱭ ᱢᱮ᱾", "text": "ᱞᱮᱠᱷᱟ ᱥᱟᱶ ᱠᱟᱹᱢᱤ ᱟᱱᱟᱜ ᱟᱨ ᱟᱹᱰᱤ ᱜᱟᱱ ᱪᱤᱱᱦᱟᱹ ᱢᱮᱥᱟ ᱟᱠᱟᱱ ᱠᱚᱫᱚ ᱢᱟᱬᱟᱝ ᱫᱚᱦᱚ ᱢᱮ᱾"}
{"unnormalised": "", "normalised": "# ᱢᱮᱥᱟ ᱠᱟᱹᱣᱰᱤ + ᱮᱞ + ᱛᱚᱯᱟᱜ (ᱱᱤᱭᱚᱢ ᱕) - ᱵᱷᱮᱜᱟᱨ ᱪᱤᱱᱦᱟᱹ ᱵᱟᱝᱠᱷᱟᱱ ᱮᱞ ᱨᱮᱭᱟᱜ ᱠᱟᱱᱩᱱ ᱢᱟᱬᱟᱝ ᱠᱷᱚᱱ ᱦᱤᱡᱩᱜ ᱫᱚᱨᱠᱟᱨ", "text": "# ᱮᱠᱟᱛ ᱠᱟᱹᱣᱰᱤ + ᱞᱮᱠᱷᱟ + ᱛᱚᱜᱮ (ᱱᱤᱭᱚᱢ ᱕) - ᱵᱷᱮᱜᱟᱨ ᱵᱷᱮᱜᱟᱨ ᱪᱤᱱᱦᱟᱹ ᱥᱮ ᱞᱮᱠᱷᱟ ᱱᱤᱭᱚᱢ ᱠᱷᱚᱱ ᱞᱟᱦᱟ ᱨᱮ ᱦᱤᱡᱩᱜ ᱢᱟ"}
{"unnormalised": "", "normalised": "ᱫᱚᱦᱚ ᱞᱟᱹᱜᱤᱫ ᱴᱟᱠᱟ ᱮᱞᱠᱷᱟ ᱛᱚᱝᱜᱮ ᱵᱚᱫᱚᱞ ᱢᱮ (ᱢᱮᱪ) :", "text": "def replace_currency_number_suffix(match):"}
{"unnormalised": "", "normalised": "currency_symbol = match.group(1)", "text": "ᱴᱟᱠᱟ ᱪᱤᱱᱦᱟᱹ = ᱢᱮᱪ.ᱜᱽᱨᱩᱯ(᱑)"}
{"unnormalised": "", "normalised": "number_val = match.group(2)", "text": "ᱮᱞᱮᱠᱟᱱ_ᱢᱟᱱ = ᱡᱚᱯᱚᱲᱟᱣ.ᱜᱩᱴ(᱒)"}
{"unnormalised": "", "normalised": "suffix = match.group(3)", "text": "suffix = match.group(3)"}
{"unnormalised": "", "normalised": "ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱚᱞ ᱢᱮ ᱾ ᱥᱩᱢᱩᱝ ᱛᱚᱨᱡᱚᱢᱟ ᱚᱞ ᱨᱩᱣᱟᱹᱲ ᱢᱮ, ᱢᱩᱲᱩᱛ ᱜᱟᱨᱮᱫ ᱟᱨ ᱴᱷᱟᱶ ᱫᱚᱦᱚᱭ ᱢᱮ ᱾", "text": ""}
{"unnormalised": "", "normalised": "currency_map = {", "text": "ᱤᱣᱨᱳ: \"ᱤᱣᱨᱳ\",\n    \"USD\": \"ᱟᱢᱮᱨᱤᱠᱟᱱ ᱰᱚᱞᱟᱨ\",\n    \"GBP\": \"ᱵᱨᱤᱴᱤᱥ ᱯᱟᱣᱩᱸᱰ\",\n    \"JPY\": \"ᱡᱟᱯᱟᱱᱤᱡᱽ ᱤᱭᱮᱱ\"\n}"}
{"unnormalised": "", "normalised": "'$': 'ᱰᱚᱞᱟᱨ', '₹': 'ᱴᱟᱠᱟ', '€': 'ᱤᱣᱨᱳ', '£': 'ᱯᱟᱣᱩᱱᱰ', '¥': 'ᱭᱮᱱ'", "text": "'$': 'ᱰᱚᱞᱟᱨ', '₹': 'ᱴᱟᱠᱟ', '€': 'ᱤᱭᱩᱨᱳ', '£': 'ᱯᱟᱣᱩᱱᱰ', '¥': 'ᱭᱮᱱ'"}
{"unnormalised": "", "normalised": "}", "text": "}"}
{"unnormalised": "", "normalised": "ᱴᱟᱠᱟ_ᱟᱹᱲᱟᱹ = ᱴᱟᱠᱟ_ᱢᱮᱯᱹᱜᱮᱴ(ᱴᱟᱠᱟ_ᱪᱤᱱᱦᱟᱹ, ᱴᱟᱠᱟ_ᱪᱤᱱᱦᱟᱹ)  # ᱨᱩᱣᱟᱹᱲ ᱡᱩᱫᱤ ᱵᱟᱹᱱᱩᱜᱼᱟ ᱢᱮᱯᱨᱮ", "text": "currency_word = currency_map.get(currency_symbol, currency_symbol) # ᱡᱩᱫᱤ ᱢᱮᱯ ᱨᱮ ᱵᱟᱹᱱᱩᱜᱼᱟ ᱮᱱᱠᱷᱟᱱ ᱱᱚᱣᱟ ᱵᱮᱵᱷᱟᱨᱚᱜᱼᱟ ᱾"}
{"unnormalised": "", "normalised": "number_words = convert_number_to_words(number_val)", "text": "number_words = number_val ᱞᱮᱠᱷᱟ ᱟᱹᱲᱟᱹ ᱨᱩᱣᱟᱹᱲ ᱢᱮ"}
{"unnormalised": "", "normalised": "suffix_map = {", "text": "suffix_map = {"}
{"unnormalised": "", "normalised": "'K': 'ᱦᱟᱡᱟᱨ', 'M': 'ᱢᱤᱞᱤᱭᱚᱱ', 'B': 'ᱵᱤᱞᱤᱭᱚᱱ', 'T': 'ᱴᱨᱤᱞᱤᱭᱚᱱ'", "text": "'K': 'ᱥᱟᱥᱟᱭ', 'M': 'ᱢᱤᱞᱤᱭᱚᱱ', 'B': 'ᱵᱤᱞᱤᱭᱚᱱ', 'T': 'ᱴᱨᱤᱞᱤᱭᱚᱱ'"}
{"unnormalised": "", "normalised": "}", "text": "}"}
{"unnormalised": "", "normalised": "suffix_word = suffix_map.get(suffix.upper(), suffix) # ᱮᱴᱟᱜ ᱧᱩᱛᱩᱢ ᱵᱟᱝ ᱧᱟᱢ ᱞᱮᱱᱠᱷᱟᱱ ᱢᱩᱲ ᱧᱩᱛᱩᱢ ᱜᱮ ᱦᱟᱛᱟᱣᱟ", "text": "suffix_word = suffix_map.get(suffix.upper(), suffix) // ᱮᱴᱟᱜ ᱠᱟᱛᱷᱟ ᱵᱟᱝ ᱧᱟᱢ ᱞᱮᱱᱠᱷᱟᱱ ᱢᱟᱲᱟᱝ ᱞᱮᱠᱟ ᱜᱮ ᱛᱟᱦᱮᱱᱟ //"}
{"unnormalised": "", "normalised": "ᱨᱩᱣᱟᱹᱲ ᱦᱩᱭᱩᱜᱼᱟ f\"{ᱴᱟᱠᱟ_ᱟᱹᱲᱟᱹ} {ᱞᱮᱠᱷᱟ_ᱟᱹᱲᱟᱹ} {ᱛᱟᱭᱚᱢ_ᱟᱹᱲᱟᱹ}\"", "text": "ᱮᱢ ᱯᱮᱨᱮᱡ ᱢᱮ \"{currency_word} {number_words} {suffix_word}\""}
{"unnormalised": "", "normalised": "ᱫᱚᱭᱟᱠᱟᱛᱮ ᱱᱚᱶᱟ ᱤᱝᱞᱤᱥ ᱴᱮᱠᱥᱴ ᱫᱚ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱢᱮ, ພᱷᱟᱹᱭᱜᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ; ᱮᱛᱚᱦᱚᱵ ᱜᱟᱨ ᱵᱮᱱᱟᱣ ᱟᱨ ᱡᱟᱭᱜᱟ ᱫᱚ ᱵᱟᱧᱪᱟᱣ ᱠᱟᱛᱮ ᱫᱚᱦᱚᱭ ᱢᱮ᱾", "text": ""}
{"unnormalised": "", "normalised": "text = re.sub(r'([$₹€£¥])(\\d+)([KMBTkmbt])\\b', replace_currency_number_suffix, text)", "text": "text = re.sub(r'([$₹€£¥])(\\d+)([KMBTkmbt])\\b', replace_currency_number_suffix, text)"}
{"unnormalised": "", "normalised": "# ᱨᱩᱞ ᱔: ᱞᱮᱠᱷᱟ ᱡᱚᱠᱷᱟ ᱛᱚᱯᱟᱜ (K, M, B, T) - ᱢᱤᱫᱩᱜ ᱠᱟᱹᱣᱰᱤ ᱛᱟᱭᱚᱢ ᱢᱮᱱᱠᱷᱟᱱ ᱥᱟᱫᱷᱟᱨᱚᱱ ᱮᱞᱮᱞ ᱨᱩᱞ ᱢᱟᱬᱟᱝ", "text": "# ᱱᱤᱭᱚᱢ ᱔: ᱮᱞ ᱨᱮᱭᱟᱜ ᱛᱟᱭᱚᱢ ᱡᱩᱲᱟᱹᱣ (ᱠᱮ, ᱮᱢ, ᱵᱤ, ᱴᱤ) - ᱡᱟᱣᱨᱤ ᱠᱟᱹᱣᱰᱤ ᱡᱩᱢᱤᱫ ᱠᱟᱛᱮ ᱢᱮᱱᱠᱷᱟᱱ ᱥᱟᱫᱷᱟᱨᱚᱱ ᱮᱞ ᱱᱤᱭᱚᱢ ᱢᱟᱬᱟᱝ ᱨᱮ"}
{"unnormalised": "", "normalised": "def replace_numeric_suffix(match):", "text": "ᱛᱚᱝᱜᱮ ᱞᱮᱠᱟᱛᱮ ᱮᱞᱠᱷᱟ ᱛᱷᱩᱠᱟᱹᱢ ᱫᱚ ᱵᱚᱫᱚᱞ ᱢᱮ (match):"}
{"unnormalised": "", "normalised": "number_val = match.group(1)", "text": "ᱞᱮᱠᱷᱟ_ᱢᱟᱱ = ᱢᱮᱪ.ᱜᱨᱩᱯ(᱑)"}
{"unnormalised": "", "normalised": "suffix = match.group(2)", "text": "ᱛᱟᱭᱚᱢ ᱡᱚᱲᱟᱣ ᱟᱠᱟᱱ = ᱡᱚᱲᱟᱣ ᱨᱮᱭᱟᱜ ᱜᱟᱫᱮᱞ (᱒)"}
{"unnormalised": "", "normalised": "number_words = convert_number_to_words(number_val)", "text": "number_words = number_val ᱞᱮᱠᱷᱟ ᱟᱹᱲᱟᱹ ᱨᱩᱣᱟᱹᱲ ᱢᱮ"}
{"unnormalised": "", "normalised": "suffix_map = {", "text": "suffix_map = {"}
{"unnormalised": "", "normalised": "'K': 'ᱦᱟᱡᱟᱨ', 'M': 'ᱢᱤᱞᱤᱭᱚᱱ', 'B': 'ᱵᱤᱞᱤᱭᱚᱱ', 'T': 'ᱴᱨᱤᱞᱤᱭᱚᱱ'", "text": "'K': 'ᱥᱟᱥᱟᱭ', 'M': 'ᱢᱤᱞᱤᱭᱚᱱ', 'B': 'ᱵᱤᱞᱤᱭᱚᱱ', 'T': 'ᱴᱨᱤᱞᱤᱭᱚᱱ'"}
{"unnormalised": "", "normalised": "}", "text": "}"}
{"unnormalised": "", "normalised": "ᱨᱩᱣᱟᱲ ᱢᱮ {number_words} {suffix_map.get(suffix.upper(), suffix)}", "text": "ᱨᱩᱣᱟᱹᱲ ᱢᱮ  `{number_words} {suffix_map.get(suffix.upper(), suffix)}`"}
{"unnormalised": "", "normalised": "ᱫᱚᱭᱟᱠᱟᱛᱮ ᱱᱚᱶᱟ ᱤᱝᱞᱤᱥ ᱴᱮᱠᱥᱴ ᱫᱚ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱢᱮ, ພᱷᱟᱹᱭᱜᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ; ᱮᱛᱚᱦᱚᱵ ᱜᱟᱨ ᱵᱮᱱᱟᱣ ᱟᱨ ᱡᱟᱭᱜᱟ ᱫᱚ ᱵᱟᱧᱪᱟᱣ ᱠᱟᱛᱮ ᱫᱚᱦᱚᱭ ᱢᱮ᱾", "text": ""}
{"unnormalised": "", "normalised": "```santali\n    text = re.sub(r'(\\d+)([KMBTkmbt])\\b', replace_numeric_suffix, text)\n```", "text": "text = re.sub(r'(\\d+)([KMBTkmbt])\\b', replace_numeric_suffix, text)"}
{"unnormalised": "", "normalised": "# Rule 1 & 8: ᱮᱞᱠᱷᱟ ᱪᱤᱱᱦᱟᱹ ᱟᱨ ᱡᱚᱴᱤᱞ ᱪᱤᱱᱦᱟᱹ", "text": "# ᱑ ᱟᱨ ᱘ ᱱᱚᱢᱵᱚᱨ ᱱᱤᱭᱚᱢ: ᱮᱞᱠᱷᱟ ᱪᱤᱱᱦᱟᱹᱣ ᱟᱨ ᱟᱴᱮᱫ ᱪᱤᱱᱦᱟᱹ"}
{"unnormalised": "", "normalised": "# ᱵᱷᱮᱜᱮᱫ ᱮᱞᱠᱟ: x/y -> x ᱫᱚ y ᱛᱮ ᱦᱟᱴᱤᱧ (ᱥᱩᱢᱩᱝ ᱯᱩᱨᱟᱹ ᱮᱞ ᱞᱟᱹᱜᱤᱫ)", "text": "# ᱵᱷᱟᱜᱽᱱᱟ: x/y -> x ᱫᱚ y ᱛᱮ ᱦᱟᱴᱤᱧ (ᱥᱩᱢᱩᱝ ᱮᱞ ᱞᱟᱹᱜᱤᱫ)"}
{"unnormalised": "", "normalised": "```santali\n    text = re.sub(r'(\\d+)/(\\d+)', r'\\1 ᱦᱟᱴᱤᱧ \\2 ᱛᱮ', text)\n```", "text": "text = re.sub(r'(\\d+)/(\\d+)', r'\\1 ᱵᱷᱟᱜᱽ ᱟᱠᱟᱱᱟ \\2 ᱛᱮ', text)"}
{"unnormalised": "", "normalised": "ᱫᱚᱭᱟᱠᱟᱛᱮ ᱱᱚᱶᱟ ᱤᱝᱞᱤᱥ ᱴᱮᱠᱥᱴ ᱫᱚ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱢᱮ, ພᱷᱟᱹᱭᱜᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ; ᱮᱛᱚᱦᱚᱵ ᱜᱟᱨ ᱵᱮᱱᱟᱣ ᱟᱨ ᱡᱟᱭᱜᱟ ᱫᱚ ᱵᱟᱧᱪᱟᱣ ᱠᱟᱛᱮ ᱫᱚᱦᱚᱭ ᱢᱮ᱾", "text": ""}
{"unnormalised": "", "normalised": "# ᱮᱞᱠᱷᱟ ᱪᱤᱱᱦᱟᱹ ᱠᱚ", "text": "ᱮᱞᱠᱷᱟ ᱪᱤᱱᱦᱟᱹ"}
{"unnormalised": "", "normalised": "text = text.replace('∫', 'integral of')", "text": "text = text.replace('∫', 'integral of')"}
{"unnormalised": "", "normalised": "text = text.replace('→', 'to') # For integral limits", "text": "text = text.replace('→', 'to') # For integral limits"}
{"unnormalised": "", "normalised": "text = text.replace('√', 'square root of')", "text": "text = text.replace('√', 'square root of')"}
{"unnormalised": "", "normalised": "text = text.replace('π', 'pi')", "text": "text = text.replace('π', 'pi')"}
{"unnormalised": "", "normalised": "text = text.replace('Σ', 'ᱡᱟᱣᱨᱟᱭᱮᱱᱟ')", "text": "text = text.replace('Σ', 'summation of')"}
{"unnormalised": "", "normalised": "text = text.replace('≠', 'ᱵᱟᱝ ᱥᱚᱢᱟᱱ ᱜᱮ')", "text": "ᱞᱟᱹᱭ ᱚᱞ = ᱞᱟᱹᱭ ᱚᱞ ᱫᱚ ᱵᱚᱫᱚᱞ ᱢᱮ '≠', 'ᱵᱟᱝ ᱥᱚᱢᱟᱱ ᱜᱮᱭᱟ' ᱥᱟᱶᱛᱮ"}
{"unnormalised": "", "normalised": "text = text.replace('≤', 'ᱞᱮᱥ ᱫᱮᱱ ᱚᱨ ᱤᱠᱣᱟᱹᱞ ᱴᱩ')", "text": "text = text.replace('≤', 'ᱞᱟᱛᱟᱨ ᱥᱮ ᱥᱚᱢᱟᱱ')"}
{"unnormalised": "", "normalised": "text = text.replace('≥', 'ᱵᱟᱹᱲᱛᱤ ᱥᱮ ᱥᱚᱢᱟᱱ')", "text": "text = text.replace('≥', 'ᱵᱟᱹᱲᱛᱤ ᱥᱮ ᱥᱚᱢᱟᱱ')"}
{"unnormalised": "", "normalised": "text = text.replace('≈', 'ᱟᱴᱢᱟᱴᱤᱠ ᱥᱚᱢᱟᱱ ᱜᱮ')", "text": "text ᱫᱚ text.replace('≈', 'approximately equal to') ᱛᱮ ᱵᱚᱫᱚᱞ ᱢᱮ ᱾"}
{"unnormalised": "", "normalised": "text = text.replace('≅', 'ᱮᱴᱟᱜ ᱥᱟᱶ ᱥᱚᱢᱟᱱ ᱜᱮ')", "text": "text = text.replace('≅', 'ᱟᱹᱰᱤ ᱥᱩᱨ ᱥᱩᱯᱩᱨ ᱥᱚᱢᱟᱱ ᱜᱮ')"}
{"unnormalised": "", "normalised": "text = text.replace('≡', 'ᱵᱟᱨᱟᱵᱟᱹᱨᱤ ᱜᱮ ᱥᱚᱢᱟᱱ')", "text": "text = ᱴᱮᱠᱥᱴ ᱫᱚ ᱴᱮᱠᱥᱴ.ᱨᱤᱯᱞᱮᱥ(‘≡’, ‘ᱟᱭᱰᱮᱱᱴᱤᱠᱟᱞᱤ ᱤᱠᱣᱟᱞ ᱴᱩ’)"}
{"unnormalised": "", "normalised": "text = text.replace('∀', 'ᱥᱟᱱᱟᱢ ᱞᱟᱹᱜᱤᱫ')", "text": "txt = txt.replace('∀', 'for all')"}
{"unnormalised": "", "normalised": "text = text.replace('∃', 'ᱢᱮᱱᱟᱜᱼᱟ')", "text": "text ᱫᱚ text.replace('∃', 'there exists') ᱛᱮ ᱵᱚᱫᱚᱞ ᱢᱮ"}
{"unnormalised": "", "normalised": "text = text.replace('∉', 'not an element of')", "text": "text = ᱴᱮᱠᱥᱴ.replace('∉', 'not an element of')"}
{"unnormalised": "", "normalised": "text = text.replace('∈', 'ᱢᱮᱱᱟᱜ ᱟᱠᱟᱫᱟ')", "text": "text = text.replace('∈', 'is an element of')"}
{"unnormalised": "", "normalised": "text = text.replace('⊂', 'is a subset of')", "text": "text = text.replace('⊂', 'ᱦᱩᱭᱩᱜ ᱠᱟᱱᱟ ᱢᱤᱫ ᱦᱟᱹᱴᱤᱧ')"}
{"unnormalised": "", "normalised": "text = text.replace('⊃', 'ᱫᱚ ᱢᱤᱫ ᱥᱩᱯᱟᱨᱥᱮᱴ ᱠᱟᱱᱟ')", "text": "Text = text.replace('⊃', 'ᱢᱟᱨᱟᱝ ᱥᱮᱴ ᱠᱟᱱᱟ')"}
{"unnormalised": "", "normalised": "text = text.replace('∪', 'union')", "text": "text = text.replace('∪', 'union')"}
{"unnormalised": "", "normalised": "text = text.replace('∩', 'intersection')", "text": "text = text.replace('∩', 'intersection')"}
{"unnormalised": "", "normalised": "text = text.replace('∅', 'ᱛᱷᱟᱠᱟ ᱥᱮᱴ')", "text": "text = text.replace('∅', 'ᱛᱷᱟᱹᱞᱤ ᱥᱮᱴ')"}
{"unnormalised": "", "normalised": "text = text.replace('∝', 'is proportional to')", "text": "text = text.replace('∝', 'ᱥᱚᱢᱟᱱুপᱟᱛᱤ ᱠᱟᱱᱟ')"}
{"unnormalised": "", "normalised": "text = text.replace('∞', 'ᱮᱥᱤᱢ')", "text": "text = text.replace('∞', 'infinity')"}
{"unnormalised": "", "normalised": "ᱱᱚᱣᱟ ᱚᱞ ᱫᱚ ᱚᱞ ᱵᱚᱫᱚᱞ ᱢᱮ '±' ᱫᱚ 'plus or minus' ᱛᱮ", "text": "text = text.replace('±', 'plus or minus')"}
{"unnormalised": "", "normalised": "text = text.replace('∇', 'nabla')", "text": "text = text.replace('∇', 'nabla')"}
{"unnormalised": "", "normalised": "text = text.replace('∂', 'ᱯᱟᱨᱥᱟᱞ ᱰᱮᱨᱤᱵᱷᱮᱴᱤᱵᱷ')", "text": "text = text.replace('∂', 'partial derivative')"}
{"unnormalised": "", "normalised": "text = text.replace('⊕', 'ᱫᱟᱨᱟᱭᱤᱡ ᱡᱚᱜ')", "text": "txt = txt.replace('⊕', 'direct sum')"}
{"unnormalised": "", "normalised": "text = text.replace('⊗', 'tensor product')", "text": "text = text.replace('⊗', 'tensor product')"}
{"unnormalised": "", "normalised": "text = text.replace('∘', 'composition')", "text": "text = text.replace('∘', 'composition')"}
{"unnormalised": "", "normalised": "text = text.replace('⋅', 'dot product') # ᱥᱮ ᱚᱠᱛᱚ ᱞᱮᱠᱟᱛᱮ ᱵᱚᱫᱚᱞᱚᱜᱼᱟ, ᱚᱱᱟ ᱦᱟᱞᱚᱛ ᱪᱮᱛᱟᱱ ᱨᱮ ᱱᱤᱨᱵᱷᱚᱨᱚᱜᱼᱟ᱾ ᱰᱤᱯᱷᱚᱞᱴ ᱞᱮᱠᱟᱛᱮ 'ᱰᱚᱴ ᱯᱨᱚᱰᱚᱠᱴ'", "text": "text = text.replace('⋅', 'ᱮᱠᱥᱴᱮᱱᱥᱚᱱ ᱰᱚᱴ ᱯᱨᱚᱰᱟᱠᱴ') # ᱵᱟᱝᱠᱷᱟᱱ ᱜᱩᱱ, ᱵᱟᱰᱟᱭ ᱠᱟᱱ ᱚᱠᱛᱚ ᱪᱮᱛᱟᱱ ᱨᱮ ᱵᱷᱚᱨᱥᱟ ᱾ ᱮᱛᱚᱦᱚᱵ ᱫᱚ ᱮᱠᱥᱴᱮᱱᱥᱚᱱ ᱰᱚᱴ ᱯᱨᱚᱰᱚᱠᱴ ᱠᱟᱱᱟ ᱾"}
{"unnormalised": "", "normalised": "text = text.replace('°', 'degree') # ᱞᱟᱹᱜᱤᱫ ᱭᱩᱱᱤᱴ, ᱵᱷᱮᱜᱟᱨ ᱛᱮ ᱦᱮᱸᱰᱮᱞ ᱟᱠᱟᱱᱟ", "text": "text = text.replace('°', 'degree') # ᱞᱟᱹᱜᱤᱫ ᱭᱩᱱᱤᱴ, ᱵᱷᱮᱜᱟᱨ ᱛᱮ ᱦᱮᱸᱰᱮᱞ ᱦᱩᱭᱩᱜᱼᱟ"}
{"unnormalised": "", "normalised": "# ᱯᱟᱣᱟᱨ ᱟᱨ ᱥᱟᱵᱽᱥᱠᱨᱤᱯᱴ", "text": "# ᱯᱟᱣᱟᱨ ᱟᱨ ᱥᱟᱵᱽᱥᱠᱨᱤᱯᱴᱥ"}
{"unnormalised": "", "normalised": "text = re.sub(r'(\\w)\\^2\\b', r'\\1 ᱵᱚᱨᱜᱚ ᱜᱩᱱ', text)", "text": "text = re.sub(r'(\\w)\\^2\\b', r'\\1 squared', text)"}
{"unnormalised": "", "normalised": "```\ntext = re.sub(r'(\\w)\\^3\\b', r'\\1 ᱠᱭᱩᱵᱰ', text)\n```", "text": "text = re.sub(r'(\\w)\\^3\\b', r'\\1 ᱠᱭᱩᱵᱽᱰ', text)"}
{"unnormalised": "", "normalised": "```santali\ntext = re.sub(r'(\\w)\\^(\\d+)\\b', r'\\1 ᱫᱚ \\2 ᱨᱮᱭᱟᱜ ᱫᱟᱲᱮ', text)\n```", "text": "text = re.sub(r'(\\w)\\^(\\d+)\\b', r'\\1 ᱨᱮᱭᱟᱜ ᱫᱟᱲᱮ \\2', text)"}
{"unnormalised": "", "normalised": "text = re.sub(r'(\\w)_(\\w+)\\b', r'\\1 sub \\2', text) # x_i -> x sub i", "text": "text = re.sub(r'(\\w)_(?!\\s)(\\w+)\\b', r'\\1 sub \\2', text) # x_i -> x sub i"}
{"unnormalised": "", "normalised": "text = re.sub(r'(\\w)_(\\{\\w+\\})\\b', r'\\1 sub \\2', text) # x_{max} -> x sub max", "text": "text = re.sub(r'(\\w)_(\\{\\w+\\})\\b', r'\\1 sub \\2', text) # x_{max} -> x sub max"}
{"unnormalised": "", "normalised": "# ᱮᱴᱟᱜ ᱪᱤᱱᱦᱟᱹᱠᱚ", "text": "# ᱮᱴᱟᱜ ᱪᱤᱱᱦᱟᱹ ᱠᱚ"}
{"unnormalised": "", "normalised": "text = text.replace('$', 'ᱰᱚᱞᱟᱨ')", "text": "text = text.replace('$', 'ᱰᱚᱞᱟᱨ')"}
{"unnormalised": "", "normalised": "text = text.replace('€', 'ᱭᱩᱨᱳ')", "text": "text = text.replace('€', 'euro')"}
{"unnormalised": "", "normalised": "text = text.replace('£', 'ᱯᱟᱣᱩᱱᱰ')", "text": "text = text.replace('£', 'ᱯᱟᱣᱩᱱᱰ')"}
{"unnormalised": "", "normalised": "text = text.replace('¥', 'ᱭᱮᱱ')", "text": "text = text.replace('¥', 'yen')"}
{"unnormalised": "", "normalised": "text = text.replace('₹', 'ᱴᱟᱠᱟ')", "text": "text = text.replace('rupee', 'ᱴᱟᱠᱟ')"}
{"unnormalised": "", "normalised": "text = text.replace('%', 'ᱯᱚᱨᱥᱮᱱᱴ')", "text": "text = text.replace('percent', 'percent')"}
{"unnormalised": "", "normalised": "text = text.replace('@', 'at')", "text": "text = text.replace('@', 'at')"}
{"unnormalised": "", "normalised": "text = text.replace('&', 'ᱟᱨ')", "text": "text = text.replace('&', 'and')"}
{"unnormalised": "", "normalised": "text = text.replace('#', 'ᱦᱟᱥ')", "text": "text = text.replace('#', 'hash')"}
{"unnormalised": "", "normalised": "text = text.replace('*', 'ᱮᱥᱴᱮᱨᱤᱥᱠ')", "text": "text = text.replace('*', 'asterisk')"}
{"unnormalised": "", "normalised": "text = text.replace('+', 'plus')", "text": "text = text.replace('+', 'plus')"}
{"unnormalised": "", "normalised": "text = text.replace('=', 'ᱥᱚᱢᱟᱱ ᱜᱮᱭᱟ')", "text": "text ᱫᱚ text.replace('=', 'equals') ᱛᱮ ᱵᱚᱫᱚᱞ ᱢᱮ"}
{"unnormalised": "", "normalised": "text = text.replace('-', 'minus') # ᱥᱟᱹᱵᱽᱫᱷᱟᱱᱛᱟ ᱛᱟᱦᱮᱱ ᱢᱟ ᱦᱟᱭᱯᱷᱮᱱ ᱟᱠᱟᱱ ᱟᱹᱲᱟᱹ ᱵᱤᱨᱩᱫᱷ ᱜᱟᱱᱤᱛ ᱢᱟᱭᱱᱟᱥ", "text": "text = text.replace('-', ' minus ')\n```santali\ntext = text.replace('minus', '-')\n```"}
{"unnormalised": "", "normalised": "text = text.replace('~', 'ᱟᱸᱰᱟᱡᱽ')", "text": "Text = ᱴᱮᱠᱥᱴ = ᱴᱮᱠᱥᱴ.ᱨᱤᱯᱞᱮᱥ('\\~', 'ᱟᱯᱟᱥᱟᱯᱤᱥ')"}
{"unnormalised": "", "normalised": "# Rule 2: Acronyms → Hyphenated letters", "text": "# ᱨᱩᱞ ᱒: ᱮᱠᱨᱳᱱᱤᱢᱥ → ᱦᱟᱭᱯᱷᱮᱱ-ᱟᱠᱟᱱ ᱪᱤᱠᱤ"}
{"unnormalised": "", "normalised": "```santali\n    text = re.sub(r'\\b([A-Z]{2,})\\b', lambda m: '-'.join(list(m.group(1))), text)\n```", "text": "text = re.sub(r'\\b([A-Z]{2,})\\b', lambda m: '-'.join(list(m.group(1))), text)"}
{"unnormalised": "", "normalised": "ᱫᱚᱭᱟᱠᱟᱛᱮ ᱱᱚᱶᱟ ᱤᱝᱞᱤᱥ ᱴᱮᱠᱥᱴ ᱫᱚ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱢᱮ, ພᱷᱟᱹᱭᱜᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ; ᱮᱛᱚᱦᱚᱵ ᱜᱟᱨ ᱵᱮᱱᱟᱣ ᱟᱨ ᱡᱟᱭᱜᱟ ᱫᱚ ᱵᱟᱧᱪᱟᱣ ᱠᱟᱛᱮ ᱫᱚᱦᱚᱭ ᱢᱮ᱾", "text": ""}
{"unnormalised": "", "normalised": "# ᱖ ᱮᱱᱚᱢ: ᱢᱟᱹᱦᱤᱛ → ᱨᱚᱲ ᱨᱩᱯ (DD/MM/YYYY ᱵᱟᱝᱢᱟ YYYY-MM-DD ᱢᱮᱱᱛᱮ ᱵᱩᱡᱷᱟᱹᱣᱚᱜᱼᱟ)", "text": "# ᱱᱤᱭᱚᱢ ᱖: ᱢᱟᱹᱦᱤᱛ → ᱨᱚᱲ ᱨᱚᱯᱚᱫ ᱨᱩᱯ ( ᱰᱤᱰᱤ/ ᱮᱢᱮᱢ/ ᱣᱟᱭᱣᱟᱭᱣᱟᱭᱣᱟᱭ ᱥᱮ ᱣᱟᱭᱣᱟᱭᱣᱟᱭᱣᱟᱭ- ᱮᱢᱮᱢ- ᱰᱤᱰᱤ ᱢᱮᱱᱛᱮ ᱵᱩᱡᱷᱟᱹᱣᱜᱼᱟ)"}
{"unnormalised": "", "normalised": "ᱦᱟᱹᱴᱤᱧ ᱢᱟᱹᱦᱤᱛ (match) :", "text": "ᱵᱚᱫᱚᱞ ᱢᱟᱹᱦᱤᱛ (ᱢᱮᱪᱷ) :"}
{"unnormalised": "", "normalised": "ᱢᱟᱦᱟᱸ, ᱪᱟᱸᱫᱚ, ᱥᱮᱨᱢᱟ = '', '', ''", "text": "ᱢᱟᱦᱟᱸ, ᱪᱟᱸᱫᱚ, ᱥᱮᱨᱢᱟ = '', '', ''"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱢᱮᱪ.ᱜᱨᱩᱯ(᱑) : # ᱰᱤᱰᱤ-ᱮᱢᱮᱢ-ᱣᱟᱭᱣᱟᱭᱣᱟᱭᱣᱟᱭ ᱥᱮ ᱰᱤᱰᱤ/ᱮᱢᱮᱢ/ᱣᱟᱭᱣᱟᱭᱣᱟᱭᱣᱟᱭ", "text": "ᱡᱩᱫᱤ ᱢᱮᱪ.ᱜᱽᱨᱩᱯ(᱑) ᱢᱮᱱᱟᱜᱼᱟ, ᱮᱱᱠᱷᱟᱱ ᱺ # ᱰᱤᱰᱤᱼᱮᱢᱮᱢᱼᱣᱟᱭᱣᱟᱭᱣᱟᱭᱣᱟᱭ ᱥᱮ ᱰᱤᱰᱤ/ᱮᱢᱮᱢ/ᱣᱟᱭᱣᱟᱭᱣᱟᱭᱣᱟᱭ"}
{"unnormalised": "", "normalised": "ᱢᱟᱦᱟᱸ ᱫᱚ = int(match.group(2))", "text": "ᱢᱟᱦᱟᱸ ᱫᱚ = ᱯᱩᱨᱟᱹᱣ ᱞᱮᱠᱷᱟᱭ ᱢᱮᱪᱷ.ᱜᱩᱨᱩᱯ(᱒)"}
{"unnormalised": "", "normalised": "ᱪᱟᱸᱫᱳ = int(match.group(᱓))", "text": "ᱪᱟᱸᱫᱚ = int(match.group(3))"}
{"unnormalised": "", "normalised": "ᱥᱮᱨᱢᱟ = ᱯᱩᱨᱟᱹ ᱞᱮᱠᱷᱟ ᱨᱮ ᱵᱚᱫᱚᱞ ᱢᱮ ᱢᱮᱪ.ᱜᱨᱩᱯ(᱔)", "text": "ᱥᱮᱨᱢᱟ = int(match.group(4))"}
{"unnormalised": "", "normalised": "ᱮᱱᱠᱷᱟᱱ ᱡᱩᱫᱤ ᱢᱮᱪ.ᱜᱨᱩᱯ(᱕) ᱢᱮᱱᱟᱜᱼᱟ ᱵᱷᱟᱹᱜᱤ ᱛᱚᱵᱮ # ᱵᱚᱪᱷᱚᱨᱼᱪᱟᱸᱫᱚᱼᱢᱟᱹᱦᱤᱛ", "text": "ᱮᱞᱟᱠᱷᱟᱱ ᱡᱩᱫᱤ ᱢᱮᱪᱹ ᱜᱟᱫᱮᱞ (5):  # YYYY-MM-DD"}
{"unnormalised": "", "normalised": "ᱥᱮᱨᱢᱟ = int(match.group(6))", "text": "ᱥᱮᱨᱢᱟ = ᱯᱩᱨᱟᱹ ᱞᱮᱠᱷᱟ (match.group(6))"}
{"unnormalised": "", "normalised": "ᱪᱟᱸᱫᱚ = int(match.group(᱗))", "text": "ᱪᱟᱸᱫᱚ = int(match.group(᱗))"}
{"unnormalised": "", "normalised": "ᱢᱟᱦᱟᱸ = int(match.group(᱘))", "text": "ᱢᱟᱦᱟᱸ ᱫᱚ = int(match.group(8))"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱵᱟᱝ (ᱢᱟᱦᱟᱸ ᱟᱨ ᱪᱟᱸᱫᱚ ᱟᱨ ᱥᱮᱨᱢᱟ) ᱠᱷᱟᱱ:", "text": "ᱡᱩᱫᱤ ᱵᱟᱝ (ᱢᱟᱦᱟᱸ ᱟᱨ ᱪᱟᱸᱫᱚ ᱟᱨ ᱥᱮᱨᱢᱟ):"}
{"unnormalised": "", "normalised": "ᱨᱩᱣᱟᱹᱲ ᱢᱮ ᱢᱮᱪ.ᱜᱨᱩᱯ(᱐) # ᱨᱩᱣᱟᱹᱲ ᱢᱮ ᱢᱩᱲᱩᱫ ᱡᱩᱫᱤ ᱢᱤᱛᱷᱤ ᱯᱟᱹᱨᱥᱤ ᱵᱟᱭ ᱥᱟᱹᱠᱷᱭᱟᱹᱛ ᱟᱠᱟᱱᱟ", "text": "ᱮᱱᱟ ᱫᱚᱲᱚᱢ ᱡᱟᱦᱟᱸ ᱜᱮ ᱧᱟᱢ ᱟᱠᱟᱱᱟ ᱚᱱᱟ ᱜᱮ ᱮᱢ ᱨᱩᱣᱟᱲ ᱢᱮ (# ᱢᱟᱹᱦᱤᱛ ᱵᱟᱹᱱᱩᱜ ᱞᱮᱠᱟ ᱵᱩᱡᱷᱟᱹᱣ ᱞᱮᱱ ᱠᱷᱟᱱ ᱢᱩᱲ ᱜᱮ ᱨᱩᱣᱟᱲ ᱢᱮ)"}
{"unnormalised": "", "normalised": "ᱪᱟᱸᱫᱚᱠᱩ = [\"\", \"ᱡᱟᱱᱩᱣᱟᱨᱤ\", \"ᱯᱷᱮᱵᱽᱨᱩᱣᱟᱨᱤ\", \"ᱢᱟᱨᱪ\", \"ᱮᱯᱨᱤᱞ\", \"ᱢᱮ\", \"ᱡᱩᱱ\",", "text": "ᱪᱟᱸᱫᱚ ᱠᱚ = [\"\", \"ᱡᱟᱱᱣᱟᱨᱤ\", \"ᱯᱷᱮᱵᱽᱨᱩᱣᱟᱨᱤ\", \"ᱢᱟᱨᱪ\", \"ᱮᱯᱨᱤᱞ\", \"ᱢᱮ\", \"ᱡᱩᱱ\","}
{"unnormalised": "", "normalised": "\"ᱡᱩᱞᱟᱭ\", \"ᱚᱜᱚᱥᱴ\", \"ᱥᱮᱯᱴᱮᱢᱵᱚᱨ\", \"ᱚᱠᱴᱚᱵᱚᱨ\", \"ᱱᱚᱵᱷᱮᱢᱵᱚᱨ\", \"ᱰᱤᱥᱮᱢᱵᱚᱨ\"]", "text": "\"ᱡᱩᱞᱟᱭ\", \"ᱚᱜᱚᱥᱴ\", \"ᱥᱮᱯᱴᱮᱢᱵᱚᱨ\", \"ᱚᱠᱴᱚᱵᱚᱨ\", \"ᱱᱚᱵᱷᱮᱢᱵᱚᱨ\", \"ᱰᱤᱥᱮᱢᱵᱚᱨ\"]"}
{"unnormalised": "", "normalised": "ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱚᱞ ᱢᱮ ᱾ ᱥᱩᱢᱩᱝ ᱛᱚᱨᱡᱚᱢᱟ ᱚᱞ ᱨᱩᱣᱟᱹᱲ ᱢᱮ, ᱢᱩᱲᱩᱛ ᱜᱟᱨᱮᱫ ᱟᱨ ᱴᱷᱟᱶ ᱫᱚᱦᱚᱭ ᱢᱮ ᱾", "text": ""}
{"unnormalised": "", "normalised": "day_suffix = {1: 'ᱯᱩᱭᱞᱩ', 2: 'ᱫᱚᱥᱟᱨ', 3: 'ᱛᱮᱥᱟᱨ', 4: 'ᱯᱩᱱᱭᱟᱜ', 5: 'ᱢᱚᱬᱮᱭᱟᱜ', 6: 'ᱛᱩᱨᱩᱭᱟᱜ', 7: 'ᱮᱭᱟᱭᱟᱜ', 8: 'ᱤᱨᱟᱹᱞᱟᱜ', 9: 'ᱛᱩᱨᱩᱭᱟᱜ', 10: 'ᱜᱮᱞᱟᱜ', 11: 'ᱜᱮᱞᱢᱤᱫ', 12: 'ᱜᱮᱞᱵᱟᱨ', 13: 'ᱜᱮᱞᱯᱮ', 14: 'ᱜᱮᱞᱯᱩᱱ', 15: 'ᱜᱮᱞᱢᱚᱬᱮ', 16: 'ᱜᱮᱞᱛᱩᱨᱩᱭ', 17: 'ᱜᱮᱞᱮᱭᱟᱭ', 18: 'ᱜᱮᱞᱤᱨᱟᱹᱞ', 19: 'ᱜᱮᱞᱛᱩᱨᱩᱭ', 20: 'ᱵᱟᱜᱮ', 21: 'ᱵᱟᱜᱮ ᱢᱤᱫ', 22: 'ᱵᱟᱜᱮ ᱵᱟᱨ', 23: 'ᱵᱟᱜᱮ ᱯᱮ', 24: 'ᱵᱟᱜᱮ ᱯᱩᱱ', 25: 'ᱵᱟᱜᱮ ᱢᱚᱬᱮ', 26: 'ᱵᱟᱜᱮ ᱛᱩᱨᱩᱭ', 27: 'ᱵᱟᱜᱮ ᱮᱭᱟᱭ', 28: 'ᱵᱟᱜᱮ ᱤᱨᱟᱹᱞ', 29: 'ᱵᱟᱜᱮ ᱛᱩᱨᱩᱭ', 30: 'ᱯᱮᱜᱮ', 31: 'ᱯᱮᱜᱮ ᱢᱤᱫ'}", "text": "day_suffix = {1: 'ᱯᱩᱭᱞᱩ', 2: 'ᱫᱚᱥᱟᱨ', 3: 'ᱛᱮᱥᱟᱨ', 4: 'ᱯᱩᱱᱭᱟᱜ', 5: 'ᱢᱚᱬᱮᱭᱟᱜ', 6: 'ᱛᱩᱨᱩᱭᱟᱜ', 7: 'ᱮᱭᱟᱭᱟᱜ', 8: 'ᱤᱨᱟᱹᱞᱟᱜ', 9: 'ᱛᱩᱨᱩᱭᱟᱜ', 10: 'ᱜᱮᱞᱟᱜ', 11: 'ᱜᱮᱞᱢᱤᱫ', 12: 'ᱜᱮᱞᱵᱟᱨ', 13: 'ᱜᱮᱞᱯᱮ', 14: 'ᱜᱮᱞᱯᱩᱱ', 15: 'ᱜᱮᱞᱢᱚᱬᱮ', 16: 'ᱜᱮᱞᱛᱩᱨᱩᱭ', 17: 'ᱜᱮᱞᱮᱭᱟᱭ', 18: 'ᱜᱮᱞᱤᱨᱟᱹᱞ', 19: 'ᱜᱮᱞᱛᱩᱨᱩᱭ', 20: 'ᱵᱟᱜᱮᱞ', 21: 'ᱵᱟᱜᱮᱞ ᱯᱩᱭᱞᱩ', 22: 'ᱵᱟᱜᱮᱞ ᱫᱚᱥᱟᱨ', 23: 'ᱵᱟᱜᱮᱞ ᱛᱮᱥᱟᱨ', 24: 'ᱵᱟᱜᱮᱞ ᱯᱩᱱᱭᱟᱜ', 25: 'ᱵᱟᱜᱮᱞ ᱢᱚᱬᱮᱭᱟᱜ', 26: 'ᱵᱟᱜᱮᱞ ᱛᱩᱨᱩᱭᱟᱜ', 27: 'ᱵᱟᱜᱮᱞ ᱮᱭᱟᱭᱟᱜ', 28: 'ᱵᱟᱜᱮᱞ ᱤᱨᱟᱹᱞᱟᱜ', 29: 'ᱵᱟᱜᱮᱞ ᱛᱩᱨᱩᱭ', 30: 'ᱛᱮᱥᱮᱞ', 31: 'ᱛᱮᱥᱮᱞ ᱯᱩᱭᱞᱩ'}"}
{"unnormalised": "", "normalised": "ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱚᱞ ᱢᱮ ᱾ ᱥᱩᱢᱩᱝ ᱛᱚᱨᱡᱚᱢᱟ ᱚᱞ ᱨᱩᱣᱟᱹᱲ ᱢᱮ, ᱢᱩᱲᱩᱛ ᱜᱟᱨᱮᱫ ᱟᱨ ᱴᱷᱟᱶ ᱫᱚᱦᱚᱭ ᱢᱮ ᱾", "text": ""}
{"unnormalised": "", "normalised": "spoken_day = day_suffix.get(day, num2words(day, to='ordinal'))", "text": "ᱨᱚᱲ ᱫᱤᱱ = ᱫᱤᱱ_ᱥᱟᱯᱷᱤᱠᱥ.get(ᱫᱤᱱ, ᱱᱚᱢ᱒ᱣᱟᱨᱰᱥ(ᱫᱤᱱ, ᱴᱚ='ᱚᱨᱰᱤᱱᱟᱞ'))"}
{"unnormalised": "", "normalised": "spoken_month = months[month]", "text": "ᱨᱚᱲ ᱪᱟᱸᱫᱚ = ᱪᱟᱸᱫᱚ ᱠᱚ [ᱪᱟᱸᱫᱚ]"}
{"unnormalised": "", "normalised": "spoken_year = convert_number_to_words(str(year))", "text": "ᱥᱟᱹᱜᱟᱹᱭᱟᱱ_ᱥᱮᱨᱢᱟ = ᱥᱮᱨᱢᱟ ᱨᱮᱭᱟᱜ ᱮᱞ ᱫᱚ ᱟᱹᱲᱟᱹ ᱛᱮ ᱵᱚᱫᱚᱞ ᱢᱮ (str(ᱥᱮᱨᱢᱟ))"}
{"unnormalised": "", "normalised": "ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱚᱞ ᱢᱮ ᱾ ᱥᱩᱢᱩᱝ ᱛᱚᱨᱡᱚᱢᱟ ᱚᱞ ᱨᱩᱣᱟᱹᱲ ᱢᱮ, ᱢᱩᱲᱩᱛ ᱜᱟᱨᱮᱫ ᱟᱨ ᱴᱷᱟᱶ ᱫᱚᱦᱚᱭ ᱢᱮ ᱾", "text": ""}
{"unnormalised": "", "normalised": "return f\"{spoken_day} {spoken_month} {spoken_year}\"", "text": "f\"{ঞᱮঁহিঞৗ দিন} {ঞᱮঁহিঞৗ ᱪᱟᱸᱫᱚ} {ঞᱮঁহিঞৗ ᱥᱮᱨᱢᱟ}\""}
{"unnormalised": "", "normalised": "ᱰᱤᱰᱤ/ᱮᱢᱮᱢ/ᱣᱟᱭᱣᱟᱭᱣᱟᱭᱣᱟᱭ ᱵᱟᱝᱛᱮ ᱰᱤᱰᱤ-ᱮᱢᱮᱢ-ᱣᱟᱭᱣᱟᱭᱣᱟᱭᱣᱟᱭ", "text": "# ᱢᱟᱹᱦᱤᱛ/ᱪᱟᱸᱫᱚ/ᱥᱮᱨᱢᱟ ᱟᱨᱵᱟᱝ ᱢᱟᱹᱦᱤᱛ-ᱪᱟᱸᱫᱚ-ᱥᱮᱨᱢᱟ"}
{"unnormalised": "", "normalised": "```santali\n    text = re.sub(r'\\b((\\d{1,2})[/-](\\d{1,2})[/-](\\d{4}))\\b', replace_date, text)\n```", "text": "text = re.sub(r'\\b((\\d{1,2})[/-](\\d{1,2})[/-](\\d{4}))\\b', replace_date, text)"}
{"unnormalised": "", "normalised": "# YYYY-MM-DD", "text": "YYYY-MM-DD"}
{"unnormalised": "", "normalised": "text = re.sub(r'\\b((\\d{4})[/-](\\d{1,2})[/-](\\d{1,2}))\\b', replace_date, text)", "text": "text = re.sub(r'\\b((\\d{4})[/-](\\d{1,2})[/-](\\d{1,2}))\\b', replace_date, text)"}
{"unnormalised": "", "normalised": "# Rule 7: Units → ᱨᱚᱲ ᱨᱩᱯ", "text": "# ᱗ ᱮᱞᱮᱠᱟᱱ ᱠᱟᱱᱩᱱ: ᱤᱣᱱᱤᱴᱥ → ᱨᱚᱲ ᱦᱚᱨᱟ"}
{"unnormalised": "", "normalised": "ᱫᱚᱦᱲᱟ ᱠᱟᱛᱷᱟ ᱠᱚ ᱫᱚᱦᱲᱟᱭ ᱢᱮ (replace_units) ᱺ", "text": "```\ndef replace_units(match):\n```"}
{"unnormalised": "", "normalised": "number = convert_number_to_words(match.group(1))", "text": "ᱞᱮᱠᱷᱟ = ᱞᱮᱠᱷᱟ_ᱟᱹᱲᱟᱹ_ᱛᱮ_ᱵᱚᱫᱚᱞ (ᱢᱮᱪ.ᱜᱽᱨᱩᱯ (᱑))"}
{"unnormalised": "", "normalised": "unit = match.group(2).lower()", "text": "unit = match.group(2).lower()"}
{"unnormalised": "", "normalised": "unit_map = {", "text": "ᱤᱭᱩᱱᱤᱴ_ᱢᱮᱯ = {"}
{"unnormalised": "", "normalised": "'cm': 'ᱥᱮᱱᱴᱤᱢᱤᱴᱟᱨ', 'mm': 'ᱢᱤᱞᱤᱢᱤᱴᱟᱨ', 'm': 'ᱢᱤᱴᱟᱨ', 'km': 'ᱠᱤᱞᱚᱢᱤᱴᱟᱨ',", "text": "'cm': 'ᱥᱮᱱᱴᱤᱢᱤᱴᱟᱨ', 'mm': 'ᱢᱤᱞᱤᱢᱤᱴᱟᱨ', 'm': 'ᱢᱤᱴᱟᱨ', 'km': 'ᱠᱤᱞᱚᱢᱤᱴᱟᱨ',"}
{"unnormalised": "", "normalised": "'g': 'ᱜᱨᱟᱢ', 'kg': 'ᱠᱤᱞᱳᱜᱨᱟᱢ', 'mg': 'ᱢᱤᱞᱤᱜᱨᱟᱢ',", "text": "'g': 'ᱜᱨᱟᱢ', 'kg': 'ᱠᱤᱞᱚᱜᱨᱟᱢ', 'mg': 'ᱢᱤᱞᱤᱜᱨᱟᱢ',"}
{"unnormalised": "", "normalised": "'ml': 'ᱢᱤᱞᱤᱞᱤᱴᱚᱨ', 'l': 'ᱞᱤᱴᱚᱨ',", "text": "'ml': 'ᱢᱤᱞᱤᱞᱤᱴᱚᱨ', 'l': 'ᱞᱤᱴᱚᱨ',"}
{"unnormalised": "", "normalised": "'°c': 'ᱰᱤᱜᱽᱨᱤ ᱥᱮᱞᱥᱤᱭᱟᱥ', 'kph': 'ᱠᱤᱞᱚᱢᱤᱴᱟᱨ ᱯᱟᱹᱣᱲᱟᱹ ᱜᱷᱚᱱᱴᱟ',", "text": "'°c': 'ᱰᱤᱜᱽᱨᱤ ᱥᱮᱞᱥᱤᱭᱟᱥ', 'kph': 'ᱠᱤᱞᱚᱢᱤᱴᱟᱨ ᱯᱨᱚᱛᱤ ᱜᱷᱚᱱᱴᱟ',"}
{"unnormalised": "", "normalised": "'mph': 'ᱢᱟᱭᱤᱞ ᱜᱷᱟᱱᱴᱟ ᱨᱮ', 'psi': 'ᱯᱟᱣᱩᱱᱰ ᱯᱚᱨ ᱥᱠᱚᱭᱟᱨ ᱤᱧᱪ',", "text": "'mph': 'ᱢᱟᱭᱤᱞ ᱜᱷᱚᱱᱴᱟ ᱯᱤᱪᱷᱤ', 'psi': 'ᱯᱟᱣᱩᱱᱰ ᱪᱟᱹᱣᱠᱟᱹ ᱤᱧᱪᱤ ᱨᱮ',"}
{"unnormalised": "", "normalised": "'sqm': 'ᱵᱚᱨᱜᱚ ᱢᱤᱴᱚᱨ', 'sqkm': 'ᱵᱚᱨᱜᱚ ᱠᱤᱞᱚᱢᱤᱴᱚᱨ',", "text": "'sqm': 'ᱵᱚᱨᱜᱚ ᱢᱤᱴᱟᱨ', 'sqkm': 'ᱵᱚᱨᱜᱚ ᱠᱤᱞᱚᱢᱤᱴᱟᱨ',"}
{"unnormalised": "", "normalised": "'ᱦᱮᱠᱴᱮᱭᱟᱨ': 'ᱦᱮᱠᱴᱚᱨ', 'ᱯᱷᱩᱴ': 'ᱯᱷᱩᱴ', 'ᱤᱧᱪ': 'ᱤᱸᱪ', 'ᱭᱟᱨᱰ': 'ᱜᱚᱡ',", "text": "'ᱦᱮᱠᱴᱚᱨ': 'ᱦᱮᱠᱴᱚᱨ', 'ᱯᱷᱩᱴ': 'ᱯᱷᱩᱴ', 'ᱤᱸᱪ': 'ᱤᱸᱪ', 'ᱭᱟᱨᱰ': 'ᱭᱟᱨᱰ',"}
{"unnormalised": "", "normalised": "'oz': 'ᱚᱩᱱᱥ', 'lb': 'ᱯᱟᱣᱩᱱᱰ', 'hr': 'ᱜᱷᱚᱱᱴᱟ', 'min': 'ᱢᱤᱱᱤᱴ', 'sec': 'ᱥᱮᱠᱮᱱᱰ',", "text": "'oz': 'ᱟᱣᱸᱥ', 'lb': 'ᱯᱟᱣᱸᱰ', 'hr': 'ᱴᱟᱲᱟᱝ', 'min': 'ᱢᱤᱱᱤᱴ', 'sec': 'ᱥᱮᱠᱮᱱᱰ',"}
{"unnormalised": "", "normalised": "'mb': 'ᱢᱮᱜᱟᱵᱟᱭᱤᱴ', 'gb': 'ᱜᱤᱜᱟᱵᱟᱭᱤᱴ', 'tb': 'ᱴᱮᱨᱟᱵᱟᱭᱤᱴ', 'kb': 'ᱠᱤᱞᱚᱵᱟᱭᱤᱴ',", "text": "'mb': 'ᱢᱮᱜᱟᱵᱟᱭᱤᱴ', 'gb': 'ᱜᱤᱜᱟᱵᱟᱭᱤᱴ', 'tb': 'ᱴᱮᱨᱟᱵᱟᱭᱤᱴ', 'kb': 'ᱠᱤᱞᱚᱵᱟᱭᱤᱴ',"}
{"unnormalised": "", "normalised": "'hz': 'ᱦᱟᱨᱴᱡᱽ', 'khz': 'ᱠᱤᱞᱳᱦᱟᱨᱴᱡᱽ', 'mhz': 'ᱢᱮᱜᱟᱦᱟᱨᱴᱡᱽ', 'ghz': 'ᱜᱤᱜᱟᱦᱟᱨᱴᱡᱽ',", "text": "'hz': 'ᱦᱟᱨᱴᱡᱽ', 'khz': 'ᱠᱤᱞᱳᱦᱟᱨᱴᱡᱽ', 'mhz': 'ᱢᱮᱜᱟᱦᱟᱨᱴᱡᱽ', 'ghz': 'ᱜᱤᱜᱟᱦᱟᱨᱴᱡᱽ',"}
{"unnormalised": "", "normalised": "'v': 'ᱵᱷᱚᱞᱴ', 'a': 'ᱮᱢᱯᱤᱭᱟᱨ', 'w': 'ᱣᱟᱴ', 'kw': 'ᱠᱤᱞᱚᱣᱟᱴ', 'mw': 'ᱢᱮᱜᱟᱣᱟᱴ'", "text": "'v': 'ᱵᱷᱚᱞᱴ', 'a': 'ᱮᱢᱯᱤᱭᱟᱨ', 'w': 'ᱣᱟᱴ', 'kw': 'ᱠᱤᱞᱚᱣᱟᱴ', 'mw': 'ᱢᱮᱜᱟᱣᱟᱴ'"}
{"unnormalised": "", "normalised": "}", "text": "}"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱞᱟᱹᱠᱛᱤ ᱛᱟᱦᱮᱸᱱᱟ ᱮᱠᱟᱫᱷᱤᱠ ᱨᱩᱯ ᱨᱮ ᱵᱚᱫᱚᱞ ᱢᱮ (ᱥᱚᱫᱷᱟᱨᱚᱱ ᱵᱤᱫᱷᱤ)", "text": "ᱡᱩᱫᱤ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ ᱮᱱᱠᱷᱟᱱ ᱵᱟᱹᱲᱛᱤ ᱵᱮᱱᱟᱣ ᱢᱮ (ᱥᱚᱡᱷᱮ ᱩᱭᱦᱟᱹᱨ)"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱤᱱᱴ (ᱢᱮᱪ.ᱜᱨᱩᱯ(᱑)) > ᱑ ᱟᱨ ᱩᱱᱤᱴ_ᱢᱮᱯ.ᱜᱮᱴ(ᱩᱱᱤᱴ) ᱢᱮᱱᱟᱜᱼᱟ ᱟᱨ ᱩᱱᱤᱴ_ᱢᱮᱯ.ᱜᱮᱴ(ᱩᱱᱤᱴ).endswith('s') ᱵᱟᱝ ᱠᱟᱱᱟ ᱾", "text": "ᱡᱩᱫᱤ int(match.group(1)) > ᱑ ᱟᱨ ᱩᱱᱤᱴ_ᱢᱮᱯ.ᱜᱮᱴ(ᱩᱱᱤᱴ) ᱢᱮᱱᱟᱜᱼᱟ ᱟᱨ ᱩᱱᱤᱴ_ᱢᱮᱯ.ᱜᱮᱴ(ᱩᱱᱤᱴ).ᱮᱱᱰᱥᱣᱤᱛᱷ('s') ᱵᱟᱹᱱᱩᱜᱼᱟ ᱾"}
{"unnormalised": "", "normalised": "return f\"{number} {unit_map.get(unit)}s\"", "text": "ᱰᱟᱹᱝᱜᱤᱨ {number} {unit_map.get(unit)}s"}
{"unnormalised": "", "normalised": "ᱨᱩᱣᱟᱹᱲ ᱢᱮ {number} {unit_map.get(unit, unit)}", "text": "ᱮᱢ ᱯᱮᱨᱮᱡᱽ ᱢᱮ \"{number} {unit_map.get(unit, unit)}\""}
{"unnormalised": "", "normalised": "text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*(cm|mm|m|km|g|kg|mg|ml|l|°C|°c|kph|mph|psi|sqm|sqkm|ha|ft|in|yd|oz|lb|hr|min|sec|mb|gb|tb|kb|hz|khz|mhz|ghz|v|a|w|kw|mw)\\b', replace_units, text, flags=re.IGNORECASE)", "text": "text = re.sub(r'(\\d+(?:\\.\\d+)?)\\s*(cm|mm|m|km|g|kg|mg|ml|l|°C|°c|kph|mph|psi|sqm|sqkm|ha|ft|in|yd|oz|lb|hr|min|sec|mb|gb|tb|kb|hz|khz|mhz|ghz|v|a|w|kw|mw)\\b', replace_units, text, flags=re.IGNORECASE)"}
{"unnormalised": "", "normalised": "# ᱨᱩᱞ ᱓: ᱮᱞᱠᱚ → ᱨᱚᱲ ᱨᱩᱯ (ᱴᱟᱠᱟ, ᱛᱚᱯᱞᱚᱜ, ᱟᱨ ᱤᱭᱩᱱᱤᱴ ᱛᱟᱭᱚᱢ)", "text": "ᱱᱤᱭᱚᱢ ᱓: ᱮᱞᱠᱚ → ᱨᱚᱲ ᱨᱩᱯ (ᱴᱟᱠᱟ ᱛᱟᱭᱚᱢ, ᱡᱚᱲᱟᱣ ᱟᱠᱟᱱ ᱟᱹᱲᱟᱹᱠᱚ, ᱟᱨ ᱤᱭᱩᱱᱤᱴᱠᱚ)"}
{"unnormalised": "", "normalised": "ᱛᱮᱭᱟᱨ ᱠᱟᱛᱮ ᱡᱚᱛᱚ ᱮᱴᱟᱜ ᱱᱚᱢᱵᱚᱨ ᱥᱟᱶ ᱡᱩᱲᱟᱹᱣ ᱠᱟᱱ ᱠᱟᱹᱱᱩᱱ ᱠᱚ", "text": "# ᱱᱚᱣᱟ ᱫᱚ ᱡᱚᱛᱚ ᱮᱴᱟᱜ ᱮᱞ ᱥᱟᱹᱜᱟᱹᱭᱟᱱ ᱱᱤᱭᱚᱢ ᱛᱟᱭᱚᱢ ᱦᱤᱡᱩᱜ ᱫᱚᱨᱠᱟᱨ ᱾"}
{"unnormalised": "", "normalised": "```santali\ntext = re.sub(r'\\b(\\d+(?:\\.\\d+)?)\\b', lambda m: convert_number_to_words(m.group(1)), text)\n```", "text": "```\ntext = re.sub(r'\\b(\\d+(?:\\.\\d+)?)\\b', lambda m: convert_number_to_words(m.group(1)), text)\n```"}
{"unnormalised": "", "normalised": "# ᱨᱩᱞ ᱑ (ᱪᱟᱹᱞᱩ:) : ᱪᱤᱱᱦᱟᱹ ᱵᱚᱫᱚᱞ ᱡᱟᱦᱟᱸ ᱫᱚ ᱮᱴᱟᱜ ᱨᱩᱞ ᱥᱟᱶ ᱠᱚ ᱵᱟᱹᱲᱤᱡ ᱫᱟᱲᱮᱭᱟᱜᱼᱟ ᱡᱩᱫᱤ ᱢᱟᱲᱟᱝ ᱨᱮ ᱫᱚᱦᱚ ᱠᱚᱣᱟ", "text": "# ᱨᱩᱞ ᱑ (ᱪᱟᱹᱞᱩ) : ᱪᱤᱱᱦᱟᱹ ᱵᱚᱫᱚᱞ ᱡᱟᱦᱟᱸ ᱫᱚ ᱮᱴᱟᱜ ᱨᱩᱞ ᱠᱚ ᱥᱟᱶ ᱡᱚᱴᱮᱫ ᱦᱩᱭ ᱫᱟᱲᱮᱭᱟᱜ-ᱟ ᱡᱩᱫᱤ ᱱᱚᱣᱟ ᱫᱚ ᱢᱟᱲᱟᱝ ᱨᱮ ᱫᱚᱦᱚ ᱠᱚᱜ-ᱟ ᱾"}
{"unnormalised": "", "normalised": "# ᱮᱢ ᱵᱮᱵᱷᱟᱨ ᱢᱚᱱᱮ ᱫᱚᱦᱚᱭ ᱢᱮ / ᱢᱚᱡᱽ ᱛᱮ: ᱮᱞᱠᱷᱟ ᱛᱟᱞᱟ ᱨᱮ \"ᱦᱟᱴᱤᱧ ᱛᱮ\", ᱟᱹᱲᱟᱹ ᱛᱟᱞᱟ ᱨᱮ \"ᱵᱟᱝᱠᱷᱟᱱ\", ᱮᱴᱟᱜ ᱞᱟᱹᱜᱤᱫ ᱫᱚ \"ᱥᱞᱮᱥ\"", "text": "ᱞᱮᱠᱷᱟ ᱡᱚᱠᱷᱚᱱ ᱵᱷᱟᱜᱽ ᱞᱟᱹᱜᱤᱫᱽ ᱫᱚ \"divided by\" ᱟᱨ ᱟᱹᱲᱟᱹ ᱡᱚᱠᱷᱚᱱ ᱫᱚ \"or\" ᱟᱨ ᱮᱴᱟᱜ ᱡᱟᱜᱟ ᱨᱮ ᱫᱚ \"slash\" ᱵᱮᱵᱷᱟᱨ ᱢᱮ ᱾"}
{"unnormalised": "", "normalised": "ᱫᱚ ᱨᱮᱯᱞᱮᱥ_ᱥᱞᱮᱥ (ᱢᱮᱪ):", "text": "ᱵᱚᱫᱚᱞ ᱥᱞᱮᱥ (ᱢᱮᱪ) :"}
{"unnormalised": "", "normalised": "pre = match.group(1)", "text": "pre = match.group(1)"}
{"unnormalised": "", "normalised": "post = match.group(2)", "text": "ᱯᱚᱥᱴ = ᱢᱮᱪ.ᱜᱨᱩᱯ(᱒)"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱨᱮ.ᱢᱮᱪ(r'\\b\\w+\\b', ᱯᱨᱤ) ᱟᱨ ᱨᱮ.ᱢᱮᱪ(r'\\b\\w+\\b', ᱯᱚᱥᱴ) ᱠᱟᱱᱟ ᱠᱷᱟᱱ:", "text": "ᱡᱩᱫᱤ ᱨᱮ.ᱢᱮᱪ(ᱟᱨ'\\ᱵ\\ᱣ+\\ᱵ', ᱯᱨᱤ) ᱟᱨ ᱨᱮ.ᱢᱮᱪ(ᱟᱨ'\\ᱵ\\ᱣ+\\ᱵ', ᱯᱚᱥᱴ):"}
{"unnormalised": "", "normalised": "return f\"{pre} ᱥᱮ {post}\"", "text": "f\"{pre} ᱥᱮ ᱫᱚ {post}\""}
{"unnormalised": "", "normalised": "ᱮᱱᱠᱷᱟᱱ (re.match(r'\\b[A-Z-]+\\b', pre) ᱥᱮ re.match(r'\\b[a-z-]+\\b', pre)) ᱟᱨ \\", "text": "ᱮᱱᱠᱷᱟᱱ (re.match(r'\\b[A-Z-]+\\b', pre) ᱥᱮ re.match(r'\\b[a-z-]+\\b', pre)) ᱟᱨ \\"}
{"unnormalised": "", "normalised": "(re.match(r'\\b[A-Z-]+\\b', post) ᱥᱮ re.match(r'\\b[a-z-]+\\b', post)) ᱟᱨ \\", "text": "(re.match(r'\\b[A-Z-]+\\b', post) ᱥᱮ re.match(r'\\b[a-z-]+\\b', post)) ᱟᱨ \\"}
{"unnormalised": "", "normalised": "(pre.isupper() != post.isupper()): # ᱮᱢᱮᱥᱟᱣ ᱢᱮᱥᱟᱣ ᱜᱷᱚᱴᱚᱱ ᱩᱫᱟᱹᱦᱟᱨᱚᱱ QA/Dev", "text": "(pre.isupper() != post.isupper()): # ᱢᱮᱥᱟᱞ ᱚᱠᱠᱷᱚᱨ ᱡᱮᱞᱮᱠᱟ QA/Dev"}
{"unnormalised": "", "normalised": "ńinda f\"{pre} slash {post}\"", "text": "ᱨᱩᱣᱟ.ᱲ ᱢᱮ {pre} ᱥᱞᱮᱥ {post}"}
{"unnormalised": "", "normalised": "ᱵᱟᱝᱠᱷᱟᱱ ᱫᱚᱺ", "text": "ᱵᱟᱝᱠᱷᱟᱱ:"}
{"unnormalised": "", "normalised": "ᱮᱢᱟᱹᱧ ᱨᱩᱣᱟᱹᱲ ᱢᱮ f\"{pre} ᱥᱞᱟᱥ ᱪᱤᱱᱦᱟᱹ {post}\" # ᱮᱴᱟᱜ ᱠᱮᱥ ᱞᱟᱹᱜᱤᱫ ᱥᱞᱟᱥ ᱪᱤᱱᱦᱟᱹ ᱰᱤᱯᱷᱚᱞᱴ ᱫᱚᱦᱚᱭ ᱢᱮ", "text": "ᱰᱟᱱᱰᱟᱨᱟ ᱯᱟᱹᱨᱤᱥ ᱞᱮᱠᱟᱛᱮ ᱰᱟᱱᱰᱟᱨᱟ ᱫᱚᱦᱚᱭ ᱢᱮ {pre} ᱥᱞᱮᱥ {post} // ᱮᱴᱟᱜ ᱠᱟᱹᱢᱤ ᱠᱚ ᱞᱟᱹᱜᱤᱫ ᱰᱟᱱᱰᱟᱨᱟ ᱜᱮ ᱵᱟᱪᱷᱟᱣ ᱢᱮ"}
{"unnormalised": "", "normalised": "text = re.sub(r'(\\S)\\s*/\\s*(\\S)', replace_slash, text) # ᱨᱮᱡᱮᱠᱥ ᱥᱟᱶ ᱵᱚᱫᱚᱞ ᱦᱩᱭᱮᱱᱟ ᱡᱟᱦᱟᱸ ᱫᱚ ᱯᱟᱹᱪᱷᱞᱟᱹ ᱟᱨ ᱢᱟᱲᱟᱝ ᱧᱮᱞ ᱟᱹᱜᱩᱭᱟ", "text": "ᱨᱮᱜᱮᱠᱥ ᱥᱟᱶᱛᱮ ᱵᱚᱫᱚᱞ ᱠᱮᱫᱟ ᱡᱟᱦᱟᱸ ᱫᱚ ᱯᱟᱹᱪᱷᱞᱟᱹ ᱟᱨ ᱢᱟᱲᱟᱝ ᱨᱮᱱᱟᱜ ᱠᱟᱛᱷᱟ ᱠᱚ ᱧᱮᱞ ᱟᱹᱜᱩᱭᱟ / re.sub(r'(\\S)\\s*/\\s*(\\S)', replace_slash, text) #"}
{"unnormalised": "", "normalised": "ᱫᱚᱭᱟᱠᱟᱛᱮ ᱱᱚᱶᱟ ᱤᱝᱞᱤᱥ ᱴᱮᱠᱥᱴ ᱫᱚ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱢᱮ, ພᱷᱟᱹᱭᱜᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ; ᱮᱛᱚᱦᱚᱵ ᱜᱟᱨ ᱵᱮᱱᱟᱣ ᱟᱨ ᱡᱟᱭᱜᱟ ᱫᱚ ᱵᱟᱧᱪᱟᱣ ᱠᱟᱛᱮ ᱫᱚᱦᱚᱭ ᱢᱮ᱾", "text": ""}
{"unnormalised": "", "normalised": "# ᱨᱩᱞ ᱙: ᱥᱯᱮᱥ ᱠᱚ ᱥᱚᱢᱟᱱ ᱢᱮ", "text": "# ᱙: ᱥᱟᱦᱟ ᱠᱚ ᱥᱚᱢᱟᱱ ᱛᱚᱨᱟᱣ ᱢᱮ"}
{"unnormalised": "", "normalised": "text = re.sub(r'\\s+', ' ', text).strip()", "text": "text = re.sub(r'\\s+', ' ', text).strip()\n```\ntext = re.sub(r'\\s+', ' ', text).strip() ᱫᱚ ᱾\n```"}
{"unnormalised": "", "normalised": "ᱫᱚᱭᱟᱠᱟᱛᱮ ᱱᱚᱶᱟ ᱤᱝᱞᱤᱥ ᱴᱮᱠᱥᱴ ᱫᱚ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱢᱮ, ພᱷᱟᱹᱭᱜᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ; ᱮᱛᱚᱦᱚᱵ ᱜᱟᱨ ᱵᱮᱱᱟᱣ ᱟᱨ ᱡᱟᱭᱜᱟ ᱫᱚ ᱵᱟᱧᱪᱟᱣ ᱠᱟᱛᱮ ᱫᱚᱦᱚᱭ ᱢᱮ᱾", "text": ""}
{"unnormalised": "", "normalised": "ᱨᱩᱣᱟᱹᱲ ᱢᱮ ᱚᱱᱟ ᱚᱞ ᱠᱟᱛᱷᱟ", "text": "ᱱᱚᱣᱟ ᱤᱝᱞᱤᱥ ᱚᱞ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱢᱮ᱾ ພᱩᱭᱱᱚᱜ ᱛᱚᱨᱡᱚᱢᱟ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ; ᱢᱩᱲ ᱫᱷᱟᱹᱲ ᱨᱮᱭᱟᱜ ᱵᱟᱹᱜᱤ ᱟᱨ ᱴᱷᱟᱶ ᱫᱚ ᱵᱟᱧᱪᱟᱣ ᱫᱚᱦᱚᱭ ᱢᱮ᱾\n\nᱚᱞ ᱨᱩᱣᱟᱹᱲ ᱢᱮ᱾"}
{"unnormalised": "", "normalised": "```santali\ndef process_folder(input_folder, output_folder):\n```", "text": "```santali\ndef process_folder(input_folder, output_folder):\n```"}
{"unnormalised": "", "normalised": "ᱵᱟᱝ ᱥᱚᱢᱟᱱ ᱟᱠᱟᱱ ᱯᱷᱟᱭᱤᱞᱠᱚ = []", "text": "ᱵᱟᱝ ᱥᱟᱫᱷᱟᱨᱚᱱ ᱯᱷᱟᱭᱤᱞ ᱠᱚ = []"}
{"unnormalised": "", "normalised": "ᱫᱚᱭᱟᱠᱟᱛᱮ ᱱᱚᱶᱟ ᱤᱝᱞᱤᱥ ᱴᱮᱠᱥᱴ ᱫᱚ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱢᱮ, ພᱷᱟᱹᱭᱜᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ; ᱮᱛᱚᱦᱚᱵ ᱜᱟᱨ ᱵᱮᱱᱟᱣ ᱟᱨ ᱡᱟᱭᱜᱟ ᱫᱚ ᱵᱟᱧᱪᱟᱣ ᱠᱟᱛᱮ ᱫᱚᱦᱚᱭ ᱢᱮ᱾", "text": ""}
{"unnormalised": "", "normalised": "ᱢᱩᱞ ᱞᱟᱹᱜᱤᱫ, ᱰᱤᱨᱮᱠᱴᱚᱨᱤ ᱟᱨ ᱯᱷᱟᱭᱤᱞ ᱠᱚ ᱚᱥ.ᱣᱟᱠ ᱨᱮ (ᱤᱱᱯᱩᱴ_ᱯᱷᱳᱞᱰᱟᱨ):", "text": "os.walk(input_folder) ᱨᱮ ᱧᱟᱢᱚᱜ ᱠᱟᱱ root, dirs, ᱟᱨ files ᱠᱚ ᱞᱟᱹᱜᱤᱫ:"}
{"unnormalised": "", "normalised": "relative_path = os.path.relpath(root, input_folder)", "text": "`relative_path` = `os.path.relpath`(root, input_folder)"}
{"unnormalised": "", "normalised": "```\n        output_root = os.path.join(output_folder, relative_path)\n```", "text": "output_root = os.path.join(output_folder, relative_path)"}
{"unnormalised": "", "normalised": "os.makedirs(output_root, exist_ok=True)", "text": "os.makedirs(output_root, exist_ok=True)"}
{"unnormalised": "", "normalised": "ᱮᱴᱟᱜ ᱯᱷᱟᱭᱤᱞ ᱧᱩᱛᱩᱢ ᱫᱚ ᱯᱷᱟᱭᱤᱞ ᱠᱟᱱᱟ:", "text": "file_name ᱞᱟᱹᱜᱤᱫ ᱛᱮ files ᱨᱮ:"}
{"unnormalised": "", "normalised": "input_file_path = os.path.join(root, file_name)", "text": "ᱤᱱᱯᱩᱴ_ᱯᱷᱟᱭᱤᱞ_ᱯᱟᱛᱷ = os.path.join(ᱨᱩᱴ, ᱯᱷᱟᱭᱤᱞ_ᱧᱩᱛᱩᱢ)"}
{"unnormalised": "", "normalised": "output_file_path = os.path.join(output_root, file_name)", "text": "output_file_path = os.path.join(output_root, file_name)"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱯᱷᱟᱭᱤᱞ ᱧᱩᱛᱩᱢ ᱫᱚ .txt ᱛᱮ ᱢᱩᱪᱟᱹᱫᱚᱜᱼᱟ ᱾", "text": "ᱡᱩᱫᱤ ᱯᱷᱟᱭᱤᱞ_ᱧᱩᱛᱩᱢ ᱫᱚ '.txt' ᱛᱮ ᱢᱩᱪᱟᱹᱫᱚᱜᱼᱟ ᱮᱱᱠᱷᱟᱱ:"}
{"unnormalised": "", "normalised": "ᱪᱮᱥᱴᱟ ᱢᱮ:", "text": "ᱠᱩᱨᱩᱢᱩᱴᱩ ᱢᱮ:"}
{"unnormalised": "", "normalised": "`with open(input_file_path, 'r', encoding='utf-8') as f_in:`", "text": "`input_file_path`, 'r', 'utf-8') ᱢᱮᱱᱟᱜ ᱯᱷᱟᱭᱤᱞ ᱥᱟᱶᱛᱮ"}
{"unnormalised": "", "normalised": "content = f_in.read()", "text": "content = f_in ᱦᱚᱛᱮᱛᱮ ᱯᱟᱲᱦᱟᱣ ᱮᱱᱟ ᱾"}
{"unnormalised": "", "normalised": "I am not able to provide a translation without the English text. Please provide the English text you would like me to translate into Santali.", "text": ""}
{"unnormalised": "", "normalised": "normalized_content = normalize_text(content)", "text": "normalized_content = normalize_text(content)"}
{"unnormalised": "", "normalised": "I am not able to provide a translation without the English text. Please provide the English text you would like me to translate into Santali.", "text": ""}
{"unnormalised": "", "normalised": "`output_file_path` ᱦᱚᱨ ᱨᱮ ᱠᱷᱩᱞᱟᱹᱣ ᱠᱟᱛᱮᱜ, 'w' ᱢᱳᱰ ᱨᱮ ᱟᱨ 'utf-8' ᱮᱱᱠᱳᱰᱤᱝ ᱥᱟᱶ ᱯᱷᱟᱭᱤᱞ ᱮᱢ ᱟᱣᱩᱴ ᱞᱮᱠᱟᱛᱮ:", "text": "```santali\n```"}
{"unnormalised": "", "normalised": "f_out.write(normalized_content)", "text": "f_out.write(normalized_content)"}
{"unnormalised": "", "normalised": "ᱟᱫᱚ ᱵᱮᱜᱚᱨ ᱵᱷᱟᱜᱮ ᱵᱟᱝ ᱦᱩᱭ ᱞᱮᱱᱠᱷᱟᱱ ᱫᱚ (Exception) e ᱦᱩᱭᱩᱜᱼᱟ ᱾", "text": "ᱵᱟᱝᱠᱷᱟᱱ ᱦᱩᱭ ᱟᱠᱟᱱ Exception ᱫᱚ ᱮ ᱞᱮᱠᱟᱛᱮ:"}
{"unnormalised": "", "normalised": "``{input_file_path}`` ᱨᱮᱱᱟᱜ ᱠᱟᱹᱢᱤ ᱦᱩᱭ ᱚᱠᱛᱮ ᱮᱴᱠᱮᱴᱚᱬᱮ ᱦᱩᱭᱮᱱᱟ: {e}", "text": "```\nᱮᱲᱮ ᱦᱩᱭᱮᱱᱟ {input_file_path} ᱠᱟᱹᱢᱤ ᱨᱮ: {e}\n```"}
{"unnormalised": "", "normalised": "unnormalized_files.append(input_file_path)", "text": "unnormalized_files.append(input_file_path)"}
{"unnormalised": "", "normalised": "# ᱡᱩᱫᱤ ᱥᱟᱹᱨᱤ ᱵᱟᱝ ᱦᱩᱭᱩᱜᱼᱟ ᱮᱱᱠᱷᱟᱱ ᱚᱨᱤᱡᱤᱱᱟᱞ ᱯᱷᱟᱭᱤᱞ ᱠᱚᱯᱤ ᱢᱮ", "text": "ᱯᱩᱭᱞᱩ ᱚᱨᱤᱡᱤᱱᱟᱞ ᱯᱷᱟᱭᱤᱞ ᱠᱚᱯᱤ ᱢᱮ, ᱡᱩᱫᱤ ᱱᱚᱨᱢᱟᱞᱟᱭᱡᱮᱥᱚᱱ ᱵᱟᱝ ᱥᱟᱹᱠᱷᱭᱟᱹᱛ ᱠᱟᱱᱟ ᱾"}
{"unnormalised": "", "normalised": "`output_file_path` ᱦᱚᱨ ᱨᱮ ᱠᱷᱩᱞᱟᱹᱣ ᱠᱟᱛᱮᱜ, 'w' ᱢᱳᱰ ᱨᱮ ᱟᱨ 'utf-8' ᱮᱱᱠᱳᱰᱤᱝ ᱥᱟᱶ ᱯᱷᱟᱭᱤᱞ ᱮᱢ ᱟᱣᱩᱴ ᱞᱮᱠᱟᱛᱮ:", "text": "```santali\n```"}
{"unnormalised": "", "normalised": "f_out.write(content)", "text": "f_out.write(ᱢᱮᱱᱛᱮᱫ ᱚᱞ ᱢᱮ)"}
{"unnormalised": "", "normalised": "ᱵᱟᱝᱠᱷᱟᱱ:", "text": "ᱵᱟᱝᱠᱷᱟᱱ:"}
{"unnormalised": "", "normalised": "# ᱵᱟᱝ -.txt ᱯᱷᱟᱭᱤᱞ ᱠᱚᱫᱚ ᱵᱟᱝ ᱵᱚᱫᱚᱞ ᱠᱟᱛᱮ ᱠᱚᱯᱤ ᱢᱮ", "text": "# ᱠᱟᱹᱯᱤ ᱵᱟᱝ-.txt ᱯᱷᱟᱭᱤᱞ ᱠᱚ ᱵᱚᱫᱚᱞ ᱵᱟᱝ ᱠᱟᱛᱮ ᱜᱮ"}
{"unnormalised": "", "normalised": "ᱪᱮᱥᱴᱟ ᱢᱮ:", "text": "ᱠᱩᱨᱩᱢᱩᱴᱩ ᱢᱮ:"}
{"unnormalised": "", "normalised": "`with open(input_file_path, 'rb') as f_in, open(output_file_path, 'wb') as f_out:`", "text": "```santali\n```"}
{"unnormalised": "", "normalised": "f_out.write(f_in.read())", "text": "f_out.write(f_in.read())"}
{"unnormalised": "", "normalised": "ᱟᱫᱚ ᱵᱮᱜᱚᱨ ᱵᱷᱟᱜᱮ ᱵᱟᱝ ᱦᱩᱭ ᱞᱮᱱᱠᱷᱟᱱ ᱫᱚ (Exception) e ᱦᱩᱭᱩᱜᱼᱟ ᱾", "text": "ᱵᱟᱝᱠᱷᱟᱱ ᱦᱩᱭ ᱟᱠᱟᱱ Exception ᱫᱚ ᱮ ᱞᱮᱠᱟᱛᱮ:"}
{"unnormalised": "", "normalised": "ᱮᱴᱟᱜ ᱴᱮᱠᱥᱴ ᱵᱟᱝ ᱯᱷᱟᱭᱤᱞ {input_file_path} ᱠᱚᱯᱤ ᱨᱮ ᱜᱟᱹᱞᱛᱤ: {e}", "text": "``ᱛᱚᱝᱜᱮ ᱵᱟᱝ ᱠᱟᱱ ᱴᱮᱠᱥᱴ ᱯᱷᱟᱭᱤᱞ {input_file_path} ᱠᱚᱯᱤ ᱨᱮ ᱮᱲᱮ ᱧᱮᱞ ᱮᱱᱟ: {e}``"}
{"unnormalised": "", "normalised": "unnormalized_files.append(input_file_path)", "text": "unnormalized_files.append(input_file_path)"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱵᱟᱝ ᱥᱚᱢᱟᱱ ᱟᱠᱟᱱ ᱯᱷᱟᱭᱤᱞ ᱠᱚ ᱢᱮᱱᱟᱜᱼᱟ ᱾", "text": "ᱡᱩᱫᱤ ᱵᱟᱝ ᱢᱟᱱᱟᱣᱟᱠᱟᱱ ᱯᱷᱟᱭᱤᱞ ᱠᱚ ᱢᱮᱱᱟᱜᱼᱟ ᱺ"}
{"unnormalised": "", "normalised": "ᱪᱷᱟᱯᱟ ᱢᱮ(\"\\nᱚᱱᱟ ᱯᱷᱟᱭᱤᱞ ᱠᱚ ᱡᱟᱦᱟᱸ ᱫᱚ ᱯᱩᱨᱟᱹ ᱵᱟᱝ ᱥᱚᱢᱟᱱ ᱥᱮ ᱠᱚᱯᱤ ᱦᱩᱭ ᱫᱟᱲᱮᱭᱟᱠᱟᱱᱟ ᱵᱷᱩᱞ ᱠᱷᱟᱹᱛᱤᱨ:\")", "text": "ᱪᱷᱟᱯᱟ ᱢᱮ(\"\\nᱯᱷᱟᱭᱤᱞ ᱠᱚ ᱡᱟᱦᱟᱸ ᱯᱩᱨᱟᱹ ᱵᱷᱟᱹᱜᱤ ᱵᱟᱝ ᱦᱩᱭ ᱫᱟᱲᱮᱭᱟᱫᱟ ᱥᱮ ᱠᱚᱯᱤ ᱦᱩᱭ ᱫᱟᱲᱮᱭᱟᱫᱟ ᱵᱷᱩᱞ ᱠᱷᱟᱹᱛᱤᱨ ᱛᱮ:\")"}
{"unnormalised": "", "normalised": "f ᱞᱟᱹᱜᱤᱫ ᱡᱟᱦᱟᱸ ᱵᱟᱝ ᱢᱟᱱᱚᱠᱟᱱ ᱯᱷᱟᱭᱤᱞ ᱠᱚ:", "text": "ᱮᱯᱷ ᱤᱱ ᱟᱱᱱᱚᱨᱢᱟᱞᱟᱭᱤᱡᱽᱰ_ᱯᱷᱟᱭᱤᱞᱥ:"}
{"unnormalised": "", "normalised": "ᱯᱨᱤᱸᱴ (ᱮᱯᱷ)", "text": "ᱪᱷᱟᱯᱟ ᱢᱮ (f)"}
{"unnormalised": "", "normalised": "ᱧᱮᱞ ᱞᱟᱹᱜᱤᱫ ᱫᱟᱹᱭᱠᱟᱹ ᱵᱮᱵᱷᱟᱨ:", "text": "ᱧᱮᱞ ᱞᱟᱹᱜᱤᱫ ᱫᱟᱹᱭᱠᱟᱹ ᱵᱮᱵᱷᱟᱨ:"}
{"unnormalised": "", "normalised": "ᱫᱮᱠᱷᱟᱣ ᱞᱟᱹᱜᱤᱫ ᱠᱤᱪᱷᱩ ᱜᱚᱯᱚᱲᱤᱭᱟᱹ ᱰᱮᱴᱟ ᱵᱮᱱᱟᱣ ᱢᱮ᱾", "text": "ᱫᱮᱠᱷᱟᱣ ᱞᱟᱹᱜᱤᱫ ᱠᱤᱪᱷᱩ ᱜᱚᱯᱚᱲᱤᱭᱟᱹ ᱰᱮᱴᱟ ᱵᱮᱱᱟᱣ ᱢᱮ᱾"}
{"unnormalised": "", "normalised": "ᱡᱩᱫᱤ ᱧᱩᱛᱩᱢ == \"__ᱢᱩᱬᱩᱛ__\":", "text": "ᱡᱩᱫᱤ ᱧᱩᱛᱩᱢ == \"__ᱢᱩᱬᱩᱛ__\":"}
{"unnormalised": "", "normalised": "ᱵᱮᱱᱟᱣ ᱢᱮ ᱢᱤᱫᱴᱟᱹᱝ ᱰᱟᱹᱢᱢᱤ ᱰᱮᱴᱟᱥᱮᱴ", "text": "# ᱵᱮᱱᱟᱣ ᱢᱤᱫᱴᱟᱝ ᱫᱷᱩᱢᱠᱟᱹ ᱰᱮᱴᱟᱥᱮᱴ"}
{"unnormalised": "", "normalised": "os.makedirs('dataset/subfolder1', exist_ok=True)", "text": "os.makedirs('dataset/subfolder1', exist_ok=True)"}
{"unnormalised": "", "normalised": "os.makedirs('dataset/subfolder2', exist_ok=True)", "text": "os.makedirs('dataset/subfolder2', exist_ok=True)"}
{"unnormalised": "", "normalised": "`dataset/file1.txt' ᱨᱮ ᱚᱞ ᱞᱟᱹᱜᱤᱫ ᱞᱮᱠᱟᱛᱮ `f' ᱥᱟᱶ ᱡᱷᱤᱡ ᱢᱮ :", "text": "`with open('dataset/file1.txt', 'w') as f:` ᱨᱮᱱᱟᱜ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱫᱚ ᱱᱚᱝᱠᱟ ᱦᱩᱭᱩᱜᱼᱟ:\n\n`with open('dataset/file1.txt', 'w') as f:` ᱨᱮᱱᱟᱜ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱫᱚ ᱱᱚᱝᱠᱟ ᱦᱩᱭᱩᱜᱼᱟ:\n\n`ᱡᱚᱠᱷᱚᱱ ᱟᱵᱚ 'dataset/file1.txt' ᱫᱚ 'w' ᱢᱳᱰ ᱛᱮ ᱠᱷᱩᱞᱟᱹᱣᱟ ᱟᱨ ᱚᱱᱟ ᱫᱚ f ᱦᱤᱥᱟᱹᱵᱽ ᱛᱮ ᱧᱩᱛᱩᱢᱟ:`"}
{"unnormalised": "", "normalised": "f.write(\"ᱱᱟᱥᱟ ᱯᱨᱚᱡᱮᱠᱴ ᱫᱚ $20B ᱯᱷᱟᱱᱰᱤᱝ ᱧᱟᱢ ᱟᱠᱟᱫᱟ᱾ ᱱᱚᱣᱟ ᱫᱚ ᱑᱐/᱐᱙/᱒᱐᱒᱔ ᱨᱮ ᱮᱦᱚᱵ ᱞᱮᱱᱟ᱾ ᱡᱤᱰᱤᱯᱤ ᱜᱨᱚᱣᱛᱷ ᱫᱚ ~᱕% ᱛᱟᱦᱮᱸ ᱠᱟᱱᱟ᱾ ᱩᱱᱤ ᱫᱚ ᱒.᱕ ᱠᱮᱡᱤ ᱪᱟᱣᱞᱮ ᱞᱟᱜᱟᱜ ᱟᱭᱟ᱾ $᱒᱐.᱕᱐ ᱫᱚ ᱫᱟᱢ ᱠᱟᱱᱟ᱾ ᱒+᱒=᱔᱾ ᱟᱨᱴ/ᱠᱨᱟᱯᱷᱴ ᱫᱚ ᱱᱟᱯᱟᱭ ᱜᱮᱭᱟ᱾ ᱠᱭᱩᱮ/ᱰᱮᱵᱷ ᱴᱤᱢ᱾\\n\")", "text": "f.write(\"ᱱᱮᱥᱟ ᱯᱨᱚᱡᱮᱠᱴ ᱫᱚ ᱒᱐B ᱰᱚᱞᱟᱨ ᱯᱷᱚᱱᱰᱤᱝ ᱧᱟᱢ ᱠᱮᱫᱟ᱾ ᱱᱚᱣᱟ ᱫᱚ ᱑᱐/᱐᱙/᱒᱐᱒᱔ ᱠᱷᱚᱱ ᱮᱦᱚᱵ ᱟᱠᱟᱱᱟ᱾ ᱡᱤᱰᱤᱯᱤ ᱜᱨᱚᱛᱷ ᱫᱚ ~᱕% ᱛᱟᱦᱮᱸ ᱠᱟᱱᱟ᱾ ᱩᱱᱤ ᱫᱚ ᱒.᱕kg ᱪᱟᱣᱞᱮ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ᱾ ᱒᱐.᱕᱐ ᱰᱚᱞᱟᱨ ᱫᱚ ᱫᱟᱢ ᱠᱟᱱᱟ᱾ ᱒+᱒=᱔᱾ ᱟᱨᱴ/ᱠᱨᱟᱯᱴ ᱫᱚ ᱱᱟᱯᱟᱭ ᱜᱮᱭᱟ᱾ ᱠᱤᱣᱮ/ᱰᱮᱵᱷ ᱴᱤᱢ᱾\\n\")"}
{"unnormalised": "", "normalised": "f.write(\"ᱤᱱᱴᱤᱜᱽᱨᱟᱞ ∫ x^2 dx ᱐ ᱠᱷᱚᱱ ᱑ ᱫᱷᱟᱹᱵᱤᱡᱽ ᱾ ᱱᱚᱣᱟ ᱨᱮᱭᱟᱜ ᱢᱩᱞ ᱫᱚ πr^2 ᱾ x^n ᱟᱨ x_i ᱫᱚ ᱞᱟᱹᱠᱛᱤᱭᱟᱱᱟ ᱾ ᱦᱚᱲ ᱮᱞ ᱨᱮᱭᱟᱜ ᱓/᱔ ᱾ ᱵᱟᱦᱨᱮ ᱨᱮ ᱒᱕°C ᱾ ᱥᱯᱤᱰ ᱫᱚ ᱑᱐᱐km/hr ᱛᱟᱦᱮᱸ ᱠᱟᱱᱟ ᱾ GDP ᱫᱚ ᱑᱐M ᱾ ᱑/᱒ kg.\\n\")", "text": "f.write(\"ᱤᱱᱴᱤᱜᱽᱨᱟᱞ ∫ x^2 dx ᱐ ᱠᱷᱚᱱ ᱑ ᱫᱷᱟᱹᱵᱤᱡᱽ᱾ ᱱᱚᱶᱟ ᱨᱮᱭᱟᱜ ᱢᱟᱹᱱ ᱫᱚ πr^2 ᱠᱟᱱᱟ᱾ x^n ᱟᱨ x_i ᱫᱚ ᱞᱟᱹᱠᱛᱤᱭᱟᱱ ᱠᱟᱱᱟ᱾ ᱦᱚᱲ ᱮᱞ ᱨᱮᱭᱟᱜ ᱓/᱔ ᱦᱤᱸᱥ᱾ ᱵᱟᱦᱨᱮ ᱨᱮ ᱒᱕°C ᱾ ᱜᱚᱴᱟᱜ ᱫᱚ ᱑᱐᱐ km/hr ᱛᱟᱦᱮᱸ ᱠᱟᱱᱟ᱾ ᱡᱤᱰᱤᱯᱤ ᱫᱚ ᱑᱐M ᱠᱟᱱᱟ᱾ ᱑/᱒ ᱠᱮᱡᱤ᱾\\n\")"}
{"unnormalised": "", "normalised": "f. ᱚᱞ ᱢᱮ (\"Special symbols: @ # & * ≠ ≤ ≥. ᱱᱚᱣᱟ ᱫᱚ ᱙᱙ ᱴᱟᱜ ᱮᱴᱠᱮᱴᱚᱬᱮ ᱠᱟᱱᱟ. U.S.A. ᱫᱚ ᱱᱟᱯᱟᱭ ᱜᱮᱭᱟ. ᱗ ᱢᱟᱦᱟᱸ. ᱒᱐᱒᱔-᱐᱙-᱑᱐ ᱨᱤᱯᱳᱨᱴ. ᱑᱐cm, ᱑᱐᱐ml. ᱩᱱᱤ ᱕km ᱛᱟᱲᱟᱢ ᱠᱮᱫᱟ. √9 ᱫᱚ ᱯᱮᱭᱟ. ᱚᱛ ᱦᱟᱥᱟ ᱫᱚ ᱑᱐᱐sqm. ᱱᱚᱣᱟ ᱫᱚ ᱫᱟᱹᱭᱠᱟᱹ ᱠᱟᱱᱟ x^3 ᱨᱮᱭᱟᱜ. ᱞᱚᱞᱚ ᱫᱚ ᱑᱐ ᱰᱤᱜᱽᱨᱤ ᱠᱟᱱᱟ. ᱤᱧᱟᱜ ᱠᱚᱢᱯᱩᱴᱚᱨ ᱨᱮ ᱑TB ᱥᱴᱳᱨᱮᱡᱽ ᱢᱮᱱᱟᱜᱼᱟ. ᱯᱷᱨᱤᱠᱩᱣᱮᱱᱥᱤ ᱫᱚ ᱕᱐Hz.\")", "text": "f.write(\"ᱵᱤᱥᱮᱥ ᱪᱤᱱᱦᱟᱹ: @ # & * ≠ ≤ ≥. ᱱᱚᱣᱟ ᱫᱚ ᱙᱙ ᱜᱚᱴᱟᱝ ᱮᱴᱠᱮᱴᱚᱬᱮ ᱠᱟᱱᱟ. U.S.A. ᱫᱚ ᱱᱟᱯᱟᱭ ᱜᱮᱭᱟ. ᱗ ᱢᱟᱦᱟᱸ. ᱒᱐᱒᱔-᱐᱙-᱑᱐ ᱨᱤᱯᱳᱨᱴ. ᱑᱐cm, ᱑᱐᱐ml. ᱩᱱᱤ ᱕km ᱮ ᱛᱟᱲᱟᱢ ᱠᱮᱫᱟ. √᱙ ᱫᱚ ᱯᱮᱭᱟ. ᱡᱟᱭᱜᱟ ᱫᱚ ᱑᱐᱐sqm. ᱱᱚᱣᱟ ᱫᱚ ᱢᱤᱫ ᱩᱫᱟᱦᱚᱨᱚᱱ ᱠᱟᱱᱟ x^᱓. ᱞᱚᱞᱚ ᱫᱚ ᱑᱐ ᱰᱤᱜᱽᱨᱤ ᱠᱟᱱᱟ. ᱤᱧᱟᱜ ᱠᱚᱢᱯᱩᱭᱴᱟᱨ ᱨᱮ ᱑TB ᱥᱴᱚᱨᱮᱡᱽ ᱢᱮᱱᱟᱜᱼᱟ. ᱯᱷᱨᱤᱠᱩᱣᱮᱱᱥᱤ ᱫᱚ ᱕᱐Hz ᱠᱟᱱᱟ.\")"}
{"unnormalised": "", "normalised": "ᱫᱚᱭᱟᱠᱟᱛᱮ ᱱᱚᱶᱟ ᱤᱝᱞᱤᱥ ᱴᱮᱠᱥᱴ ᱫᱚ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱮ ᱛᱚᱨᱡᱚᱢᱟ ᱢᱮ, ພᱷᱟᱹᱭᱜᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱜᱮ ᱨᱩᱣᱟᱹᱲ ᱢᱮ; ᱮᱛᱚᱦᱚᱵ ᱜᱟᱨ ᱵᱮᱱᱟᱣ ᱟᱨ ᱡᱟᱭᱜᱟ ᱫᱚ ᱵᱟᱧᱪᱟᱣ ᱠᱟᱛᱮ ᱫᱚᱦᱚᱭ ᱢᱮ᱾", "text": ""}
{"unnormalised": "", "normalised": "```santali\n    'dataset/subfolder1/file2.txt', 'w' ᱞᱮᱠᱟᱛᱮ ᱠᱷᱩᱞᱟᱹᱣ ᱠᱟᱛᱮ f ᱞᱮᱠᱟᱛᱮ:\n```", "text": "`dataset/subfolder1/file2.txt`, ᱨᱮ ᱚᱞ ᱞᱟᱹᱜᱤᱫ ᱛᱮ ᱡᱮᱞᱮᱠᱟ ᱮᱯᱷ (f):"}
{"unnormalised": "", "normalised": "f.write(\"ᱟᱨ ᱢᱤᱫᱴᱟᱝ ᱴᱮᱥᱴ: ᱑᱒᱓᱔᱕ ᱰᱚᱞᱟᱨ᱾ ᱢᱟᱹᱦᱤᱛ ᱫᱚ ᱐᱑-᱐᱑-᱒᱐᱒᱓ ᱠᱟᱱᱟ᱾ ᱟᱵᱚ ᱕᱐᱐ ᱮᱢᱡᱤ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ᱾ ᱠᱚᱱᱟ ᱫᱚ ᱔᱕° ᱠᱟᱱᱟ᱾ ᱱᱚᱣᱟ ᱫᱚ ᱱᱚᱨᱢᱟᱞᱟᱭᱤᱡᱽ ᱵᱷᱟᱹᱜᱤ ᱞᱮᱠᱟᱛᱮ ᱦᱩᱭᱩᱜ ᱢᱟ᱾ ᱙᱙᱙᱙᱙᱙᱙᱙᱙᱙.᱙᱙ ᱵᱟᱵᱚᱛ ᱪᱮᱫ ᱪᱤᱠᱟᱹᱜᱼᱟ?\\n\")", "text": "f.write(\"ᱟᱨ ᱢᱤᱫᱴᱟᱝ ᱴᱮᱥᱴ: ᱑᱒᱓᱔᱕ ᱰᱚᱞᱟᱨ᱾ ᱢᱟᱹᱦᱤᱛ ᱫᱚ ᱐᱑-᱐᱑-᱒᱐᱒᱓ ᱠᱟᱱᱟ᱾ ᱟᱵᱚ ᱕᱐᱐ ᱢᱤᱞᱤᱜᱨᱟᱢ ᱞᱟᱹᱠᱛᱤ ᱠᱟᱱᱟ᱾ ᱠᱚᱬ ᱫᱚ ᱔᱕° ᱠᱟᱱᱟ᱾ ᱱᱚᱣᱟ ᱫᱚ ᱵᱟᱹᱲᱛᱤ ᱞᱮᱠᱟᱛᱮ ᱥᱟᱢᱟᱱ ᱞᱟᱹᱠᱛᱤᱜᱼᱟ᱾ ᱙᱙᱙᱙᱙᱙᱙᱙᱙᱙.᱙᱙ ᱵᱟᱵᱚᱛ ᱪᱮᱫ ᱢᱮᱱᱟᱜᱼᱟ?\\n\")"}
{"unnormalised": "", "normalised": "f.write(\"ᱱᱚᱣᱟ ᱫᱚ ᱢᱤᱫ X-Y-Z ᱴᱮᱥᱴ ᱠᱟᱱᱟ᱾ ᱱᱚᱣᱟ ᱫᱚ A.B.C. ᱚᱞ ᱠᱟᱱᱟ᱾ ᱒᱐᱐V, ᱑᱐A, ᱕KW᱾ x_max ᱟᱨ y_min ᱢᱚᱦᱚᱛ ᱵᱚᱫᱚᱞ ᱠᱟᱱᱟ᱾\")", "text": "f.write(\"ᱱᱚᱣᱟ ᱫᱚ ᱢᱤᱫ X-Y-Z ᱴᱮᱥᱴ ᱠᱟᱱᱟ᱾ ᱱᱚᱣᱟ ᱫᱚ A.B.C. ᱚᱞ ᱠᱟᱱᱟ᱾ ᱒᱐᱐V, ᱑᱐A, ᱕KW. x_max ᱟᱨ y_min ᱫᱚ ᱢᱩᱠᱷᱭᱟᱹ ᱵᱚᱫᱚᱞᱚᱜ ᱠᱟᱱᱟ᱾\")"}
{"unnormalised": "", "normalised": "`with open('dataset/subfolder2/image.jpg', 'w') as f:` ᱾ # ᱰᱟᱢᱢᱤ ᱵᱟᱝᱼᱴᱮᱠᱥᱴ ᱯᱷᱟᱭᱤᱞ", "text": "`with open('dataset/subfolder2/image.jpg', 'w') as f: # Dummy non-text file` ᱨᱮᱱᱟᱜ ᱥᱟᱱᱛᱟᱲᱤ ᱛᱚᱨᱡᱚᱢᱟ ᱫᱚ ᱱᱚᱝᱠᱟ ᱦᱩᱭᱩᱜᱼᱟ:\n\n`with open('dataset/subfolder2/image.jpg', 'w') as f: # ᱵᱮᱱᱟᱣ ᱟᱠᱟᱫ ᱵᱟᱝ ᱚᱞᱚᱜ ᱯᱷᱟᱭᱤᱞ`"}
{"unnormalised": "", "normalised": "f. ᱚᱞ ᱢᱮ (\"ᱱᱚᱣᱟ ᱫᱚ ᱚᱞ ᱯᱷᱟᱭᱤᱞ ᱫᱚ ᱵᱟᱝ ᱠᱟᱱᱟ᱾\")", "text": "f.write(\"ᱱᱚᱣᱟ ᱫᱚ ᱴᱮᱠᱥᱴ ᱯᱷᱟᱭᱤᱞ ᱫᱚ ᱵᱟᱝ ᱠᱟᱱᱟ᱾\")"}
{"unnormalised": "", "normalised": "input_folder = 'dataset'", "text": "input_folder = 'dataset'"}
{"unnormalised": "", "normalised": "output_folder = 'dataset_normalized'", "text": "output_folder = 'dataset_normalized'"}
{"unnormalised": "", "normalised": "process_folder(input_folder, output_folder)", "text": "process_folder(input_folder, output_folder)"}
{"unnormalised": "", "normalised": "ᱪᱷᱟᱯᱟ ᱢᱮ (f\"\\nᱥᱚᱢᱟᱱᱤᱠᱟᱨᱚᱱ ᱯᱩᱨᱟᱹᱣᱮᱱᱟ᱾ '{output_folder}' ᱨᱮ ᱚᱨᱡᱚ ᱠᱚ ᱧᱮᱞ ᱢᱮ᱾\")", "text": "ᱪᱷᱟᱯᱟ ᱠᱟᱛᱮ ᱩᱫᱩᱜ ᱢᱮ (f\"\\nᱥᱚᱢᱟᱱ ᱵᱮᱱᱟᱣ ᱢᱩᱪᱟᱹᱫ ᱮᱱᱟ᱾ '{output_folder}' ᱨᱮ ᱚᱨᱡᱚ ᱧᱮᱞ ᱢᱮ᱾\")"}
{"unnormalised": "", "normalised": "ᱪᱷᱟᱯᱟ ᱢᱮ (\"Normalized ᱯᱷᱟᱭᱤᱞ ᱨᱮᱭᱟᱜ ᱫᱟᱹᱭᱠᱟᱹ (file1.txt):\")", "text": "ᱪᱷᱟᱯᱟ ᱢᱮ (\"Normalized ᱯᱷᱟᱭᱤᱞ ᱠᱚᱱᱴᱮᱱᱴ ᱨᱮᱭᱟᱜ ᱱᱩᱢᱩᱱᱟ (file1.txt):\")"}
{"unnormalised": "", "normalised": "ᱠᱩᱨᱩᱢᱩᱴᱩ ᱢᱮ:", "text": "ᱠᱩᱨᱩᱢᱩᱴᱩ ᱢᱮ:"}
{"unnormalised": "", "normalised": "```santali\n        os.path.join(output_folder, 'file1.txt') ᱨᱮᱱᱟᱜ ᱧᱩᱛᱩᱢᱛᱮ ᱢᱤᱫ ᱯᱷᱟᱭᱤᱞ (file1.txt), 'r' ᱟᱨ 'utf-8' ᱮᱱᱠᱳᱰᱤᱝ ᱛᱮ ᱡᱷᱤᱡ ᱠᱟᱛᱮ:\n        ```", "text": "```santali\nᱢᱤᱫ ᱥᱟᱶᱛᱮ ᱠᱷᱩᱞᱟᱹ ᱠᱟᱛᱮ ᱚᱞ ᱟᱠᱟᱱ (os.path.join(output_folder, 'file1.txt'), 'r', encoding='utf-8') ᱞᱮᱠᱟᱛᱮ ᱮᱯᱷ:\n```"}
{"unnormalised": "", "normalised": "ᱯᱨᱤᱱᱴ (f.read())", "text": "ᱯᱨᱤᱱᱴ(f.ᱨᱮᱰ())"}
{"unnormalised": "", "normalised": "ᱵᱟᱝᱠᱷᱟᱱ ᱧᱟᱢ ᱵᱟᱝ ᱧᱟᱢ ᱨᱮᱭᱟᱜ ᱮᱴᱠᱮᱴᱚᱬᱮ ᱧᱟᱢ ᱞᱮᱱᱠᱷᱟᱱ:", "text": "ᱵᱟᱝ ᱧᱟᱢ ᱟᱠᱟᱱ ᱨᱮᱭᱟᱜ ᱫᱚᱥ ᱵᱟᱝ ᱧᱟᱢ ᱞᱮᱱᱠᱷᱟᱱ ᱫᱚ:"}
{"unnormalised": "", "normalised": "ᱪᱷᱟᱯᱟ ᱢᱮ (\"Normalized file1.txt ᱫᱚ ᱵᱟᱝ ᱧᱟᱢ ᱟᱠᱟᱱᱟ᱾\")", "text": "print(\"Normalized file1.txt ᱵᱟᱹᱱᱩᱜᱼᱟ ᱾\")"}
{"unnormalised": "", "normalised": "Hello, how are you?\n\nI am doing well, thank you.\n\nWhat is your name?\n\nMy name is [Name].\n```\nᱥᱟᱹᱜᱩᱱ ᱡᱚᱦᱟᱨ, ᱪᱮᱫ ᱞᱮᱠᱟ ᱢᱮᱱᱟᱢᱟ?\n\nᱤᱧ ᱫᱚ ᱱᱟᱯᱟᱭ ᱜᱮ ᱢᱮᱱᱟᱹᱧᱟ, ᱥᱟᱨᱦᱟᱣ᱾\n\nᱟᱢᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱪᱮᱫ?\n\nᱤᱧᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ [Name]᱾", "text": "Hello, how are you?\n\nI am doing well, thank you.\n\nWhat is your name?\n\nMy name is [Name].\n```\nᱥᱟᱹᱜᱩᱱ ᱡᱚᱦᱟᱨ, ᱪᱮᱫ ᱞᱮᱠᱟ ᱢᱮᱱᱟᱢᱟ?\n\nᱤᱧ ᱫᱚ ᱱᱟᱯᱟᱭ ᱜᱮ ᱢᱮᱱᱟᱹᱧᱟ, ᱥᱟᱨᱦᱟᱣ᱾\n\nᱟᱢᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ ᱪᱮᱫ?\n\nᱤᱧᱟᱜ ᱧᱩᱛᱩᱢ ᱫᱚ [Name]᱾"}
